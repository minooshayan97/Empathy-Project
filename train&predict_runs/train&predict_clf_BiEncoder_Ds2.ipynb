{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-11-06T02:27:02.226415Z","iopub.status.busy":"2024-11-06T02:27:02.225789Z","iopub.status.idle":"2024-11-06T02:27:15.029947Z","shell.execute_reply":"2024-11-06T02:27:15.028789Z","shell.execute_reply.started":"2024-11-06T02:27:02.226370Z"},"trusted":true},"outputs":[],"source":["!pip install -q transformers datasets wandb"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-06T02:27:15.032132Z","iopub.status.busy":"2024-11-06T02:27:15.031816Z","iopub.status.idle":"2024-11-06T02:27:16.661288Z","shell.execute_reply":"2024-11-06T02:27:16.660326Z","shell.execute_reply.started":"2024-11-06T02:27:15.032099Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: fineGrained).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["!huggingface-cli login --token hf_"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-11-06T02:27:21.192749Z","iopub.status.busy":"2024-11-06T02:27:21.192040Z","iopub.status.idle":"2024-11-06T02:28:00.629491Z","shell.execute_reply":"2024-11-06T02:28:00.628574Z","shell.execute_reply.started":"2024-11-06T02:27:21.192687Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"22f1492fda4140dbab4f9acc910dffe5","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112502588889583, max=1.0…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241106_022742-t7zyv56x</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/minoosh/bert-biencoder-classification/runs/t7zyv56x' target=\"_blank\">worthy-wave-48</a></strong> to <a href='https://wandb.ai/minoosh/bert-biencoder-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/minoosh/bert-biencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/minoosh/bert-biencoder-classification/runs/t7zyv56x' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification/runs/t7zyv56x</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ebd73e799166465d94b57127bb90c55e","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/588 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd99b6c28c8147138f0780c6a176f1b7","version_major":2,"version_minor":0},"text/plain":["train-00000-of-00001.parquet:   0%|          | 0.00/660k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"94d1e4b2d05e4472b85f321eb4f28f5c","version_major":2,"version_minor":0},"text/plain":["test-00000-of-00001.parquet:   0%|          | 0.00/100k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d24ab1a797b488db31db1ea6b125554","version_major":2,"version_minor":0},"text/plain":["validation-00000-of-00001.parquet:   0%|          | 0.00/88.5k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"67ddb3e68bfa421ca99e1b1fdaf7e232","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/2467 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"34243a950669470db47fabbc90c9dfc8","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/308 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"afb3eb43eb114b529b7bfe83d20f84bb","version_major":2,"version_minor":0},"text/plain":["Generating validation split:   0%|          | 0/309 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9245da5f092407b96d9132ce4261627","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b24060c6fcff48ceb087d1317dfe635b","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de1823f5fa634fec90d06d3d317f983c","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e417779e1e074737a57986aa9d84ce35","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2619535d18dc47679aadf099fd7c7da4","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6691f3c0461b432eaf4807817e7f87e2","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2467 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"974e4d8610434de399c349197d32ad26","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/308 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"781cda12c58b44a7875c751bb585648f","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/309 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import torch\n","\n","from datasets import load_dataset\n","\n","from transformers import AutoModel, AutoTokenizer, TrainingArguments, Trainer\n","\n","from transformers import BertConfig, BertModel\n","\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","\n","import wandb\n","\n","import numpy as np\n","\n","\n","\n","# Initialize wandb\n","\n","wandb.init(\n","\n","    project=\"bert-biencoder-classification\"\n","\n",")\n","\n","\n","\n","# Load dataset\n","\n","dataset = load_dataset(\"minoosh/EPITOME_pairs\")\n","\n","\n","\n","# Initialize bi-encoder model (e.g., BERT as a sentence encoder)\n","\n","model_name = \"bert-base-uncased\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","base_model = AutoModel.from_pretrained(model_name)\n","\n","\n","\n","# Tokenize both text1 and text2 independently\n","\n","def preprocess_function(examples):\n","\n","    text1_encodings = tokenizer(examples['text1'], truncation=True, padding=True, max_length=512)\n","\n","    text2_encodings = tokenizer(examples['text2'], truncation=True, padding=True, max_length=512)\n","\n","    return {\n","\n","        'input_ids_text1': text1_encodings['input_ids'],\n","\n","        'attention_mask_text1': text1_encodings['attention_mask'],\n","\n","        'input_ids_text2': text2_encodings['input_ids'],\n","\n","        'attention_mask_text2': text2_encodings['attention_mask'],\n","\n","        'labels': examples['label']\n","\n","    }\n","\n","\n","\n","# Apply tokenization\n","\n","tokenized_train = dataset['train'].map(preprocess_function, batched=True)\n","\n","tokenized_test = dataset['test'].map(preprocess_function, batched=True)\n","\n","tokenized_val = dataset['validation'].map(preprocess_function, batched=True)\n","\n","\n","\n","# Remove unnecessary columns and set format for PyTorch\n","\n","columns_to_keep = ['input_ids_text1', 'attention_mask_text1', 'input_ids_text2', 'attention_mask_text2', 'labels']\n","\n","tokenized_train.set_format(type='torch', columns=columns_to_keep)\n","\n","tokenized_test.set_format(type='torch', columns=columns_to_keep)\n","\n","tokenized_val.set_format(type='torch', columns=columns_to_keep)\n","\n","\n","\n","# Define a custom collator to handle text1 and text2 encoding\n","\n","class BiEncoderCollator:\n","\n","    def __call__(self, features):\n","\n","        batch = {\n","\n","            'input_ids_text1': torch.nn.utils.rnn.pad_sequence(\n","\n","                [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","\n","            'attention_mask_text1': torch.nn.utils.rnn.pad_sequence(\n","\n","                [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","\n","            'input_ids_text2': torch.nn.utils.rnn.pad_sequence(\n","\n","                [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","\n","            'attention_mask_text2': torch.nn.utils.rnn.pad_sequence(\n","\n","                [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","\n","            'labels': torch.tensor([f['labels'] for f in features], dtype=torch.long)  # Change to long for classification\n","\n","        }\n","\n","        return batch\n","\n","\n","\n","collator = BiEncoderCollator()\n","\n","\n","\n","# Define the compute_metrics function for classification with precision and recall\n","\n","def compute_metrics(eval_pred):\n","\n","    predictions, labels = eval_pred\n","\n","    preds = np.argmax(predictions, axis=1)\n","\n","    accuracy = accuracy_score(labels, preds)\n","\n","    f1 = f1_score(labels, preds, average=\"weighted\")\n","\n","    precision = precision_score(labels, preds, average=\"weighted\")\n","\n","    recall = recall_score(labels, preds, average=\"weighted\")\n","\n","    return {\n","\n","        \"accuracy\": accuracy,\n","\n","        \"f1\": f1,\n","\n","        \"precision\": precision,\n","\n","        \"recall\": recall,\n","\n","    }\n","\n","\n","\n","# Define a custom BiEncoder model with options for different loss functions\n","\n","class BiEncoderModel(torch.nn.Module):\n","\n","    def __init__(self, base_model, config=None, num_classes=4, loss_fn=\"cross_entropy\"):\n","\n","        super(BiEncoderModel, self).__init__()\n","\n","        self.base_model = base_model\n","\n","        self.config = config  # Add this line to set the config attribute\n","\n","        self.classifier = torch.nn.Linear(base_model.config.hidden_size * 2, num_classes)  # Updated for 4 classes\n","\n","        self.loss_fn = loss_fn\n","\n","\n","\n","    def forward(self, input_ids_text1, attention_mask_text1, input_ids_text2, attention_mask_text2, labels=None):\n","\n","        # Encode text1 and text2 separately\n","\n","        outputs_text1 = self.base_model(input_ids_text1, attention_mask=attention_mask_text1)\n","\n","        outputs_text2 = self.base_model(input_ids_text2, attention_mask=attention_mask_text2)\n","\n","\n","\n","        # Extract [CLS] token embeddings (first token)\n","\n","        cls_embedding_text1 = outputs_text1.last_hidden_state[:, 0, :]\n","\n","        cls_embedding_text2 = outputs_text2.last_hidden_state[:, 0, :]\n","\n","\n","\n","        # Concatenate embeddings and apply classifier\n","\n","        concatenated_embeddings = torch.cat([cls_embedding_text1, cls_embedding_text2], dim=1)\n","\n","        logits = self.classifier(concatenated_embeddings)\n","\n","\n","\n","        loss = None\n","\n","        if labels is not None:\n","\n","            if self.loss_fn == \"cross_entropy\":\n","\n","                loss_fct = torch.nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n","\n","                loss = loss_fct(logits, labels)\n","\n","            elif self.loss_fn == \"focal_loss\":\n","\n","                # Focal loss implementation\n","\n","                alpha = 0.25\n","\n","                gamma = 2.0\n","\n","                ce_loss = torch.nn.CrossEntropyLoss(reduction=\"none\")(logits, labels)\n","\n","                pt = torch.exp(-ce_loss)  # Probability of the true class\n","\n","                loss = (alpha * (1 - pt) ** gamma * ce_loss).mean()\n","\n","            elif self.loss_fn == \"kl_divergence\":\n","\n","                # KL Divergence for soft-label classification\n","\n","                kl_div = torch.nn.KLDivLoss(reduction=\"batchmean\")\n","\n","                soft_labels = torch.nn.functional.one_hot(labels, num_classes=self.classifier.out_features).float()\n","\n","                log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n","\n","                loss = kl_div(log_probs, soft_labels)\n","\n","            else:\n","\n","                raise ValueError(f\"Unsupported loss function: {self.loss_fn}\")\n","\n","\n","\n","        return {\"loss\": loss, \"logits\": logits}\n","\n","\n","\n","# Initialize the Bi-Encoder model with specified loss function\n","\n","def train_biencoder(loss_fn=\"cross_entropy\"):\n","\n","    # Load pre-trained BERT configuration and model\n","\n","    config = BertConfig.from_pretrained(model_name)\n","\n","    bert_model = BertModel.from_pretrained(model_name)\n","\n","\n","\n","    # Initialize your custom BiEncoderModel with the BERT model, config, and loss function\n","\n","    bi_encoder_model = BiEncoderModel(base_model=bert_model, config=config, loss_fn=loss_fn)\n","\n","\n","\n","    # Define TrainingArguments\n","\n","    training_args = TrainingArguments(\n","\n","        output_dir=f\"./output/bert-clf-biencoder-{loss_fn}\",\n","\n","        evaluation_strategy=\"epoch\",    # Evaluate at the end of each epoch\n","\n","        logging_dir='./logs',           # Directory for logs\n","\n","        logging_steps=10,               # Log every 10 steps\n","\n","        per_device_train_batch_size=wandb.config['batch_size'],\n","\n","        per_device_eval_batch_size=wandb.config['batch_size'],\n","\n","        num_train_epochs=wandb.config['epochs'],\n","\n","        warmup_steps=100,\n","\n","        learning_rate=wandb.config['learning_rate'],\n","\n","        weight_decay=0.01,\n","\n","        report_to=\"wandb\",\n","\n","        save_strategy=\"epoch\",          # Save checkpoints at the end of each epoch\n","\n","        load_best_model_at_end=True,\n","\n","        push_to_hub=True,\n","\n","        save_total_limit=2              # Keep only the 2 most recent checkpoints\n","\n","    )\n","\n","\n","\n","    # Define the Trainer\n","\n","    trainer = Trainer(\n","\n","        model=bi_encoder_model,             # Custom BiEncoder model\n","\n","        args=training_args,                 # Training arguments\n","\n","        train_dataset=tokenized_train,      # Training dataset\n","\n","        eval_dataset=tokenized_val,         # Validation dataset\n","\n","        data_collator=collator,             # Custom collator for handling bi-encoder inputs\n","\n","        compute_metrics=compute_metrics     # Function to compute metrics\n","\n","    )\n","\n","\n","\n","    # Train the model\n","\n","    trainer.train()\n","\n","\n","\n","    # Evaluate the model on the test set\n","\n","    #trainer.evaluate(tokenized_test)\n","\n","\n","\n","    #trainer.model = trainer.model.base_model\n","\n","\n","\n","    # Save and push the model to the Hugging Face Hub\n","\n","    trainer.save_model(f\"./output/bert-clf-biencoder-{loss_fn}\")\n","\n","    trainer.push_to_hub(f\"minoosh/bert-clf-biencoder-{loss_fn}\")\n","\n","\n","\n","    # Finish wandb run\n","\n","    wandb.finish()\n","\n","\n","\n","    return trainer"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 0"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-11-06T01:28:15.180431Z","iopub.status.busy":"2024-11-06T01:28:15.180151Z","iopub.status.idle":"2024-11-06T01:49:31.530947Z","shell.execute_reply":"2024-11-06T01:49:31.530186Z","shell.execute_reply.started":"2024-11-06T01:28:15.180401Z"},"trusted":true},"outputs":[{"data":{"text/html":["Finishing last run (ID:dipj6vxn) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d1ac8e4e026a491ca9eb3761e7cad928","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.016 MB of 0.016 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">fresh-snow-44</strong> at: <a href='https://wandb.ai/minoosh/bert-biencoder-classification/runs/dipj6vxn' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification/runs/dipj6vxn</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-biencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241106_012800-dipj6vxn/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:dipj6vxn). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241106_012815-q5a2ucvk</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/minoosh/bert-biencoder-classification/runs/q5a2ucvk' target=\"_blank\">bert-biencoder-classification-cross_entropy</a></strong> to <a href='https://wandb.ai/minoosh/bert-biencoder-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/minoosh/bert-biencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/minoosh/bert-biencoder-classification/runs/q5a2ucvk' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification/runs/q5a2ucvk</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='546' max='546' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [546/546 20:49, Epoch 7/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.175400</td>\n","      <td>1.059528</td>\n","      <td>0.595469</td>\n","      <td>0.578422</td>\n","      <td>0.595608</td>\n","      <td>0.595469</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.870700</td>\n","      <td>0.863345</td>\n","      <td>0.650485</td>\n","      <td>0.642537</td>\n","      <td>0.664873</td>\n","      <td>0.650485</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.636700</td>\n","      <td>0.829994</td>\n","      <td>0.689320</td>\n","      <td>0.693869</td>\n","      <td>0.708117</td>\n","      <td>0.689320</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.539200</td>\n","      <td>0.842188</td>\n","      <td>0.689320</td>\n","      <td>0.690290</td>\n","      <td>0.697068</td>\n","      <td>0.689320</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.348500</td>\n","      <td>0.875202</td>\n","      <td>0.689320</td>\n","      <td>0.689807</td>\n","      <td>0.692440</td>\n","      <td>0.689320</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.262900</td>\n","      <td>0.930244</td>\n","      <td>0.679612</td>\n","      <td>0.679704</td>\n","      <td>0.679968</td>\n","      <td>0.679612</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.198100</td>\n","      <td>0.963187</td>\n","      <td>0.666667</td>\n","      <td>0.667124</td>\n","      <td>0.669312</td>\n","      <td>0.666667</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","No files have been modified since last commit. Skipping to prevent empty commit.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"33c00c30e06e46c4bf614fe39634a9d3","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.040 MB of 0.040 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅███▇▆</td></tr><tr><td>eval/f1</td><td>▁▅███▇▆</td></tr><tr><td>eval/loss</td><td>█▂▁▁▂▄▅</td></tr><tr><td>eval/precision</td><td>▁▅█▇▇▆▆</td></tr><tr><td>eval/recall</td><td>▁▅███▇▆</td></tr><tr><td>eval/runtime</td><td>▁▃▄▄█▄▅</td></tr><tr><td>eval/samples_per_second</td><td>█▆▅▄▁▄▄</td></tr><tr><td>eval/steps_per_second</td><td>█▆▅▄▁▄▄</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▂▆▁▃▂▂▂▃▂▃▂▃▄▄▂▄▅▃▂▂▃▅▂▃▃▃▅▂█▃▅▃▂▄▄▃▂▂▂▃</td></tr><tr><td>train/learning_rate</td><td>▂▃▄▄▅▇▇███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>██▇▇▇▇▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.66667</td></tr><tr><td>eval/f1</td><td>0.66712</td></tr><tr><td>eval/loss</td><td>0.96319</td></tr><tr><td>eval/precision</td><td>0.66931</td></tr><tr><td>eval/recall</td><td>0.66667</td></tr><tr><td>eval/runtime</td><td>7.221</td></tr><tr><td>eval/samples_per_second</td><td>42.792</td></tr><tr><td>eval/steps_per_second</td><td>1.385</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>7</td></tr><tr><td>train/global_step</td><td>546</td></tr><tr><td>train/grad_norm</td><td>6.61177</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1981</td></tr><tr><td>train_loss</td><td>0.63083</td></tr><tr><td>train_runtime</td><td>1253.3092</td></tr><tr><td>train_samples_per_second</td><td>13.779</td></tr><tr><td>train_steps_per_second</td><td>0.436</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">bert-biencoder-classification-cross_entropy</strong> at: <a href='https://wandb.ai/minoosh/bert-biencoder-classification/runs/q5a2ucvk' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification/runs/q5a2ucvk</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-biencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241106_012815-q5a2ucvk/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Start training with classification setup and selected loss function\n","\n","loss_fns = [\"cross_entropy\", \"focal_loss\", \"kl_divergence\"]\n","\n","loss_fn = loss_fns[0]\n","\n","wandb.init(project=\"bert-biencoder-classification\", name=f\"bert-biencoder-classification-{loss_fn}\", config={\"epochs\": 7, \"batch_size\": 16, \"learning_rate\": 2e-5})\n","\n","tr = train_biencoder(loss_fn)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-11-06T01:49:31.532397Z","iopub.status.busy":"2024-11-06T01:49:31.532091Z","iopub.status.idle":"2024-11-06T01:49:47.253745Z","shell.execute_reply":"2024-11-06T01:49:47.252665Z","shell.execute_reply.started":"2024-11-06T01:49:31.532364Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Saving model to temp_save_bert-clf-biencoder-cross_entropy...\n","Saving tokenizer...\n","Pushing to hub at minoosh/bert-clf-biencoder-cross_entropy...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ed192d811cd48b18ec5acbccbda46ed","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Successfully pushed model to minoosh/bert-clf-biencoder-cross_entropy\n"]}],"source":["tr.tokenizer = tokenizer\n","\n","\n","\n","# To save and push to hub:\n","\n","repo_id = f\"minoosh/bert-clf-biencoder-{loss_fn}\"  \n","\n","save_and_push_to_hub(tr, repo_id)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-11-06T01:50:29.421297Z","iopub.status.busy":"2024-11-06T01:50:29.420829Z","iopub.status.idle":"2024-11-06T01:50:39.631432Z","shell.execute_reply":"2024-11-06T01:50:39.630489Z","shell.execute_reply.started":"2024-11-06T01:50:29.421254Z"},"trusted":true},"outputs":[{"data":{"text/html":["Finishing last run (ID:824khrc9) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"857c261c1d3a4c0eb5419face46e2695","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.018 MB of 0.018 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test/accuracy</td><td>0.64286</td></tr><tr><td>test/f1</td><td>0.64267</td></tr><tr><td>test/loss</td><td>0.93339</td></tr><tr><td>test/precision</td><td>0.65018</td></tr><tr><td>test/recall</td><td>0.64286</td></tr><tr><td>test/runtime</td><td>7.3686</td></tr><tr><td>test/samples_per_second</td><td>41.799</td></tr><tr><td>test/steps_per_second</td><td>1.357</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">glad-elevator-5</strong> at: <a href='https://wandb.ai/minoosh/uncategorized/runs/824khrc9' target=\"_blank\">https://wandb.ai/minoosh/uncategorized/runs/824khrc9</a><br/> View project at: <a href='https://wandb.ai/minoosh/uncategorized' target=\"_blank\">https://wandb.ai/minoosh/uncategorized</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241106_014947-824khrc9/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:824khrc9). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241106_015029-exgqws05</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/minoosh/uncategorized/runs/exgqws05' target=\"_blank\">youthful-rain-6</a></strong> to <a href='https://wandb.ai/minoosh/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/minoosh/uncategorized' target=\"_blank\">https://wandb.ai/minoosh/uncategorized</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/minoosh/uncategorized/runs/exgqws05' target=\"_blank\">https://wandb.ai/minoosh/uncategorized/runs/exgqws05</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["PredictionOutput(predictions=array([[ 0.47875184, -0.7571652 ,  3.1247444 , -1.6508647 ],\n","       [ 0.6576831 ,  2.9659288 , -0.61126363, -2.3105402 ],\n","       [ 2.7631958 ,  0.03781628, -0.4214085 , -1.7669917 ],\n","       ...,\n","       [ 1.9563907 ,  0.5080263 ,  0.912665  , -2.8388667 ],\n","       [ 0.47819823, -0.4523617 ,  1.0313622 ,  0.24573353],\n","       [ 2.052886  ,  0.44165656, -0.18419163, -3.007797  ]],\n","      dtype=float32), label_ids=array([0, 1, 0, 0, 1, 2, 0, 3, 2, 2, 0, 0, 2, 2, 2, 1, 0, 1, 1, 2, 0, 3,\n","       2, 1, 3, 0, 0, 2, 3, 2, 2, 2, 0, 0, 2, 2, 2, 3, 2, 3, 1, 2, 2, 3,\n","       0, 1, 2, 2, 0, 2, 2, 3, 3, 2, 1, 3, 0, 1, 3, 2, 2, 1, 2, 2, 2, 0,\n","       0, 2, 2, 1, 0, 0, 2, 2, 2, 1, 2, 3, 2, 1, 0, 1, 0, 2, 0, 2, 2, 1,\n","       2, 2, 2, 0, 2, 1, 0, 2, 0, 1, 2, 0, 3, 2, 2, 1, 3, 2, 1, 1, 2, 3,\n","       3, 3, 3, 2, 1, 2, 0, 3, 0, 3, 3, 3, 3, 2, 2, 0, 0, 2, 1, 2, 0, 0,\n","       2, 0, 0, 2, 2, 2, 3, 0, 2, 2, 2, 2, 3, 2, 2, 0, 2, 2, 2, 2, 2, 2,\n","       0, 2, 2, 2, 2, 1, 3, 0, 1, 0, 1, 0, 0, 1, 3, 3, 3, 0, 3, 2, 1, 0,\n","       1, 3, 1, 2, 3, 2, 3, 2, 1, 2, 2, 2, 0, 1, 0, 2, 2, 2, 1, 1, 1, 2,\n","       2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 0, 2, 0, 3, 2, 0, 2, 2, 1, 3, 0, 2,\n","       3, 1, 0, 2, 1, 2, 1, 2, 0, 3, 2, 2, 3, 1, 2, 0, 1, 0, 0, 0, 2, 0,\n","       1, 0, 2, 1, 2, 0, 2, 2, 2, 2, 2, 1, 2, 3, 0, 2, 3, 3, 0, 1, 2, 3,\n","       0, 0, 2, 2, 3, 2, 2, 0, 1, 3, 2, 3, 2, 2, 3, 1, 2, 1, 2, 2, 1, 0,\n","       0, 0, 0, 2, 3, 1, 3, 0, 0, 1, 0, 1, 3, 3, 2, 1, 1, 2, 0, 0, 2, 1]), metrics={'test_loss': 0.9333889484405518, 'test_accuracy': 0.6428571428571429, 'test_f1': 0.642670395972224, 'test_precision': 0.6501814667559133, 'test_recall': 0.6428571428571429, 'test_runtime': 7.3654, 'test_samples_per_second': 41.817, 'test_steps_per_second': 1.358})"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init()\n","\n","preds = tr.predict(tokenized_test)\n","preds"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-11-06T01:51:34.790894Z","iopub.status.busy":"2024-11-06T01:51:34.790192Z","iopub.status.idle":"2024-11-06T01:51:34.798089Z","shell.execute_reply":"2024-11-06T01:51:34.797144Z","shell.execute_reply.started":"2024-11-06T01:51:34.790849Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([2, 1, 0, 0, 1, 1, 0, 3, 0, 2, 0, 0, 2, 2, 0, 0, 0, 1, 1, 2, 0, 1,\n","       2, 1, 1, 1, 0, 2, 3, 2, 2, 2, 0, 0, 2, 2, 2, 3, 0, 0, 1, 1, 2, 2,\n","       1, 1, 2, 2, 2, 2, 0, 2, 1, 2, 1, 1, 2, 0, 2, 2, 2, 2, 2, 2, 1, 0,\n","       0, 2, 1, 1, 0, 0, 3, 1, 2, 1, 2, 3, 1, 0, 1, 0, 2, 2, 2, 2, 2, 0,\n","       2, 2, 2, 0, 2, 2, 2, 3, 0, 1, 2, 1, 3, 2, 0, 0, 1, 2, 1, 2, 2, 1,\n","       1, 1, 3, 2, 1, 2, 0, 2, 0, 3, 3, 2, 1, 2, 2, 0, 0, 2, 2, 2, 1, 0,\n","       1, 0, 2, 2, 2, 2, 1, 1, 2, 2, 0, 2, 3, 2, 2, 0, 2, 2, 2, 2, 2, 2,\n","       2, 2, 1, 3, 2, 2, 3, 1, 1, 0, 1, 0, 0, 2, 2, 3, 3, 1, 2, 2, 3, 0,\n","       1, 2, 2, 2, 1, 2, 3, 2, 2, 2, 3, 2, 2, 1, 0, 2, 2, 3, 2, 1, 1, 2,\n","       2, 2, 3, 1, 2, 2, 0, 1, 2, 0, 0, 2, 0, 1, 2, 0, 3, 2, 1, 2, 0, 2,\n","       1, 1, 0, 1, 1, 2, 1, 2, 0, 3, 2, 2, 3, 2, 2, 0, 1, 0, 0, 2, 2, 0,\n","       1, 0, 0, 0, 2, 0, 2, 2, 0, 0, 1, 1, 2, 3, 0, 1, 1, 3, 3, 1, 2, 1,\n","       0, 1, 2, 2, 3, 2, 1, 1, 1, 2, 2, 3, 3, 1, 2, 0, 2, 2, 2, 2, 2, 0,\n","       0, 0, 0, 3, 2, 0, 3, 0, 0, 2, 2, 1, 3, 3, 3, 1, 1, 3, 1, 0, 2, 0])"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["preds.predictions.argmax(axis=1)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 1"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-11-06T01:53:42.430283Z","iopub.status.busy":"2024-11-06T01:53:42.429941Z","iopub.status.idle":"2024-11-06T02:17:12.227962Z","shell.execute_reply":"2024-11-06T02:17:12.227201Z","shell.execute_reply.started":"2024-11-06T01:53:42.430243Z"},"trusted":true},"outputs":[{"data":{"text/html":["Finishing last run (ID:mbxf7x73) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e432a840aa424f6ba3f47187736d4158","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.016 MB of 0.016 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">logical-tree-46</strong> at: <a href='https://wandb.ai/minoosh/bert-biencoder-classification/runs/mbxf7x73' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification/runs/mbxf7x73</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-biencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241106_015328-mbxf7x73/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:mbxf7x73). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241106_015342-0g2nwct8</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/minoosh/bert-biencoder-classification/runs/0g2nwct8' target=\"_blank\">bert-biencoder-classification-focal_loss</a></strong> to <a href='https://wandb.ai/minoosh/bert-biencoder-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/minoosh/bert-biencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/minoosh/bert-biencoder-classification/runs/0g2nwct8' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification/runs/0g2nwct8</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='546' max='546' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [546/546 22:05, Epoch 7/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.157100</td>\n","      <td>0.133447</td>\n","      <td>0.576052</td>\n","      <td>0.559657</td>\n","      <td>0.584601</td>\n","      <td>0.576052</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.101900</td>\n","      <td>0.100859</td>\n","      <td>0.647249</td>\n","      <td>0.639938</td>\n","      <td>0.666010</td>\n","      <td>0.647249</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.071100</td>\n","      <td>0.092316</td>\n","      <td>0.686084</td>\n","      <td>0.686860</td>\n","      <td>0.690961</td>\n","      <td>0.686084</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.047500</td>\n","      <td>0.097190</td>\n","      <td>0.660194</td>\n","      <td>0.661132</td>\n","      <td>0.674644</td>\n","      <td>0.660194</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.025800</td>\n","      <td>0.108519</td>\n","      <td>0.660194</td>\n","      <td>0.659646</td>\n","      <td>0.669853</td>\n","      <td>0.660194</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.018800</td>\n","      <td>0.109882</td>\n","      <td>0.663430</td>\n","      <td>0.662647</td>\n","      <td>0.666683</td>\n","      <td>0.663430</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.015500</td>\n","      <td>0.113551</td>\n","      <td>0.660194</td>\n","      <td>0.659590</td>\n","      <td>0.664228</td>\n","      <td>0.660194</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","No files have been modified since last commit. Skipping to prevent empty commit.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b36a8a5054d4d5caf2d5555481159df","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.040 MB of 0.040 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆█▆▆▇▆</td></tr><tr><td>eval/f1</td><td>▁▅█▇▇▇▆</td></tr><tr><td>eval/loss</td><td>█▂▁▂▄▄▅</td></tr><tr><td>eval/precision</td><td>▁▆█▇▇▆▆</td></tr><tr><td>eval/recall</td><td>▁▆█▆▆▇▆</td></tr><tr><td>eval/runtime</td><td>█▅▆▅▁█▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▄▃▄█▁█</td></tr><tr><td>eval/steps_per_second</td><td>▁▄▃▄█▂█</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▄█▃▅▄▅▄▄▅▄▅▅▅▃▃█▄▄▅▇▄▄▃▃▆▄▄▄▄▄▃▁▂▂▂▂▂▃▁▁</td></tr><tr><td>train/learning_rate</td><td>▂▃▄▄▅▇▇███▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▇██▇▆▆▅▅▅▄▄▄▃▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.66019</td></tr><tr><td>eval/f1</td><td>0.65959</td></tr><tr><td>eval/loss</td><td>0.11355</td></tr><tr><td>eval/precision</td><td>0.66423</td></tr><tr><td>eval/recall</td><td>0.66019</td></tr><tr><td>eval/runtime</td><td>7.5282</td></tr><tr><td>eval/samples_per_second</td><td>41.045</td></tr><tr><td>eval/steps_per_second</td><td>1.328</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>7</td></tr><tr><td>train/global_step</td><td>546</td></tr><tr><td>train/grad_norm</td><td>0.4663</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0155</td></tr><tr><td>train_loss</td><td>0.07096</td></tr><tr><td>train_runtime</td><td>1328.7726</td></tr><tr><td>train_samples_per_second</td><td>12.996</td></tr><tr><td>train_steps_per_second</td><td>0.411</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">bert-biencoder-classification-focal_loss</strong> at: <a href='https://wandb.ai/minoosh/bert-biencoder-classification/runs/0g2nwct8' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification/runs/0g2nwct8</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-biencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241106_015342-0g2nwct8/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Start training with classification setup and selected loss function\n","\n","loss_fns = [\"cross_entropy\", \"focal_loss\", \"kl_divergence\"]\n","\n","loss_fn = loss_fns[1]\n","\n","wandb.init(project=\"bert-biencoder-classification\", name=f\"bert-biencoder-classification-{loss_fn}\", config={\"epochs\": 7, \"batch_size\": 16, \"learning_rate\": 2e-5})\n","\n","tr = train_biencoder(loss_fn)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-11-06T02:17:12.229769Z","iopub.status.busy":"2024-11-06T02:17:12.229287Z","iopub.status.idle":"2024-11-06T02:17:30.513330Z","shell.execute_reply":"2024-11-06T02:17:30.512318Z","shell.execute_reply.started":"2024-11-06T02:17:12.229724Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Saving model to temp_save_bert-clf-biencoder-focal_loss...\n","Saving tokenizer...\n","Pushing to hub at minoosh/bert-clf-biencoder-focal_loss...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5323968552ee4a08b609d4a9f8181f03","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Successfully pushed model to minoosh/bert-clf-biencoder-focal_loss\n"]}],"source":["tr.tokenizer = tokenizer\n","\n","\n","\n","# To save and push to hub:\n","\n","repo_id = f\"minoosh/bert-clf-biencoder-{loss_fn}\"  \n","\n","save_and_push_to_hub(tr, repo_id)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-11-06T02:17:30.516687Z","iopub.status.busy":"2024-11-06T02:17:30.515912Z","iopub.status.idle":"2024-11-06T02:17:39.787622Z","shell.execute_reply":"2024-11-06T02:17:39.786598Z","shell.execute_reply.started":"2024-11-06T02:17:30.516629Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminooshayan97\u001b[0m (\u001b[33mminoosh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241106_021730-jqzrmh31</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/minoosh/uncategorized/runs/jqzrmh31' target=\"_blank\">deep-universe-7</a></strong> to <a href='https://wandb.ai/minoosh/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/minoosh/uncategorized' target=\"_blank\">https://wandb.ai/minoosh/uncategorized</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/minoosh/uncategorized/runs/jqzrmh31' target=\"_blank\">https://wandb.ai/minoosh/uncategorized/runs/jqzrmh31</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["PredictionOutput(predictions=array([[ 0.4862593 , -0.89750385,  1.7197946 , -0.72526085],\n","       [ 0.09727408,  1.843831  , -0.56674606, -1.7101706 ],\n","       [ 2.0809734 ,  0.02295816,  0.5901209 , -1.7126127 ],\n","       ...,\n","       [ 1.5558326 ,  0.46905598,  0.5399975 , -1.3892521 ],\n","       [ 0.4268964 , -0.7688354 ,  1.0717008 ,  0.1452835 ],\n","       [ 1.5584437 ,  0.8424485 ,  0.29216307, -1.8913709 ]],\n","      dtype=float32), label_ids=array([0, 1, 0, 0, 1, 2, 0, 3, 2, 2, 0, 0, 2, 2, 2, 1, 0, 1, 1, 2, 0, 3,\n","       2, 1, 3, 0, 0, 2, 3, 2, 2, 2, 0, 0, 2, 2, 2, 3, 2, 3, 1, 2, 2, 3,\n","       0, 1, 2, 2, 0, 2, 2, 3, 3, 2, 1, 3, 0, 1, 3, 2, 2, 1, 2, 2, 2, 0,\n","       0, 2, 2, 1, 0, 0, 2, 2, 2, 1, 2, 3, 2, 1, 0, 1, 0, 2, 0, 2, 2, 1,\n","       2, 2, 2, 0, 2, 1, 0, 2, 0, 1, 2, 0, 3, 2, 2, 1, 3, 2, 1, 1, 2, 3,\n","       3, 3, 3, 2, 1, 2, 0, 3, 0, 3, 3, 3, 3, 2, 2, 0, 0, 2, 1, 2, 0, 0,\n","       2, 0, 0, 2, 2, 2, 3, 0, 2, 2, 2, 2, 3, 2, 2, 0, 2, 2, 2, 2, 2, 2,\n","       0, 2, 2, 2, 2, 1, 3, 0, 1, 0, 1, 0, 0, 1, 3, 3, 3, 0, 3, 2, 1, 0,\n","       1, 3, 1, 2, 3, 2, 3, 2, 1, 2, 2, 2, 0, 1, 0, 2, 2, 2, 1, 1, 1, 2,\n","       2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 0, 2, 0, 3, 2, 0, 2, 2, 1, 3, 0, 2,\n","       3, 1, 0, 2, 1, 2, 1, 2, 0, 3, 2, 2, 3, 1, 2, 0, 1, 0, 0, 0, 2, 0,\n","       1, 0, 2, 1, 2, 0, 2, 2, 2, 2, 2, 1, 2, 3, 0, 2, 3, 3, 0, 1, 2, 3,\n","       0, 0, 2, 2, 3, 2, 2, 0, 1, 3, 2, 3, 2, 2, 3, 1, 2, 1, 2, 2, 1, 0,\n","       0, 0, 0, 2, 3, 1, 3, 0, 0, 1, 0, 1, 3, 3, 2, 1, 1, 2, 0, 0, 2, 1]), metrics={'test_loss': 0.10883145779371262, 'test_accuracy': 0.6525974025974026, 'test_f1': 0.6506934618819955, 'test_precision': 0.6506317326084768, 'test_recall': 0.6525974025974026, 'test_runtime': 7.8565, 'test_samples_per_second': 39.203, 'test_steps_per_second': 1.273})"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init()\n","\n","preds = tr.predict(tokenized_test)\n","preds"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-11-06T02:17:39.789336Z","iopub.status.busy":"2024-11-06T02:17:39.788922Z","iopub.status.idle":"2024-11-06T02:17:39.798034Z","shell.execute_reply":"2024-11-06T02:17:39.797134Z","shell.execute_reply.started":"2024-11-06T02:17:39.789290Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([2, 1, 0, 0, 2, 1, 0, 3, 2, 2, 0, 0, 0, 2, 0, 0, 0, 1, 0, 2, 0, 3,\n","       2, 1, 1, 1, 0, 2, 3, 2, 0, 2, 0, 0, 2, 2, 0, 3, 0, 0, 1, 3, 2, 3,\n","       0, 1, 2, 2, 2, 2, 0, 2, 0, 2, 1, 1, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0,\n","       1, 2, 1, 1, 0, 0, 3, 1, 2, 1, 2, 3, 1, 0, 0, 0, 2, 2, 2, 2, 2, 0,\n","       2, 2, 2, 0, 2, 2, 0, 3, 0, 1, 2, 1, 3, 2, 2, 0, 1, 2, 1, 2, 2, 1,\n","       1, 3, 3, 2, 1, 2, 2, 2, 0, 2, 3, 2, 3, 2, 2, 0, 0, 2, 2, 2, 1, 0,\n","       1, 0, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 3, 2, 3, 0, 2, 1, 2, 2, 2, 2,\n","       2, 2, 1, 3, 2, 2, 3, 1, 1, 0, 1, 0, 0, 2, 2, 3, 3, 1, 2, 2, 3, 0,\n","       1, 2, 2, 2, 1, 2, 3, 2, 2, 2, 3, 2, 2, 1, 0, 2, 2, 3, 2, 1, 1, 2,\n","       2, 2, 3, 2, 2, 0, 0, 1, 2, 1, 0, 2, 0, 3, 2, 0, 3, 2, 1, 2, 0, 2,\n","       1, 1, 0, 1, 1, 2, 1, 2, 0, 3, 2, 2, 3, 2, 1, 0, 1, 0, 0, 0, 2, 0,\n","       1, 0, 0, 0, 2, 0, 2, 2, 0, 0, 0, 0, 3, 3, 0, 1, 3, 3, 3, 3, 2, 3,\n","       0, 0, 2, 2, 3, 2, 1, 1, 1, 2, 2, 3, 3, 2, 2, 0, 2, 2, 2, 2, 2, 0,\n","       0, 0, 0, 2, 2, 0, 3, 0, 0, 2, 0, 1, 3, 3, 3, 1, 1, 3, 2, 0, 2, 0])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["preds.predictions.argmax(axis=1)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 2"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-11-06T02:28:00.631960Z","iopub.status.busy":"2024-11-06T02:28:00.631449Z","iopub.status.idle":"2024-11-06T02:50:05.541064Z","shell.execute_reply":"2024-11-06T02:50:05.540176Z","shell.execute_reply.started":"2024-11-06T02:28:00.631915Z"},"trusted":true},"outputs":[{"data":{"text/html":["Finishing last run (ID:t7zyv56x) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd9a6941f55545d5ac19d4eba43fff43","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.016 MB of 0.016 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">worthy-wave-48</strong> at: <a href='https://wandb.ai/minoosh/bert-biencoder-classification/runs/t7zyv56x' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification/runs/t7zyv56x</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-biencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241106_022742-t7zyv56x/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:t7zyv56x). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241106_022800-fnu3ia4u</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/minoosh/bert-biencoder-classification/runs/fnu3ia4u' target=\"_blank\">bert-biencoder-classification-kl_divergence</a></strong> to <a href='https://wandb.ai/minoosh/bert-biencoder-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/minoosh/bert-biencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/minoosh/bert-biencoder-classification/runs/fnu3ia4u' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification/runs/fnu3ia4u</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='546' max='546' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [546/546 21:41, Epoch 7/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.144900</td>\n","      <td>1.056463</td>\n","      <td>0.598706</td>\n","      <td>0.582026</td>\n","      <td>0.606798</td>\n","      <td>0.598706</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.867200</td>\n","      <td>0.847126</td>\n","      <td>0.650485</td>\n","      <td>0.644873</td>\n","      <td>0.661130</td>\n","      <td>0.650485</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.628800</td>\n","      <td>0.800347</td>\n","      <td>0.682848</td>\n","      <td>0.685784</td>\n","      <td>0.693318</td>\n","      <td>0.682848</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.502300</td>\n","      <td>0.817851</td>\n","      <td>0.689320</td>\n","      <td>0.691120</td>\n","      <td>0.700848</td>\n","      <td>0.689320</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.332000</td>\n","      <td>0.860958</td>\n","      <td>0.686084</td>\n","      <td>0.686556</td>\n","      <td>0.690745</td>\n","      <td>0.686084</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.263700</td>\n","      <td>0.907476</td>\n","      <td>0.686084</td>\n","      <td>0.686973</td>\n","      <td>0.689050</td>\n","      <td>0.686084</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.189500</td>\n","      <td>0.946877</td>\n","      <td>0.682848</td>\n","      <td>0.684449</td>\n","      <td>0.693678</td>\n","      <td>0.682848</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","No files have been modified since last commit. Skipping to prevent empty commit.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"944f5a3e7b694fa8bd98039bd44f9415","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.040 MB of 0.040 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅█████</td></tr><tr><td>eval/f1</td><td>▁▅█████</td></tr><tr><td>eval/loss</td><td>█▂▁▁▃▄▅</td></tr><tr><td>eval/precision</td><td>▁▅▇█▇▇▇</td></tr><tr><td>eval/recall</td><td>▁▅█████</td></tr><tr><td>eval/runtime</td><td>▃▁▅█▁▂▅</td></tr><tr><td>eval/samples_per_second</td><td>▆█▄▁█▇▄</td></tr><tr><td>eval/steps_per_second</td><td>▆█▄▁██▄</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▂▄▂▂▂▃▂▃▂▂▂▄▄▄▂▃▄▂▂▂▁▃▃▂▃▂▂▃▂█▁▂▂▂▃▂▁▂▂▂</td></tr><tr><td>train/learning_rate</td><td>▂▂▃▄▄▆▇▇███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>███▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.68285</td></tr><tr><td>eval/f1</td><td>0.68445</td></tr><tr><td>eval/loss</td><td>0.94688</td></tr><tr><td>eval/precision</td><td>0.69368</td></tr><tr><td>eval/recall</td><td>0.68285</td></tr><tr><td>eval/runtime</td><td>7.3416</td></tr><tr><td>eval/samples_per_second</td><td>42.089</td></tr><tr><td>eval/steps_per_second</td><td>1.362</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>7</td></tr><tr><td>train/global_step</td><td>546</td></tr><tr><td>train/grad_norm</td><td>4.96978</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1895</td></tr><tr><td>train_loss</td><td>0.61508</td></tr><tr><td>train_runtime</td><td>1304.9241</td></tr><tr><td>train_samples_per_second</td><td>13.234</td></tr><tr><td>train_steps_per_second</td><td>0.418</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">bert-biencoder-classification-kl_divergence</strong> at: <a href='https://wandb.ai/minoosh/bert-biencoder-classification/runs/fnu3ia4u' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification/runs/fnu3ia4u</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-biencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241106_022800-fnu3ia4u/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Start training with classification setup and selected loss function\n","\n","loss_fns = [\"cross_entropy\", \"focal_loss\", \"kl_divergence\"]\n","\n","loss_fn = loss_fns[2]\n","\n","wandb.init(project=\"bert-biencoder-classification\", name=f\"bert-biencoder-classification-{loss_fn}\", config={\"epochs\": 7, \"batch_size\": 16, \"learning_rate\": 2e-5})\n","\n","tr = train_biencoder(loss_fn)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-11-06T02:50:05.543180Z","iopub.status.busy":"2024-11-06T02:50:05.542402Z","iopub.status.idle":"2024-11-06T02:50:19.145844Z","shell.execute_reply":"2024-11-06T02:50:19.144911Z","shell.execute_reply.started":"2024-11-06T02:50:05.543146Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Saving model to temp_save_bert-clf-biencoder-kl_divergence...\n","Saving tokenizer...\n","Pushing to hub at minoosh/bert-clf-biencoder-kl_divergence...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e02fc60abbc747b184511e7951fc0f25","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Successfully pushed model to minoosh/bert-clf-biencoder-kl_divergence\n"]}],"source":["tr.tokenizer = tokenizer\n","\n","\n","\n","# To save and push to hub:\n","\n","repo_id = f\"minoosh/bert-clf-biencoder-{loss_fn}\"  \n","\n","save_and_push_to_hub(tr, repo_id)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-11-06T02:50:19.148394Z","iopub.status.busy":"2024-11-06T02:50:19.148073Z","iopub.status.idle":"2024-11-06T02:50:27.981712Z","shell.execute_reply":"2024-11-06T02:50:27.980898Z","shell.execute_reply.started":"2024-11-06T02:50:19.148362Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminooshayan97\u001b[0m (\u001b[33mminoosh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241106_025019-dva6uaz1</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/minoosh/uncategorized/runs/dva6uaz1' target=\"_blank\">ethereal-dew-8</a></strong> to <a href='https://wandb.ai/minoosh/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/minoosh/uncategorized' target=\"_blank\">https://wandb.ai/minoosh/uncategorized</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/minoosh/uncategorized/runs/dva6uaz1' target=\"_blank\">https://wandb.ai/minoosh/uncategorized/runs/dva6uaz1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_30/3681778032.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3681778032.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["PredictionOutput(predictions=array([[ 0.39821813, -1.4689566 ,  2.45921   , -1.5977148 ],\n","       [ 0.42356625,  2.5593278 , -0.574579  , -1.5304163 ],\n","       [ 1.9899086 , -0.00462926, -0.44955316, -1.7662003 ],\n","       ...,\n","       [ 1.9871001 , -0.21687815,  0.94965726, -2.630942  ],\n","       [ 0.07549342, -1.3629589 ,  1.504989  , -0.8616574 ],\n","       [ 2.2410529 ,  1.0336057 ,  0.05006527, -2.8397596 ]],\n","      dtype=float32), label_ids=array([0, 1, 0, 0, 1, 2, 0, 3, 2, 2, 0, 0, 2, 2, 2, 1, 0, 1, 1, 2, 0, 3,\n","       2, 1, 3, 0, 0, 2, 3, 2, 2, 2, 0, 0, 2, 2, 2, 3, 2, 3, 1, 2, 2, 3,\n","       0, 1, 2, 2, 0, 2, 2, 3, 3, 2, 1, 3, 0, 1, 3, 2, 2, 1, 2, 2, 2, 0,\n","       0, 2, 2, 1, 0, 0, 2, 2, 2, 1, 2, 3, 2, 1, 0, 1, 0, 2, 0, 2, 2, 1,\n","       2, 2, 2, 0, 2, 1, 0, 2, 0, 1, 2, 0, 3, 2, 2, 1, 3, 2, 1, 1, 2, 3,\n","       3, 3, 3, 2, 1, 2, 0, 3, 0, 3, 3, 3, 3, 2, 2, 0, 0, 2, 1, 2, 0, 0,\n","       2, 0, 0, 2, 2, 2, 3, 0, 2, 2, 2, 2, 3, 2, 2, 0, 2, 2, 2, 2, 2, 2,\n","       0, 2, 2, 2, 2, 1, 3, 0, 1, 0, 1, 0, 0, 1, 3, 3, 3, 0, 3, 2, 1, 0,\n","       1, 3, 1, 2, 3, 2, 3, 2, 1, 2, 2, 2, 0, 1, 0, 2, 2, 2, 1, 1, 1, 2,\n","       2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 0, 2, 0, 3, 2, 0, 2, 2, 1, 3, 0, 2,\n","       3, 1, 0, 2, 1, 2, 1, 2, 0, 3, 2, 2, 3, 1, 2, 0, 1, 0, 0, 0, 2, 0,\n","       1, 0, 2, 1, 2, 0, 2, 2, 2, 2, 2, 1, 2, 3, 0, 2, 3, 3, 0, 1, 2, 3,\n","       0, 0, 2, 2, 3, 2, 2, 0, 1, 3, 2, 3, 2, 2, 3, 1, 2, 1, 2, 2, 1, 0,\n","       0, 0, 0, 2, 3, 1, 3, 0, 0, 1, 0, 1, 3, 3, 2, 1, 1, 2, 0, 0, 2, 1]), metrics={'test_loss': 0.9395537972450256, 'test_accuracy': 0.6428571428571429, 'test_f1': 0.6426294649088589, 'test_precision': 0.6447272239955166, 'test_recall': 0.6428571428571429, 'test_runtime': 7.4366, 'test_samples_per_second': 41.417, 'test_steps_per_second': 1.345})"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init()\n","\n","preds = tr.predict(tokenized_test)\n","preds"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-11-06T02:50:28.048256Z","iopub.status.busy":"2024-11-06T02:50:28.048002Z","iopub.status.idle":"2024-11-06T02:50:28.056864Z","shell.execute_reply":"2024-11-06T02:50:28.055839Z","shell.execute_reply.started":"2024-11-06T02:50:28.048226Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([2, 1, 0, 0, 1, 2, 0, 3, 2, 2, 0, 0, 2, 2, 0, 0, 0, 1, 0, 2, 0, 3,\n","       2, 1, 1, 1, 0, 2, 3, 2, 2, 2, 0, 0, 2, 2, 2, 1, 0, 0, 1, 3, 2, 3,\n","       1, 1, 2, 2, 2, 2, 0, 2, 1, 2, 1, 1, 2, 0, 2, 2, 2, 2, 2, 2, 1, 0,\n","       0, 2, 1, 1, 0, 0, 3, 1, 2, 1, 2, 3, 1, 0, 0, 0, 2, 2, 2, 2, 2, 0,\n","       2, 2, 2, 0, 2, 2, 0, 3, 0, 1, 2, 1, 3, 2, 0, 0, 1, 2, 1, 2, 2, 0,\n","       1, 1, 3, 2, 1, 2, 2, 2, 0, 3, 3, 2, 3, 2, 2, 0, 0, 2, 2, 2, 1, 0,\n","       1, 0, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 3, 2, 2, 0, 2, 2, 2, 2, 2, 3,\n","       2, 2, 1, 3, 2, 2, 3, 1, 0, 0, 1, 0, 0, 2, 2, 3, 3, 0, 2, 2, 3, 0,\n","       1, 2, 2, 2, 1, 2, 3, 2, 2, 2, 3, 2, 2, 1, 1, 2, 2, 3, 2, 1, 1, 2,\n","       2, 2, 3, 1, 2, 2, 0, 1, 2, 0, 0, 2, 0, 1, 2, 0, 3, 2, 1, 2, 0, 2,\n","       1, 1, 0, 1, 1, 2, 1, 2, 0, 3, 2, 2, 3, 2, 2, 0, 1, 0, 0, 2, 3, 0,\n","       1, 0, 0, 0, 2, 0, 2, 2, 0, 0, 1, 1, 2, 3, 0, 1, 1, 3, 3, 3, 2, 1,\n","       0, 0, 2, 2, 3, 2, 1, 1, 1, 2, 2, 3, 3, 1, 3, 0, 2, 2, 2, 2, 2, 1,\n","       1, 0, 0, 3, 2, 0, 3, 0, 0, 2, 2, 1, 1, 3, 3, 1, 1, 3, 1, 0, 2, 0])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["preds.predictions.argmax(axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Save and Push to hub"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-11-06T02:27:16.662943Z","iopub.status.busy":"2024-11-06T02:27:16.662609Z","iopub.status.idle":"2024-11-06T02:27:21.189539Z","shell.execute_reply":"2024-11-06T02:27:21.188526Z","shell.execute_reply.started":"2024-11-06T02:27:16.662910Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","import json\n","\n","from huggingface_hub import HfApi\n","\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, BertConfig\n","\n","\n","\n","def save_and_push_to_hub(trainer, repo_id, token=None):\n","\n","    \"\"\"\n","\n","    Save and push BiEncoder model to Hugging Face Hub\n","\n","    \"\"\"\n","\n","    api = HfApi()\n","\n","    \n","\n","    try:\n","\n","        temp_save_path = f\"temp_save_{repo_id.split('/')[-1]}\"\n","\n","        os.makedirs(temp_save_path, exist_ok=True)\n","\n","        \n","\n","        print(f\"Saving model to {temp_save_path}...\")\n","\n","        \n","\n","        # 1. Save the base model configuration\n","\n","        base_config = trainer.model.base_model.config.to_dict()\n","\n","        base_config[\"model_type\"] = \"bert\"  # Ensure we're using BERT as base\n","\n","        base_config[\"architectures\"] = [\"BertModel\"]\n","\n","        \n","\n","        with open(os.path.join(temp_save_path, \"config.json\"), 'w') as f:\n","\n","            json.dump(base_config, f)\n","\n","            \n","\n","        # 2. Save model weights\n","\n","        torch.save(trainer.model.state_dict(), os.path.join(temp_save_path, \"pytorch_model.bin\"))\n","\n","        \n","\n","        # 3. Save tokenizer\n","\n","        print(\"Saving tokenizer...\")\n","\n","        if hasattr(trainer, 'tokenizer'):\n","\n","            trainer.tokenizer.save_pretrained(temp_save_path)\n","\n","        \n","\n","        # 4. Create model card\n","\n","        model_card = f\"\"\"---\n","\n","language: en\n","\n","tags:\n","\n","- bert\n","\n","- classification\n","\n","- pytorch\n","\n","pipeline_tag: text-classification\n","\n","---\n","\n","\n","\n","# BiEncoder Classification Model\n","\n","\n","\n","This model is a BiEncoder architecture based on BERT for text pair classification.\n","\n","\n","\n","## Model Details\n","\n","- Base Model: bert-base-uncased\n","\n","- Architecture: BiEncoder with BERT base\n","\n","- Number of classes: {trainer.model.classifier.out_features}\n","\n","\n","\n","## Usage\n","\n","\n","\n","```python\n","\n","from transformers import AutoTokenizer\n","\n","import torch\n","\n","\n","\n","# Load tokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"{repo_id}\")\n","\n","\n","\n","# Load model weights\n","\n","state_dict = torch.load(\"pytorch_model.bin\")\n","\n","\n","\n","# Initialize model (you'll need the BiEncoderModel class)\n","\n","model = BiEncoderModel(\n","\n","    base_model=AutoModel.from_pretrained(\"bert-base-uncased\"),\n","\n","    num_classes={trainer.model.classifier.out_features}\n","\n",")\n","\n","model.load_state_dict(state_dict)\n","\n","```\n","\n","\"\"\"\n","\n","        with open(os.path.join(temp_save_path, \"README.md\"), 'w') as f:\n","\n","            f.write(model_card)\n","\n","        \n","\n","        # 5. Push to hub\n","\n","        print(f\"Pushing to hub at {repo_id}...\")\n","\n","        api.upload_folder(\n","\n","            folder_path=temp_save_path,\n","\n","            repo_id=repo_id,\n","\n","            token=token\n","\n","        )\n","\n","        \n","\n","        print(f\"Successfully pushed model to {repo_id}\")\n","\n","        \n","\n","    except Exception as e:\n","\n","        print(f\"Error during push to hub: {str(e)}\")\n","\n","        raise\n","\n","    finally:\n","\n","        if os.path.exists(temp_save_path):\n","\n","            import shutil\n","\n","            shutil.rmtree(temp_save_path)\n","\n","\n","\n","def load_from_hub(repo_id, num_classes=4):\n","\n","    \"\"\"\n","\n","    Load BiEncoder model from Hugging Face Hub\n","\n","    \"\"\"\n","\n","    try:\n","\n","        print(f\"Loading model from {repo_id}...\")\n","\n","        \n","\n","        # 1. Initialize base model with BERT\n","\n","        base_model = AutoModel.from_pretrained(\"bert-base-uncased\")\n","\n","        \n","\n","        # 2. Create BiEncoder model\n","\n","        model = BiEncoderModel(\n","\n","            base_model=base_model,\n","\n","            num_classes=num_classes\n","\n","        )\n","\n","        \n","\n","        # 3. Load state dict\n","\n","        state_dict = torch.hub.load_state_dict_from_url(\n","\n","            f\"https://huggingface.co/{repo_id}/resolve/main/pytorch_model.bin\",\n","\n","            map_location=\"cpu\"\n","\n","        )\n","\n","        model.load_state_dict(state_dict)\n","\n","        \n","\n","        # 4. Load tokenizer\n","\n","        tokenizer = AutoTokenizer.from_pretrained(repo_id)\n","\n","        \n","\n","        # 5. Create trainer\n","\n","        trainer = Trainer(\n","\n","            model=model,\n","\n","            data_collator=BiEncoderCollator(),\n","\n","            compute_metrics=compute_metrics\n","\n","        )\n","\n","        \n","\n","        print(\"Model loaded successfully!\")\n","\n","        return trainer, model, tokenizer\n","\n","        \n","\n","    except Exception as e:\n","\n","        print(f\"Error loading model from hub: {str(e)}\")\n","\n","        raise"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T18:24:49.248184Z","iopub.status.busy":"2024-11-05T18:24:49.247786Z","iopub.status.idle":"2024-11-05T18:25:05.406862Z","shell.execute_reply":"2024-11-05T18:25:05.405701Z","shell.execute_reply.started":"2024-11-05T18:24:49.248147Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Saving model to temp_save_bert-clf-biencoder-cross_entropy...\n","Saving tokenizer...\n","Pushing to hub at minoosh/bert-clf-biencoder-cross_entropy...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"79f80432f2d64bfda5c5b0c32eb75a3a","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Successfully pushed model to minoosh/bert-clf-biencoder-cross_entropy\n"]}],"source":["# To save and push to hub:\n","\n","repo_id = f\"minoosh/bert-clf-biencoder-{loss_fn}\"  \n","\n","save_and_push_to_hub(tr, repo_id)\n","\n","\n","\n","# To load from hub later:\n","\n","#loaded_trainer, loaded_model, loaded_tokenizer = load_from_hub(repo_id)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"vscode":{"interpreter":{"hash":"103de50b6741efac643968c186d1b1abfce3e31cc37d5e54d8bda505b68efb83"}}},"nbformat":4,"nbformat_minor":4}
