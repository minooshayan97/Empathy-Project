{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-11-02T23:03:32.794140Z","iopub.status.busy":"2024-11-02T23:03:32.793371Z","iopub.status.idle":"2024-11-02T23:03:45.985619Z","shell.execute_reply":"2024-11-02T23:03:45.984277Z","shell.execute_reply.started":"2024-11-02T23:03:32.794088Z"},"id":"TY_JJkPo58St","trusted":true},"outputs":[],"source":["!pip install -q transformers datasets wandb"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-11-02T23:03:45.988336Z","iopub.status.busy":"2024-11-02T23:03:45.987931Z","iopub.status.idle":"2024-11-02T23:03:47.626797Z","shell.execute_reply":"2024-11-02T23:03:47.625772Z","shell.execute_reply.started":"2024-11-02T23:03:45.988290Z"},"id":"Um2NZlL_58Su","outputId":"b1856c19-93fd-4bb2-d42b-81fa5df9af2e","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: fineGrained).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["!huggingface-cli login --token "]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":208},"execution":{"iopub.execute_input":"2024-11-02T23:03:57.940271Z","iopub.status.busy":"2024-11-02T23:03:57.939895Z","iopub.status.idle":"2024-11-02T23:05:21.437478Z","shell.execute_reply":"2024-11-02T23:05:21.436503Z","shell.execute_reply.started":"2024-11-02T23:03:57.940235Z"},"id":"XTnEOW4N58Sv","outputId":"b8306239-f2ac-4096-e4be-0e322208d567","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3154b0562e084015ba9138fee16672d4","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112901844444422, max=1.0…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241102_230512-ydhzi830</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/minoosh/bert-crossencoder-classification/runs/ydhzi830' target=\"_blank\">exalted-microwave-92</a></strong> to <a href='https://wandb.ai/minoosh/bert-crossencoder-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/minoosh/bert-crossencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-classification</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/minoosh/bert-crossencoder-classification/runs/ydhzi830' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-classification/runs/ydhzi830</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3aef825da2d34beb8785281c200fbd7f","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/588 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"60cd2e32ae894324a433b274dfc3da55","version_major":2,"version_minor":0},"text/plain":["train-00000-of-00001.parquet:   0%|          | 0.00/660k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"badae393129e497fb658fa14436e0936","version_major":2,"version_minor":0},"text/plain":["test-00000-of-00001.parquet:   0%|          | 0.00/100k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2dfd48c1e1a1488484cc7c0dbb337177","version_major":2,"version_minor":0},"text/plain":["validation-00000-of-00001.parquet:   0%|          | 0.00/88.5k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bdd4108bf0b843229eceb235299332c9","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/2467 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"893838a6a5ad48b4b96671bb75586501","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/308 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a4763760eb74199aa0acca2feb41780","version_major":2,"version_minor":0},"text/plain":["Generating validation split:   0%|          | 0/309 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"258cf75749d241e592a6ca1adf1930c1","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66ff2d77048845ebb386568a01b01308","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1389e541140f4ad6874d28e52f93b54b","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0ede06549d645cc80a2406a8213f437","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"665847cbf4194fb4809d01ccf6fe934f","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2467 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b477a3121ba84b8193f58d558232686a","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/308 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"160a4c7e75a44bc7955d6e5a4a0ccddc","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/309 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import torch\n","\n","from datasets import load_dataset\n","\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, TrainingArguments, Trainer\n","\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","import wandb\n","\n","\n","\n","# Initialize wandb\n","\n","wandb.init(\n","\n","    project=\"bert-crossencoder-classification\"\n","\n",")\n","\n","\n","\n","# Load dataset\n","\n","dataset = load_dataset(\"minoosh/EPITOME_pairs\")\n","\n","\n","\n","# Initialize the tokenizer and model for cross-encoder setup\n","\n","model_name = \"google-bert/bert-base-uncased\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","\n","\n","# Preprocess data for the cross-encoder model by concatenating text1 and text2 with [SEP]\n","\n","def preprocess_function(examples):\n","\n","    # Concatenate both texts with a [SEP] token in between\n","\n","    encodings = tokenizer(examples['text1'], examples['text2'], truncation=True, padding=True, max_length=512)\n","\n","    encodings['labels'] = examples['label']  # Add labels\n","\n","    return encodings\n","\n","\n","\n","# Apply tokenization\n","\n","tokenized_train = dataset['train'].map(preprocess_function, batched=True)\n","\n","tokenized_test = dataset['test'].map(preprocess_function, batched=True)\n","\n","tokenized_val = dataset['validation'].map(preprocess_function, batched=True)\n","\n","\n","\n","# Set format for PyTorch\n","\n","tokenized_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n","\n","tokenized_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n","\n","tokenized_val.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n","\n","\n","\n","# Define compute_metrics function for classification evaluation\n","\n","def compute_metrics(eval_pred):\n","\n","    predictions, labels = eval_pred\n","\n","    preds = predictions.argmax(axis=1)\n","\n","    accuracy = accuracy_score(labels, preds)\n","\n","    precision = precision_score(labels, preds, average=\"weighted\")\n","\n","    recall = recall_score(labels, preds, average=\"weighted\")\n","\n","    f1 = f1_score(labels, preds, average=\"weighted\")\n","\n","    return {\n","\n","        \"accuracy\": accuracy,\n","\n","        \"precision\": precision,\n","\n","        \"recall\": recall,\n","\n","        \"f1\": f1\n","\n","    }\n","\n","\n","\n","# Custom Cross-Encoder model class for classification\n","\n","class CrossEncoderModel(torch.nn.Module):\n","\n","    def __init__(self, model_name, num_classes=4, loss_fn=\"cross_entropy\"):\n","\n","        super(CrossEncoderModel, self).__init__()\n","\n","        # Load model config\n","\n","        self.config = AutoConfig.from_pretrained(model_name, num_labels=num_classes)\n","\n","        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, config=self.config)\n","\n","        self.loss_fn = loss_fn\n","\n","\n","\n","    def forward(self, input_ids, attention_mask, labels=None):\n","\n","        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n","\n","        logits = outputs.logits  # Output logits for classification\n","\n","\n","\n","        loss = None\n","\n","        if labels is not None:\n","\n","            if self.loss_fn == \"cross_entropy\":\n","\n","                loss_fct = torch.nn.CrossEntropyLoss()  # Use CrossEntropyLoss for classification\n","\n","                loss = loss_fct(logits, labels)\n","\n","            elif self.loss_fn == \"focal_loss\":\n","\n","                # Focal loss implementation for handling class imbalance\n","\n","                alpha = 0.25\n","\n","                gamma = 2.0\n","\n","                ce_loss = torch.nn.CrossEntropyLoss(reduction=\"none\")(logits, labels)\n","\n","                pt = torch.exp(-ce_loss)  # Probability of the true class\n","\n","                loss = (alpha * (1 - pt) ** gamma * ce_loss).mean()\n","\n","            elif self.loss_fn == \"kl_divergence\":\n","\n","                # KL Divergence for soft-label classification\n","\n","                kl_div = torch.nn.KLDivLoss(reduction=\"batchmean\")\n","\n","                soft_labels = torch.nn.functional.one_hot(labels, num_classes=self.config.num_labels).float()\n","\n","                log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n","\n","                loss = kl_div(log_probs, soft_labels)\n","\n","            else:\n","\n","                raise ValueError(f\"Unsupported loss function: {self.loss_fn}\")\n","\n","\n","\n","        return {\"loss\": loss, \"logits\": logits}\n","\n","\n","# Function to initialize and train the cross-encoder model\n","\n","def train_crossencoder(loss_fn):\n","\n","    model = CrossEncoderModel(model_name=model_name, loss_fn=loss_fn)\n","\n","\n","\n","    # Set up TrainingArguments\n","\n","    training_args = TrainingArguments(\n","\n","        output_dir=f\"./output/TTTTempathy-crossencoder-{loss_fn}\",\n","\n","        evaluation_strategy=\"epoch\",\n","\n","        logging_dir='./logs',\n","\n","        logging_steps=10,\n","\n","        per_device_train_batch_size=wandb.config['batch_size'],\n","\n","        per_device_eval_batch_size=wandb.config['batch_size'],\n","\n","        num_train_epochs=wandb.config['epochs'],\n","\n","        warmup_steps=100,\n","\n","        learning_rate=wandb.config['learning_rate'],\n","\n","        weight_decay=0.01,\n","\n","        report_to=\"wandb\",\n","\n","        save_strategy=\"epoch\",\n","\n","        load_best_model_at_end=True,\n","\n","        push_to_hub=True,\n","\n","        save_total_limit=2\n","\n","    )\n","\n","\n","\n","    # Initialize Trainer\n","\n","    trainer = Trainer(\n","\n","        model=model,\n","\n","        args=training_args,\n","\n","        train_dataset=tokenized_train,\n","\n","        eval_dataset=tokenized_val,\n","\n","        tokenizer=tokenizer,\n","\n","        compute_metrics=compute_metrics\n","\n","    )\n","\n","\n","\n","    # Train the model\n","\n","    trainer.train()\n","\n","\n","\n","    # Evaluate the model on the test set\n","\n","    trainer.evaluate(tokenized_test)\n","\n","\n","\n","    #trainer.model.save_pretrained(f\"./output/TTTTempathy-crossencoder-{loss_fn}\")\n","\n","\n","\n","    # Save and push the model to the Hugging Face Hub\n","\n","    #trainer.save_model(f\"./output/TTTTempathy-crossencoder-{loss_fn}\")\n","\n","    #trainer.push_to_hub(f\"minoosh/TTTTempathy-crossencoder-{loss_fn}\")\n","\n","\n","\n","    # End the wandb run\n","\n","    wandb.finish()\n","\n","    return trainer"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.execute_input":"2024-11-02T23:05:21.577486Z","iopub.status.busy":"2024-11-02T23:05:21.577141Z","iopub.status.idle":"2024-11-02T23:12:05.147565Z","shell.execute_reply":"2024-11-02T23:12:05.146845Z","shell.execute_reply.started":"2024-11-02T23:05:21.577444Z"},"id":"DATap4of58Sw","outputId":"0f50d7ce-234a-48ec-95cb-c5f0f4d90f7a","trusted":true},"outputs":[{"data":{"text/html":["Finishing last run (ID:ydhzi830) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"11ef0610f718410f9a317f3f3433019c","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.016 MB of 0.016 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">exalted-microwave-92</strong> at: <a href='https://wandb.ai/minoosh/bert-crossencoder-classification/runs/ydhzi830' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-classification/runs/ydhzi830</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-crossencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241102_230512-ydhzi830/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:ydhzi830). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241102_230521-kklpohg4</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/minoosh/bert-crossencoder-classification/runs/kklpohg4' target=\"_blank\">bert-crossencoder-classification-cross_entropy</a></strong> to <a href='https://wandb.ai/minoosh/bert-crossencoder-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/minoosh/bert-crossencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-classification</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/minoosh/bert-crossencoder-classification/runs/kklpohg4' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-classification/runs/kklpohg4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"122ac144bebc408094c3a78953fd5692","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='234' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [234/234 06:23, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.223600</td>\n","      <td>1.136467</td>\n","      <td>0.517799</td>\n","      <td>0.525199</td>\n","      <td>0.517799</td>\n","      <td>0.457086</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.009400</td>\n","      <td>0.998384</td>\n","      <td>0.579288</td>\n","      <td>0.574253</td>\n","      <td>0.579288</td>\n","      <td>0.563826</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.878000</td>\n","      <td>0.955802</td>\n","      <td>0.598706</td>\n","      <td>0.589249</td>\n","      <td>0.598706</td>\n","      <td>0.587973</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f13e71d34b94a6fb28c46b7b619649c","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.029 MB of 0.029 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆█▇</td></tr><tr><td>eval/f1</td><td>▁▇██</td></tr><tr><td>eval/loss</td><td>█▃▁▃</td></tr><tr><td>eval/precision</td><td>▁▆██</td></tr><tr><td>eval/recall</td><td>▁▆█▇</td></tr><tr><td>eval/runtime</td><td>▆█▆▁</td></tr><tr><td>eval/samples_per_second</td><td>▃▁▃█</td></tr><tr><td>eval/steps_per_second</td><td>▃▁▃█</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▂▅▁▂▁▃▄▄▃▄▃▇▅▆▂▃▃▄█▆▃▄▄</td></tr><tr><td>train/learning_rate</td><td>▂▂▃▄▄▅▆▇▇█▇▇▆▆▅▅▄▄▃▃▂▂▁</td></tr><tr><td>train/loss</td><td>█▇▇▇▇▆▆▆▅▅▄▅▃▄▃▃▂▃▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.59091</td></tr><tr><td>eval/f1</td><td>0.58041</td></tr><tr><td>eval/loss</td><td>1.01562</td></tr><tr><td>eval/precision</td><td>0.59106</td></tr><tr><td>eval/recall</td><td>0.59091</td></tr><tr><td>eval/runtime</td><td>5.1342</td></tr><tr><td>eval/samples_per_second</td><td>59.99</td></tr><tr><td>eval/steps_per_second</td><td>1.948</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>234</td></tr><tr><td>train/grad_norm</td><td>6.97934</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.878</td></tr><tr><td>train_loss</td><td>1.10608</td></tr><tr><td>train_runtime</td><td>386.1097</td></tr><tr><td>train_samples_per_second</td><td>19.168</td></tr><tr><td>train_steps_per_second</td><td>0.606</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">bert-crossencoder-classification-cross_entropy</strong> at: <a href='https://wandb.ai/minoosh/bert-crossencoder-classification/runs/kklpohg4' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-classification/runs/kklpohg4</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-crossencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241102_230521-kklpohg4/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Specify list of loss functions to try\n","\n","loss_functions = [\"cross_entropy\", \"focal_loss\", \"kl_divergence\"]\n","\n","\n","\n","loss_fn = loss_functions[0]  # Change to desired loss function\n","\n","wandb.init(project=\"bert-crossencoder-classification\", name=f\"bert-crossencoder-classification-{loss_fn}\", config={\"epochs\": 3, \"batch_size\": 16, \"learning_rate\": 2e-5})\n","\n","tr = train_crossencoder(loss_fn)\n","\n","wandb.finish()"]},{"cell_type":"markdown","metadata":{},"source":["# prediction"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T23:20:28.808368Z","iopub.status.busy":"2024-11-02T23:20:28.807990Z","iopub.status.idle":"2024-11-02T23:20:28.815474Z","shell.execute_reply":"2024-11-02T23:20:28.814492Z","shell.execute_reply.started":"2024-11-02T23:20:28.808332Z"},"trusted":true},"outputs":[],"source":["def compute_metrics2(preds, labels):\n","\n","    #predictions, labels = eval_pred\n","\n","    #preds = predictions.argmax(axis=1)\n","\n","    accuracy = accuracy_score(labels, preds)\n","\n","    precision = precision_score(labels, preds, average=\"weighted\")\n","\n","    recall = recall_score(labels, preds, average=\"weighted\")\n","\n","    f1 = f1_score(labels, preds, average=\"weighted\")\n","\n","    return {\n","\n","        \"accuracy\": accuracy,\n","\n","        \"precision\": precision,\n","\n","        \"recall\": recall,\n","\n","        \"f1\": f1\n","\n","    }"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T23:26:59.995641Z","iopub.status.busy":"2024-11-02T23:26:59.995198Z","iopub.status.idle":"2024-11-02T23:27:02.755988Z","shell.execute_reply":"2024-11-02T23:27:02.754967Z","shell.execute_reply.started":"2024-11-02T23:26:59.995602Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d03e6b735f474cb38374636c7e98bef0","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2467 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7888fe91eb8948a0b267fc3d996a3c32","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/308 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d60affda51b340008e98e1f6f7939c35","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/309 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Load dataset\n","\n","dataset = load_dataset(\"minoosh/EPITOME_pairs\")\n","\n","\n","\n","tokenizer = tr.tokenizer\n","\n","\n","\n","# Preprocess data for the cross-encoder model by concatenating text1 and text2 with [SEP]\n","\n","def preprocess_function(examples):\n","\n","    # Concatenate both texts with a [SEP] token in between\n","\n","    encodings = tokenizer(examples['text1'], examples['text2'], truncation=True, padding=True, max_length=512)\n","\n","    encodings['labels'] = examples['label']  # Add labels\n","\n","    return encodings\n","\n","\n","\n","# Apply tokenization\n","\n","tokenized_train = dataset['train'].map(preprocess_function, batched=True)\n","\n","tokenized_test = dataset['test'].map(preprocess_function, batched=True)\n","\n","tokenized_val = dataset['validation'].map(preprocess_function, batched=True)\n","\n","\n","\n","# Set format for PyTorch\n","\n","tokenized_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n","\n","tokenized_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n","\n","tokenized_val.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T23:27:06.412171Z","iopub.status.busy":"2024-11-02T23:27:06.411180Z","iopub.status.idle":"2024-11-02T23:27:14.392659Z","shell.execute_reply":"2024-11-02T23:27:14.391608Z","shell.execute_reply.started":"2024-11-02T23:27:06.412127Z"},"trusted":true},"outputs":[{"data":{"text/html":["Finishing last run (ID:7pwzqcf9) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d1464d565a844a49372fe5231c57f7b","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.016 MB of 0.016 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">fast-moon-4</strong> at: <a href='https://wandb.ai/minoosh/uncategorized/runs/7pwzqcf9' target=\"_blank\">https://wandb.ai/minoosh/uncategorized/runs/7pwzqcf9</a><br/> View project at: <a href='https://wandb.ai/minoosh/uncategorized' target=\"_blank\">https://wandb.ai/minoosh/uncategorized</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241102_232601-7pwzqcf9/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:7pwzqcf9). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241102_232706-wswr91rx</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/minoosh/uncategorized/runs/wswr91rx' target=\"_blank\">revived-surf-5</a></strong> to <a href='https://wandb.ai/minoosh/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/minoosh/uncategorized' target=\"_blank\">https://wandb.ai/minoosh/uncategorized</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/minoosh/uncategorized/runs/wswr91rx' target=\"_blank\">https://wandb.ai/minoosh/uncategorized/runs/wswr91rx</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["PredictionOutput(predictions=array([[-0.45503232, -1.0947487 ,  1.9089473 , -0.24962118],\n","       [ 0.80990165,  0.97936547, -0.61233205, -0.8243233 ],\n","       [ 0.36533967, -0.05923421,  0.59694076, -0.83456737],\n","       ...,\n","       [ 0.98752993, -0.4267132 ,  1.1035475 , -1.1273757 ],\n","       [-0.8679848 , -1.2133474 ,  1.8939304 ,  0.01474193],\n","       [ 0.9232104 , -0.33683768,  1.0794307 , -1.1720507 ]],\n","      dtype=float32), label_ids=array([0, 1, 0, 0, 1, 2, 0, 3, 2, 2, 0, 0, 2, 2, 2, 1, 0, 1, 1, 2, 0, 3,\n","       2, 1, 3, 0, 0, 2, 3, 2, 2, 2, 0, 0, 2, 2, 2, 3, 2, 3, 1, 2, 2, 3,\n","       0, 1, 2, 2, 0, 2, 2, 3, 3, 2, 1, 3, 0, 1, 3, 2, 2, 1, 2, 2, 2, 0,\n","       0, 2, 2, 1, 0, 0, 2, 2, 2, 1, 2, 3, 2, 1, 0, 1, 0, 2, 0, 2, 2, 1,\n","       2, 2, 2, 0, 2, 1, 0, 2, 0, 1, 2, 0, 3, 2, 2, 1, 3, 2, 1, 1, 2, 3,\n","       3, 3, 3, 2, 1, 2, 0, 3, 0, 3, 3, 3, 3, 2, 2, 0, 0, 2, 1, 2, 0, 0,\n","       2, 0, 0, 2, 2, 2, 3, 0, 2, 2, 2, 2, 3, 2, 2, 0, 2, 2, 2, 2, 2, 2,\n","       0, 2, 2, 2, 2, 1, 3, 0, 1, 0, 1, 0, 0, 1, 3, 3, 3, 0, 3, 2, 1, 0,\n","       1, 3, 1, 2, 3, 2, 3, 2, 1, 2, 2, 2, 0, 1, 0, 2, 2, 2, 1, 1, 1, 2,\n","       2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 0, 2, 0, 3, 2, 0, 2, 2, 1, 3, 0, 2,\n","       3, 1, 0, 2, 1, 2, 1, 2, 0, 3, 2, 2, 3, 1, 2, 0, 1, 0, 0, 0, 2, 0,\n","       1, 0, 2, 1, 2, 0, 2, 2, 2, 2, 2, 1, 2, 3, 0, 2, 3, 3, 0, 1, 2, 3,\n","       0, 0, 2, 2, 3, 2, 2, 0, 1, 3, 2, 3, 2, 2, 3, 1, 2, 1, 2, 2, 1, 0,\n","       0, 0, 0, 2, 3, 1, 3, 0, 0, 1, 0, 1, 3, 3, 2, 1, 1, 2, 0, 0, 2, 1]), metrics={'test_loss': 1.015624761581421, 'test_accuracy': 0.5909090909090909, 'test_precision': 0.5910610076886423, 'test_recall': 0.5909090909090909, 'test_f1': 0.5804054100567049, 'test_runtime': 5.1424, 'test_samples_per_second': 59.894, 'test_steps_per_second': 1.945})"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init()\n","a = tr.predict(tokenized_test)\n","a"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T23:27:19.265900Z","iopub.status.busy":"2024-11-02T23:27:19.264940Z","iopub.status.idle":"2024-11-02T23:27:19.282182Z","shell.execute_reply":"2024-11-02T23:27:19.281228Z","shell.execute_reply.started":"2024-11-02T23:27:19.265855Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'accuracy': 0.5909090909090909,\n"," 'precision': 0.6299192354580286,\n"," 'recall': 0.5909090909090909,\n"," 'f1': 0.6014127717614769}"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["actual_labels = tokenized_test['labels'].tolist()\n","predicted_classes = list(a.predictions.argmax(axis=1))\n","res = compute_metrics2(actual_labels, predicted_classes)\n","\n","res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3DxapER-EcpE"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Predictions from saved model"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T23:42:50.221666Z","iopub.status.busy":"2024-11-02T23:42:50.220497Z","iopub.status.idle":"2024-11-02T23:42:52.522468Z","shell.execute_reply":"2024-11-02T23:42:52.519779Z","shell.execute_reply.started":"2024-11-02T23:42:50.221614Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd29acd844c6436eaf8ea63185e56f16","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/905 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"OSError","evalue":"Can't load tokenizer for 'minoosh/tmp_trainer'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'minoosh/tmp_trainer' is the correct path to a directory containing all relevant files for a BertTokenizerFast tokenizer.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[72], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminoosh/EPITOME_pairs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminoosh/tmp_trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Preprocess data for the cross-encoder model by concatenating text1 and text2 with [SEP]\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_function\u001b[39m(examples):\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Concatenate both texts with a [SEP] token in between\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:926\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m tokenizer_class_py, tokenizer_class_fast \u001b[38;5;241m=\u001b[39m TOKENIZER_MAPPING[\u001b[38;5;28mtype\u001b[39m(config)]\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_fast \u001b[38;5;129;01mand\u001b[39;00m (use_fast \u001b[38;5;129;01mor\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 926\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class_fast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2200\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2197\u001b[0m \u001b[38;5;66;03m# If one passes a GGUF file path to `gguf_file` there is no need for this check as the tokenizer will be\u001b[39;00m\n\u001b[1;32m   2198\u001b[0m \u001b[38;5;66;03m# loaded directly from the GGUF file.\u001b[39;00m\n\u001b[1;32m   2199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(full_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m full_file_name \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m gguf_file:\n\u001b[0;32m-> 2200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load tokenizer for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2203\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2204\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining all relevant files for a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2205\u001b[0m     )\n\u001b[1;32m   2207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_id, file_path \u001b[38;5;129;01min\u001b[39;00m vocab_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files:\n","\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'minoosh/tmp_trainer'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'minoosh/tmp_trainer' is the correct path to a directory containing all relevant files for a BertTokenizerFast tokenizer."]}],"source":["# Load dataset\n","\n","dataset = load_dataset(\"minoosh/EPITOME_pairs\")\n","\n","\n","model_name = \"minoosh/tmp_trainer\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","\n","# Preprocess data for the cross-encoder model by concatenating text1 and text2 with [SEP]\n","\n","def preprocess_function(examples):\n","\n","    # Concatenate both texts with a [SEP] token in between\n","\n","    encodings = tokenizer(examples['text1'], examples['text2'], truncation=True, padding=True, max_length=512)\n","\n","    encodings['labels'] = examples['label']  # Add labels\n","\n","    return encodings\n","\n","\n","\n","# Apply tokenization\n","\n","tokenized_train = dataset['train'].map(preprocess_function, batched=True)\n","\n","tokenized_test = dataset['test'].map(preprocess_function, batched=True)\n","\n","tokenized_val = dataset['validation'].map(preprocess_function, batched=True)\n","\n","\n","\n","# Set format for PyTorch\n","\n","tokenized_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n","\n","tokenized_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n","\n","tokenized_val.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T23:43:01.816332Z","iopub.status.busy":"2024-11-02T23:43:01.815950Z","iopub.status.idle":"2024-11-02T23:43:12.949011Z","shell.execute_reply":"2024-11-02T23:43:12.947483Z","shell.execute_reply.started":"2024-11-02T23:43:01.816296Z"},"id":"G6gFGCh1Ecs8","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d030ecc563541888ed9a3c132ff3a6f","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Load the model and tokenizer\n","\n","model_name = \"minoosh/tmp_trainer\"\n","\n","model = AutoModelForSequenceClassification.from_pretrained(model_name)\n","\n","# Initialize the Trainer\n","\n","trainer = Trainer(model=model)"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T23:43:12.977810Z","iopub.status.busy":"2024-11-02T23:43:12.977512Z","iopub.status.idle":"2024-11-02T23:43:18.170755Z","shell.execute_reply":"2024-11-02T23:43:18.169913Z","shell.execute_reply.started":"2024-11-02T23:43:12.977778Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["b = trainer.predict(tokenized_test)"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T23:43:23.699748Z","iopub.status.busy":"2024-11-02T23:43:23.698815Z","iopub.status.idle":"2024-11-02T23:43:23.715901Z","shell.execute_reply":"2024-11-02T23:43:23.714975Z","shell.execute_reply.started":"2024-11-02T23:43:23.699703Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'accuracy': 0.5909090909090909,\n"," 'precision': 0.6299192354580286,\n"," 'recall': 0.5909090909090909,\n"," 'f1': 0.6014127717614769}"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["actual_labels = tokenized_test['labels'].tolist()\n","predicted_classes = list(b.predictions.argmax(axis=1))\n","res = compute_metrics2(actual_labels, predicted_classes)\n","\n","res"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T23:31:24.093297Z","iopub.status.busy":"2024-11-02T23:31:24.092913Z","iopub.status.idle":"2024-11-02T23:31:24.112518Z","shell.execute_reply":"2024-11-02T23:31:24.111681Z","shell.execute_reply.started":"2024-11-02T23:31:24.093258Z"},"id":"1_Yc7GSnEcvI","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"data":{"text/plain":["{'accuracy': 0.16233766233766234,\n"," 'precision': 0.9967532467532467,\n"," 'recall': 0.16233766233766234,\n"," 'f1': 0.2792025901269598}"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["actual_labels = tokenized_test['labels'].tolist()\n","predicted_classes = list(b.predictions.argmax(axis=1))\n","res = compute_metrics2(actual_labels, predicted_classes)\n","\n","res"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# This line saves moo"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T23:39:07.249747Z","iopub.status.busy":"2024-11-02T23:39:07.249322Z","iopub.status.idle":"2024-11-02T23:39:08.442513Z","shell.execute_reply":"2024-11-02T23:39:08.441544Z","shell.execute_reply.started":"2024-11-02T23:39:07.249696Z"},"trusted":true},"outputs":[],"source":["tr.model.model.save_pretrained(\"moo\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trainer.push_to_hub() #push 'moo' to hub"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["# saved from disk"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T23:39:52.918633Z","iopub.status.busy":"2024-11-02T23:39:52.918216Z","iopub.status.idle":"2024-11-02T23:39:55.839744Z","shell.execute_reply":"2024-11-02T23:39:55.838733Z","shell.execute_reply.started":"2024-11-02T23:39:52.918596Z"},"id":"krmrWPNnDOrY","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6033dde9c787449d81baddac80e12e8f","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2467 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"288bd39c8a954e6e8c4f6bcb3c346132","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/308 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e303a79de22648ac8fa290cf6f199af6","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/309 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Load dataset\n","\n","dataset = load_dataset(\"minoosh/EPITOME_pairs\")\n","\n","\n","model_name = \"moo\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","\n","# Preprocess data for the cross-encoder model by concatenating text1 and text2 with [SEP]\n","\n","def preprocess_function(examples):\n","\n","    # Concatenate both texts with a [SEP] token in between\n","\n","    encodings = tokenizer(examples['text1'], examples['text2'], truncation=True, padding=True, max_length=512)\n","\n","    encodings['labels'] = examples['label']  # Add labels\n","\n","    return encodings\n","\n","\n","\n","# Apply tokenization\n","\n","tokenized_train = dataset['train'].map(preprocess_function, batched=True)\n","\n","tokenized_test = dataset['test'].map(preprocess_function, batched=True)\n","\n","tokenized_val = dataset['validation'].map(preprocess_function, batched=True)\n","\n","\n","\n","# Set format for PyTorch\n","\n","tokenized_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n","\n","tokenized_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n","\n","tokenized_val.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T23:40:04.398510Z","iopub.status.busy":"2024-11-02T23:40:04.397572Z","iopub.status.idle":"2024-11-02T23:40:05.068479Z","shell.execute_reply":"2024-11-02T23:40:05.067403Z","shell.execute_reply.started":"2024-11-02T23:40:04.398456Z"},"trusted":true},"outputs":[],"source":["# Load the model and tokenizer\n","\n","model_name = \"moo\"\n","\n","model = AutoModelForSequenceClassification.from_pretrained(model_name)\n","\n","# Initialize the Trainer\n","\n","trainer = Trainer(model=model)"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T23:40:53.609270Z","iopub.status.busy":"2024-11-02T23:40:53.608842Z","iopub.status.idle":"2024-11-02T23:40:58.802618Z","shell.execute_reply":"2024-11-02T23:40:58.801539Z","shell.execute_reply.started":"2024-11-02T23:40:53.609229Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["c = trainer.predict(tokenized_test)"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T23:41:28.944944Z","iopub.status.busy":"2024-11-02T23:41:28.944249Z","iopub.status.idle":"2024-11-02T23:41:28.952604Z","shell.execute_reply":"2024-11-02T23:41:28.951524Z","shell.execute_reply.started":"2024-11-02T23:41:28.944901Z"},"trusted":true},"outputs":[{"data":{"text/plain":["PredictionOutput(predictions=array([[-0.45503157, -1.0947485 ,  1.9089471 , -0.24962176],\n","       [ 0.80990183,  0.97936547, -0.6123324 , -0.8243238 ],\n","       [ 0.36533806, -0.05923416,  0.5969407 , -0.83456695],\n","       ...,\n","       [ 0.98752975, -0.42671373,  1.1035484 , -1.1273757 ],\n","       [-0.86798465, -1.2133476 ,  1.8939301 ,  0.01474158],\n","       [ 0.92321026, -0.33683765,  1.0794307 , -1.1720507 ]],\n","      dtype=float32), label_ids=array([0, 1, 0, 0, 1, 2, 0, 3, 2, 2, 0, 0, 2, 2, 2, 1, 0, 1, 1, 2, 0, 3,\n","       2, 1, 3, 0, 0, 2, 3, 2, 2, 2, 0, 0, 2, 2, 2, 3, 2, 3, 1, 2, 2, 3,\n","       0, 1, 2, 2, 0, 2, 2, 3, 3, 2, 1, 3, 0, 1, 3, 2, 2, 1, 2, 2, 2, 0,\n","       0, 2, 2, 1, 0, 0, 2, 2, 2, 1, 2, 3, 2, 1, 0, 1, 0, 2, 0, 2, 2, 1,\n","       2, 2, 2, 0, 2, 1, 0, 2, 0, 1, 2, 0, 3, 2, 2, 1, 3, 2, 1, 1, 2, 3,\n","       3, 3, 3, 2, 1, 2, 0, 3, 0, 3, 3, 3, 3, 2, 2, 0, 0, 2, 1, 2, 0, 0,\n","       2, 0, 0, 2, 2, 2, 3, 0, 2, 2, 2, 2, 3, 2, 2, 0, 2, 2, 2, 2, 2, 2,\n","       0, 2, 2, 2, 2, 1, 3, 0, 1, 0, 1, 0, 0, 1, 3, 3, 3, 0, 3, 2, 1, 0,\n","       1, 3, 1, 2, 3, 2, 3, 2, 1, 2, 2, 2, 0, 1, 0, 2, 2, 2, 1, 1, 1, 2,\n","       2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 0, 2, 0, 3, 2, 0, 2, 2, 1, 3, 0, 2,\n","       3, 1, 0, 2, 1, 2, 1, 2, 0, 3, 2, 2, 3, 1, 2, 0, 1, 0, 0, 0, 2, 0,\n","       1, 0, 2, 1, 2, 0, 2, 2, 2, 2, 2, 1, 2, 3, 0, 2, 3, 3, 0, 1, 2, 3,\n","       0, 0, 2, 2, 3, 2, 2, 0, 1, 3, 2, 3, 2, 2, 3, 1, 2, 1, 2, 2, 1, 0,\n","       0, 0, 0, 2, 3, 1, 3, 0, 0, 1, 0, 1, 3, 3, 2, 1, 1, 2, 0, 0, 2, 1]), metrics={'test_loss': 1.015625, 'test_runtime': 5.1658, 'test_samples_per_second': 59.623, 'test_steps_per_second': 3.872})"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["c"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T23:41:41.747029Z","iopub.status.busy":"2024-11-02T23:41:41.746586Z","iopub.status.idle":"2024-11-02T23:41:41.768983Z","shell.execute_reply":"2024-11-02T23:41:41.767991Z","shell.execute_reply.started":"2024-11-02T23:41:41.746984Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'accuracy': 0.5909090909090909,\n"," 'precision': 0.6299192354580286,\n"," 'recall': 0.5909090909090909,\n"," 'f1': 0.6014127717614769}"]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["actual_labels = tokenized_test['labels'].tolist()\n","predicted_classes = list(c.predictions.argmax(axis=1))\n","res = compute_metrics2(actual_labels, predicted_classes)\n","\n","res"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2024-11-02T23:42:07.441721Z","iopub.status.busy":"2024-11-02T23:42:07.441275Z","iopub.status.idle":"2024-11-02T23:42:20.167711Z","shell.execute_reply":"2024-11-02T23:42:20.166621Z","shell.execute_reply.started":"2024-11-02T23:42:07.441679Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5cc19cbe33f34469b613f6387732694a","version_major":2,"version_minor":0},"text/plain":["Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1d0253de0fa43699f6919bf30e23763","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f011d9bf7a9f4bc18f3d6aca48c6ea04","version_major":2,"version_minor":0},"text/plain":["training_args.bin:   0%|          | 0.00/5.24k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/minoosh/tmp_trainer/commit/271cb78d69d72f989b362e7f4e74900e4003b2dd', commit_message='End of training', commit_description='', oid='271cb78d69d72f989b362e7f4e74900e4003b2dd', pr_url=None, repo_url=RepoUrl('https://huggingface.co/minoosh/tmp_trainer', endpoint='https://huggingface.co', repo_type='model', repo_id='minoosh/tmp_trainer'), pr_revision=None, pr_num=None)"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["trainer.push_to_hub()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
