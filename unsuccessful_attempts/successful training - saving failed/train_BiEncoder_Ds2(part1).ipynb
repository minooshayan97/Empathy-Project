{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-10-25T00:39:18.320104Z",
          "iopub.status.busy": "2024-10-25T00:39:18.319121Z",
          "iopub.status.idle": "2024-10-25T00:39:31.821148Z",
          "shell.execute_reply": "2024-10-25T00:39:31.820026Z",
          "shell.execute_reply.started": "2024-10-25T00:39:18.320043Z"
        },
        "id": "aP-2A1gCkqsq",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-25T00:39:31.824505Z",
          "iopub.status.busy": "2024-10-25T00:39:31.823712Z",
          "iopub.status.idle": "2024-10-25T00:39:33.487470Z",
          "shell.execute_reply": "2024-10-25T00:39:33.486251Z",
          "shell.execute_reply.started": "2024-10-25T00:39:31.824457Z"
        },
        "id": "0VA7Mpf1ktNB",
        "outputId": "5c2f7184-99ba-4d96-8eee-d65a33d72a77",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login --token hf_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "execution": {
          "iopub.execute_input": "2024-10-25T00:39:33.489825Z",
          "iopub.status.busy": "2024-10-25T00:39:33.489433Z",
          "iopub.status.idle": "2024-10-25T00:45:06.748842Z",
          "shell.execute_reply": "2024-10-25T00:45:06.748094Z",
          "shell.execute_reply.started": "2024-10-25T00:39:33.489790Z"
        },
        "id": "tsK_q1ackMS0",
        "outputId": "cc73bc0e-86b3-47c0-88e4-6d8485fc8136",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminooshayan97\u001b[0m (\u001b[33mminoosh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241025_181305-0sx4e3i7</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/minoosh/bert-biencoder-empathy/runs/0sx4e3i7' target=\"_blank\">cerulean-firefly-21</a></strong> to <a href='https://wandb.ai/minoosh/bert-biencoder-empathy' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/minoosh/bert-biencoder-empathy' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/minoosh/bert-biencoder-empathy/runs/0sx4e3i7' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy/runs/0sx4e3i7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModel, AutoTokenizer, TrainingArguments, Trainer\n",
        "from transformers import BertConfig, BertModel\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "import wandb\n",
        "import numpy as np\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(\n",
        "    project=\"bert-biencoder-empathy\"\n",
        ")\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"minoosh/EPITOME_pairs2\")\n",
        "\n",
        "# Initialize bi-encoder model (e.g., BERT as a sentence encoder)\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "base_model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize both text1 and text2 independently\n",
        "def preprocess_function(examples):\n",
        "    text1_encodings = tokenizer(examples['text1'], truncation=True, padding=True, max_length=512)\n",
        "    text2_encodings = tokenizer(examples['text2'], truncation=True, padding=True, max_length=512)\n",
        "    return {\n",
        "        'input_ids_text1': text1_encodings['input_ids'],\n",
        "        'attention_mask_text1': text1_encodings['attention_mask'],\n",
        "        'input_ids_text2': text2_encodings['input_ids'],\n",
        "        'attention_mask_text2': text2_encodings['attention_mask'],\n",
        "        'labels': examples['label']\n",
        "    }\n",
        "\n",
        "# Apply tokenization\n",
        "tokenized_train = dataset['train'].map(preprocess_function, batched=True)\n",
        "tokenized_test = dataset['test'].map(preprocess_function, batched=True)\n",
        "tokenized_val = dataset['validation'].map(preprocess_function, batched=True)\n",
        "\n",
        "# Remove unnecessary columns and set format for PyTorch\n",
        "columns_to_keep = ['input_ids_text1', 'attention_mask_text1', 'input_ids_text2', 'attention_mask_text2', 'labels']\n",
        "tokenized_train.set_format(type='torch', columns=columns_to_keep)\n",
        "tokenized_test.set_format(type='torch', columns=columns_to_keep)\n",
        "tokenized_val.set_format(type='torch', columns=columns_to_keep)\n",
        "\n",
        "# Define a custom collator to handle text1 and text2 encoding\n",
        "class BiEncoderCollator:\n",
        "    def __call__(self, features):\n",
        "        # Pad each batch dynamically\n",
        "        batch = {\n",
        "            'input_ids_text1': torch.nn.utils.rnn.pad_sequence(\n",
        "                [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n",
        "            'attention_mask_text1': torch.nn.utils.rnn.pad_sequence(\n",
        "                [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n",
        "            'input_ids_text2': torch.nn.utils.rnn.pad_sequence(\n",
        "                [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n",
        "            'attention_mask_text2': torch.nn.utils.rnn.pad_sequence(\n",
        "                [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n",
        "            'labels': torch.tensor([f['labels'] for f in features], dtype=torch.float)\n",
        "        }\n",
        "        '''batch = {\n",
        "            'input_ids_text1': torch.stack([f['input_ids_text1'] for f in features]),\n",
        "            'attention_mask_text1': torch.stack([f['attention_mask_text1'] for f in features]),\n",
        "            'input_ids_text2': torch.stack([f['input_ids_text2'] for f in features]),\n",
        "            'attention_mask_text2': torch.stack([f['attention_mask_text2'] for f in features]),\n",
        "            'labels': torch.tensor([f['labels'] for f in features], dtype=torch.float)\n",
        "        }'''\n",
        "        return batch\n",
        "\n",
        "collator = BiEncoderCollator()\n",
        "\n",
        "# Define the compute_metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = predictions.squeeze()\n",
        "    labels = labels.squeeze()\n",
        "\n",
        "    mse = mean_squared_error(labels, predictions)\n",
        "    mae = mean_absolute_error(labels, predictions)\n",
        "    pearson_corr, _ = pearsonr(predictions, labels)\n",
        "    spearman_corr, _ = spearmanr(predictions, labels)\n",
        "    cosine_sim = torch.nn.functional.cosine_similarity(torch.tensor(predictions), torch.tensor(labels), dim=0).mean().item()\n",
        "\n",
        "    return {\n",
        "        \"mse\": mse,\n",
        "        \"mae\": mae,\n",
        "        \"pearson_corr\": pearson_corr,\n",
        "        \"spearman_corr\": spearman_corr,\n",
        "        \"cosine_sim\": cosine_sim  # Optional metric for similarity tasks\n",
        "    }\n",
        "\n",
        "# Define a custom BiEncoder model\n",
        "class BiEncoderModel(torch.nn.Module):\n",
        "    def __init__(self, base_model, config=None, loss_fn=\"mse\"):\n",
        "        super(BiEncoderModel, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.cos = torch.nn.CosineSimilarity(dim=1)\n",
        "        self.loss_fn = loss_fn\n",
        "        self.config = config\n",
        "\n",
        "    def forward(self, input_ids_text1, attention_mask_text1, input_ids_text2, attention_mask_text2, labels=None):\n",
        "        # Encode text1 and text2 separately\n",
        "        outputs_text1 = self.base_model(input_ids_text1, attention_mask=attention_mask_text1)\n",
        "        outputs_text2 = self.base_model(input_ids_text2, attention_mask=attention_mask_text2)\n",
        "\n",
        "        # Extract [CLS] token embeddings (first token)\n",
        "        cls_embedding_text1 = outputs_text1.last_hidden_state[:, 0, :]\n",
        "        cls_embedding_text2 = outputs_text2.last_hidden_state[:, 0, :]\n",
        "\n",
        "        # Calculate cosine similarity between the two embeddings\n",
        "        cos_sim = self.cos(cls_embedding_text1, cls_embedding_text2)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if self.loss_fn == \"mse\":\n",
        "                loss_fct = torch.nn.MSELoss()  # Mean Squared Error Loss\n",
        "            elif self.loss_fn == \"mae\":\n",
        "                loss_fct = torch.nn.L1Loss()  # Mean Absolute Error Loss\n",
        "            elif self.loss_fn == \"contrastive\":\n",
        "                loss_fct = self.contrastive_loss\n",
        "            elif self.loss_fn == \"cosine_embedding\":\n",
        "                loss_fct = torch.nn.CosineEmbeddingLoss()  # Cosine Embedding Loss\n",
        "\n",
        "            if self.loss_fn == \"cosine_embedding\":\n",
        "                labels_cosine = 2 * (labels > 0.5).float() - 1  # Convert labels to binary for cosine embedding loss\n",
        "                loss = loss_fct(cls_embedding_text1, cls_embedding_text2, labels_cosine)\n",
        "            else:\n",
        "                loss = loss_fct(cos_sim, labels)\n",
        "\n",
        "        return {\"loss\": loss, \"logits\": cos_sim}\n",
        "\n",
        "    def contrastive_loss(self, cos_sim, labels, margin=0.5):\n",
        "        loss = torch.mean((1 - labels) * torch.pow(cos_sim, 2) + labels * torch.pow(torch.clamp(margin - cos_sim, min=0.0), 2))\n",
        "        return loss\n",
        "\n",
        "# Initialize the Bi-Encoder model with a specific loss function\n",
        "def train_biencoder(loss_fn):\n",
        "    # Load pre-trained BERT configuration and model\n",
        "    config = BertConfig.from_pretrained(model_name)\n",
        "    bert_model = BertModel.from_pretrained(model_name)\n",
        "\n",
        "    # Initialize your custom BiEncoderModel with the BERT model and config\n",
        "    bi_encoder_model = BiEncoderModel(base_model=bert_model, config=config, loss_fn=loss_fn)\n",
        "    #bi_encoder_model = BiEncoderModel(base_model, loss_fn)\n",
        "\n",
        "    # Define TrainingArguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./output/empathy-biencoder-{loss_fn}_Ds2\",\n",
        "        evaluation_strategy=\"epoch\",    # Evaluate at the end of each epoch\n",
        "        logging_dir='./logs',           # Directory for logs\n",
        "        logging_steps=10,               # Log every 10 steps\n",
        "        per_device_train_batch_size=wandb.config['batch_size'],\n",
        "        per_device_eval_batch_size=wandb.config['batch_size'],\n",
        "        num_train_epochs=wandb.config['epochs'],\n",
        "        warmup_steps=100,\n",
        "        learning_rate=wandb.config['learning_rate'],\n",
        "        weight_decay=0.01,\n",
        "        report_to=\"wandb\",\n",
        "        save_strategy=\"epoch\",          # Save checkpoints at the end of each epoch\n",
        "        load_best_model_at_end=True,\n",
        "        push_to_hub=True,\n",
        "        save_total_limit=2              # Keep only the 2 most recent checkpoints\n",
        "    )\n",
        "\n",
        "    # Define the Trainer\n",
        "    trainer = Trainer(\n",
        "        model=bi_encoder_model,             # Custom BiEncoder model\n",
        "        args=training_args,                 # Training arguments\n",
        "        train_dataset=tokenized_train,      # Training dataset\n",
        "        eval_dataset=tokenized_val,         # Validation dataset\n",
        "        data_collator=collator,             # Custom collator for handling bi-encoder inputs\n",
        "        compute_metrics=compute_metrics     # Function to compute metrics\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    trainer.evaluate(tokenized_test)\n",
        "\n",
        "    # Save the model to Hugging Face Hub\n",
        "    trainer.save_model(f\"./output/empathy-biencoder-{loss_fn}_Ds2\")\n",
        "    trainer.push_to_hub(f\"minoosh/empathy-biencoder-{loss_fn}_Ds2\")\n",
        "\n",
        "    # Finish wandb run\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "execution": {
          "iopub.execute_input": "2024-10-25T00:45:06.750833Z",
          "iopub.status.busy": "2024-10-25T00:45:06.750530Z",
          "iopub.status.idle": "2024-10-25T00:53:29.736651Z",
          "shell.execute_reply": "2024-10-25T00:53:29.735750Z",
          "shell.execute_reply.started": "2024-10-25T00:45:06.750800Z"
        },
        "id": "mOvgS4uevnnz",
        "outputId": "b178e9cf-209a-4677-8013-8bdd9ed27030",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:0sx4e3i7) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">cerulean-firefly-21</strong> at: <a href='https://wandb.ai/minoosh/bert-biencoder-empathy/runs/0sx4e3i7' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy/runs/0sx4e3i7</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-biencoder-empathy' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241025_181305-0sx4e3i7/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:0sx4e3i7). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241025_181310-dmpgu8n0</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/minoosh/bert-biencoder-empathy/runs/dmpgu8n0' target=\"_blank\">bert-biencoder-empathy-mse_Ds2</a></strong> to <a href='https://wandb.ai/minoosh/bert-biencoder-empathy' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/minoosh/bert-biencoder-empathy' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/minoosh/bert-biencoder-empathy/runs/dmpgu8n0' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy/runs/dmpgu8n0</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "<ipython-input-3-134491438b9c>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='775' max='775' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [775/775 30:24, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Mse</th>\n",
              "      <th>Mae</th>\n",
              "      <th>Pearson Corr</th>\n",
              "      <th>Spearman Corr</th>\n",
              "      <th>Cosine Sim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.029600</td>\n",
              "      <td>0.035439</td>\n",
              "      <td>0.035439</td>\n",
              "      <td>0.151431</td>\n",
              "      <td>0.549467</td>\n",
              "      <td>0.554085</td>\n",
              "      <td>0.876148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.020700</td>\n",
              "      <td>0.033078</td>\n",
              "      <td>0.033078</td>\n",
              "      <td>0.145318</td>\n",
              "      <td>0.571682</td>\n",
              "      <td>0.570007</td>\n",
              "      <td>0.881709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.016100</td>\n",
              "      <td>0.029965</td>\n",
              "      <td>0.029965</td>\n",
              "      <td>0.140373</td>\n",
              "      <td>0.567467</td>\n",
              "      <td>0.564673</td>\n",
              "      <td>0.877430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.011900</td>\n",
              "      <td>0.032782</td>\n",
              "      <td>0.032782</td>\n",
              "      <td>0.145690</td>\n",
              "      <td>0.566645</td>\n",
              "      <td>0.557560</td>\n",
              "      <td>0.878716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.009000</td>\n",
              "      <td>0.033197</td>\n",
              "      <td>0.033197</td>\n",
              "      <td>0.147239</td>\n",
              "      <td>0.569198</td>\n",
              "      <td>0.562387</td>\n",
              "      <td>0.878575</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-134491438b9c>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "<ipython-input-3-134491438b9c>:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n",
            "<ipython-input-3-134491438b9c>:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:14]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/cosine_sim</td><td>‚ñÅ‚ñà‚ñÉ‚ñÑ‚ñÑ‚ñÑ</td></tr><tr><td>eval/loss</td><td>‚ñà‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÅ</td></tr><tr><td>eval/mae</td><td>‚ñà‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÅ</td></tr><tr><td>eval/mse</td><td>‚ñà‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñÅ</td></tr><tr><td>eval/pearson_corr</td><td>‚ñÅ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñà</td></tr><tr><td>eval/runtime</td><td>‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñà</td></tr><tr><td>eval/samples_per_second</td><td>‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÅ</td></tr><tr><td>eval/spearman_corr</td><td>‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñà</td></tr><tr><td>eval/steps_per_second</td><td>‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñà‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ</td></tr><tr><td>train/learning_rate</td><td>‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/cosine_sim</td><td>0.87866</td></tr><tr><td>eval/loss</td><td>0.02989</td></tr><tr><td>eval/mae</td><td>0.13558</td></tr><tr><td>eval/mse</td><td>0.02989</td></tr><tr><td>eval/pearson_corr</td><td>0.58575</td></tr><tr><td>eval/runtime</td><td>15.2168</td></tr><tr><td>eval/samples_per_second</td><td>20.241</td></tr><tr><td>eval/spearman_corr</td><td>0.59531</td></tr><tr><td>eval/steps_per_second</td><td>1.314</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>775</td></tr><tr><td>train/grad_norm</td><td>0.54461</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.009</td></tr><tr><td>train_loss</td><td>0.02365</td></tr><tr><td>train_runtime</td><td>1829.6527</td></tr><tr><td>train_samples_per_second</td><td>6.742</td></tr><tr><td>train_steps_per_second</td><td>0.424</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">bert-biencoder-empathy-mse_Ds2</strong> at: <a href='https://wandb.ai/minoosh/bert-biencoder-empathy/runs/dmpgu8n0' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy/runs/dmpgu8n0</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-biencoder-empathy' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241025_181310-dmpgu8n0/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train bi-encoder with different loss functions\n",
        "loss_functions = [\"mse\", \"mae\", \"contrastive\", \"cosine_embedding\"]\n",
        "loss_fn = loss_functions[0]\n",
        "wandb.init(project=\"bert-biencoder-empathy\", name=f\"bert-biencoder-empathy-{loss_fn}_Ds2\", config={\"epochs\": 5, \"batch_size\": 16, \"learning_rate\": 2e-5})\n",
        "train_biencoder(loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAlDcG3EwciE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30787,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
