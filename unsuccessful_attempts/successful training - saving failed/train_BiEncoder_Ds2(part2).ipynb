{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T19:01:07.370314Z","iopub.status.busy":"2024-10-25T19:01:07.369981Z","iopub.status.idle":"2024-10-25T19:01:22.377897Z","shell.execute_reply":"2024-10-25T19:01:22.376662Z","shell.execute_reply.started":"2024-10-25T19:01:07.370276Z"},"id":"aP-2A1gCkqsq","trusted":true},"outputs":[],"source":["!pip install -q transformers datasets wandb"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-10-25T19:01:22.380198Z","iopub.status.busy":"2024-10-25T19:01:22.379879Z","iopub.status.idle":"2024-10-25T19:01:24.256591Z","shell.execute_reply":"2024-10-25T19:01:24.255400Z","shell.execute_reply.started":"2024-10-25T19:01:22.380163Z"},"id":"0VA7Mpf1ktNB","outputId":"5c2f7184-99ba-4d96-8eee-d65a33d72a77","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: fineGrained).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["!huggingface-cli login --token hf_"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"execution":{"iopub.execute_input":"2024-10-25T19:01:24.258997Z","iopub.status.busy":"2024-10-25T19:01:24.258583Z","iopub.status.idle":"2024-10-25T19:02:13.862408Z","shell.execute_reply":"2024-10-25T19:02:13.861629Z","shell.execute_reply.started":"2024-10-25T19:01:24.258949Z"},"id":"tsK_q1ackMS0","outputId":"cc73bc0e-86b3-47c0-88e4-6d8485fc8136","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"311f2d117f69497cac16d54eedb434b8","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113091077778057, max=1.0…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241025_190201-vn71fviz</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/minoosh/bert-biencoder-empathy/runs/vn71fviz' target=\"_blank\">rosy-plant-28</a></strong> to <a href='https://wandb.ai/minoosh/bert-biencoder-empathy' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/minoosh/bert-biencoder-empathy' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/minoosh/bert-biencoder-empathy/runs/vn71fviz' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy/runs/vn71fviz</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa6cff0408734296a999e66cf7793eeb","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/589 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ccfc750f719041cc82c3aff8facac6e9","version_major":2,"version_minor":0},"text/plain":["train-00000-of-00001.parquet:   0%|          | 0.00/660k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21dfa881989e4e41ae8d5287e31e12fc","version_major":2,"version_minor":0},"text/plain":["test-00000-of-00001.parquet:   0%|          | 0.00/100k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ee25dc2ef2a47b884f12b86ab7c4edf","version_major":2,"version_minor":0},"text/plain":["validation-00000-of-00001.parquet:   0%|          | 0.00/88.6k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76597ac1b2744132a6db886295414859","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/2467 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"df12638edcd246969daaed2ebf9489b1","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/308 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"00a890a496c340fc806d0faddbf5af61","version_major":2,"version_minor":0},"text/plain":["Generating validation split:   0%|          | 0/309 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2645d1c5f2f45a0b8fda52649aaab0f","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b7245c7bd67747e3a9f7ced58e5cccd9","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b251353eefa44ce98bcffad61deed932","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d6535b19455b4906889744efcd3fd686","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b7ccfa0af464da5a5cf2e5003eeaf35","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3cdb543cc98e42ebb2cfb76f6aeb74c7","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2467 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7632f5d0d0a342f6bb15bbd4e1ee2208","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/308 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"abedf17b3ce54783abcb40fc42d00c74","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/309 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import torch\n","from datasets import load_dataset\n","from transformers import AutoModel, AutoTokenizer, TrainingArguments, Trainer\n","from transformers import BertConfig, BertModel\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from scipy.stats import pearsonr, spearmanr\n","import wandb\n","import numpy as np\n","\n","# Initialize wandb\n","wandb.init(\n","    project=\"bert-biencoder-empathy\"\n",")\n","\n","# Load dataset\n","dataset = load_dataset(\"minoosh/EPITOME_pairs2\")\n","\n","# Initialize bi-encoder model (e.g., BERT as a sentence encoder)\n","model_name = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","base_model = AutoModel.from_pretrained(model_name)\n","\n","# Tokenize both text1 and text2 independently\n","def preprocess_function(examples):\n","    text1_encodings = tokenizer(examples['text1'], truncation=True, padding=True, max_length=512)\n","    text2_encodings = tokenizer(examples['text2'], truncation=True, padding=True, max_length=512)\n","    return {\n","        'input_ids_text1': text1_encodings['input_ids'],\n","        'attention_mask_text1': text1_encodings['attention_mask'],\n","        'input_ids_text2': text2_encodings['input_ids'],\n","        'attention_mask_text2': text2_encodings['attention_mask'],\n","        'labels': examples['label']\n","    }\n","\n","# Apply tokenization\n","tokenized_train = dataset['train'].map(preprocess_function, batched=True)\n","tokenized_test = dataset['test'].map(preprocess_function, batched=True)\n","tokenized_val = dataset['validation'].map(preprocess_function, batched=True)\n","\n","# Remove unnecessary columns and set format for PyTorch\n","columns_to_keep = ['input_ids_text1', 'attention_mask_text1', 'input_ids_text2', 'attention_mask_text2', 'labels']\n","tokenized_train.set_format(type='torch', columns=columns_to_keep)\n","tokenized_test.set_format(type='torch', columns=columns_to_keep)\n","tokenized_val.set_format(type='torch', columns=columns_to_keep)\n","\n","# Define a custom collator to handle text1 and text2 encoding\n","class BiEncoderCollator:\n","    def __call__(self, features):\n","        # Pad each batch dynamically\n","        batch = {\n","            'input_ids_text1': torch.nn.utils.rnn.pad_sequence(\n","                [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","            'attention_mask_text1': torch.nn.utils.rnn.pad_sequence(\n","                [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","            'input_ids_text2': torch.nn.utils.rnn.pad_sequence(\n","                [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","            'attention_mask_text2': torch.nn.utils.rnn.pad_sequence(\n","                [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","            'labels': torch.tensor([f['labels'] for f in features], dtype=torch.float)\n","        }\n","        '''batch = {\n","            'input_ids_text1': torch.stack([f['input_ids_text1'] for f in features]),\n","            'attention_mask_text1': torch.stack([f['attention_mask_text1'] for f in features]),\n","            'input_ids_text2': torch.stack([f['input_ids_text2'] for f in features]),\n","            'attention_mask_text2': torch.stack([f['attention_mask_text2'] for f in features]),\n","            'labels': torch.tensor([f['labels'] for f in features], dtype=torch.float)\n","        }'''\n","        return batch\n","\n","collator = BiEncoderCollator()\n","\n","# Define the compute_metrics function\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = predictions.squeeze()\n","    labels = labels.squeeze()\n","\n","    mse = mean_squared_error(labels, predictions)\n","    mae = mean_absolute_error(labels, predictions)\n","    pearson_corr, _ = pearsonr(predictions, labels)\n","    spearman_corr, _ = spearmanr(predictions, labels)\n","    cosine_sim = torch.nn.functional.cosine_similarity(torch.tensor(predictions), torch.tensor(labels), dim=0).mean().item()\n","\n","    return {\n","        \"mse\": mse,\n","        \"mae\": mae,\n","        \"pearson_corr\": pearson_corr,\n","        \"spearman_corr\": spearman_corr,\n","        \"cosine_sim\": cosine_sim  # Optional metric for similarity tasks\n","    }\n","\n","# Define a custom BiEncoder model\n","class BiEncoderModel(torch.nn.Module):\n","    def __init__(self, base_model, config=None, loss_fn=\"mse\"):\n","        super(BiEncoderModel, self).__init__()\n","        self.base_model = base_model\n","        self.cos = torch.nn.CosineSimilarity(dim=1)\n","        self.loss_fn = loss_fn\n","        self.config = config\n","\n","    def forward(self, input_ids_text1, attention_mask_text1, input_ids_text2, attention_mask_text2, labels=None):\n","        # Encode text1 and text2 separately\n","        outputs_text1 = self.base_model(input_ids_text1, attention_mask=attention_mask_text1)\n","        outputs_text2 = self.base_model(input_ids_text2, attention_mask=attention_mask_text2)\n","\n","        # Extract [CLS] token embeddings (first token)\n","        cls_embedding_text1 = outputs_text1.last_hidden_state[:, 0, :]\n","        cls_embedding_text2 = outputs_text2.last_hidden_state[:, 0, :]\n","\n","        # Calculate cosine similarity between the two embeddings\n","        cos_sim = self.cos(cls_embedding_text1, cls_embedding_text2)\n","\n","        loss = None\n","        if labels is not None:\n","            if self.loss_fn == \"mse\":\n","                loss_fct = torch.nn.MSELoss()  # Mean Squared Error Loss\n","            elif self.loss_fn == \"mae\":\n","                loss_fct = torch.nn.L1Loss()  # Mean Absolute Error Loss\n","            elif self.loss_fn == \"contrastive\":\n","                loss_fct = self.contrastive_loss\n","            elif self.loss_fn == \"cosine_embedding\":\n","                loss_fct = torch.nn.CosineEmbeddingLoss()  # Cosine Embedding Loss\n","\n","            if self.loss_fn == \"cosine_embedding\":\n","                labels_cosine = 2 * (labels > 0.5).float() - 1  # Convert labels to binary for cosine embedding loss\n","                loss = loss_fct(cls_embedding_text1, cls_embedding_text2, labels_cosine)\n","            else:\n","                loss = loss_fct(cos_sim, labels)\n","\n","        return {\"loss\": loss, \"logits\": cos_sim}\n","\n","    def contrastive_loss(self, cos_sim, labels, margin=0.5):\n","        loss = torch.mean((1 - labels) * torch.pow(cos_sim, 2) + labels * torch.pow(torch.clamp(margin - cos_sim, min=0.0), 2))\n","        return loss\n","\n","# Initialize the Bi-Encoder model with a specific loss function\n","def train_biencoder(loss_fn):\n","    # Load pre-trained BERT configuration and model\n","    config = BertConfig.from_pretrained(model_name)\n","    bert_model = BertModel.from_pretrained(model_name)\n","\n","    # Initialize your custom BiEncoderModel with the BERT model and config\n","    bi_encoder_model = BiEncoderModel(base_model=bert_model, config=config, loss_fn=loss_fn)\n","    #bi_encoder_model = BiEncoderModel(base_model, loss_fn)\n","\n","    # Define TrainingArguments\n","    training_args = TrainingArguments(\n","        output_dir=f\"./output/empathy-biencoder-{loss_fn}_Ds2\",\n","        evaluation_strategy=\"epoch\",    # Evaluate at the end of each epoch\n","        logging_dir='./logs',           # Directory for logs\n","        logging_steps=10,               # Log every 10 steps\n","        per_device_train_batch_size=wandb.config['batch_size'],\n","        per_device_eval_batch_size=wandb.config['batch_size'],\n","        num_train_epochs=wandb.config['epochs'],\n","        warmup_steps=100,\n","        learning_rate=wandb.config['learning_rate'],\n","        weight_decay=0.01,\n","        report_to=\"wandb\",\n","        save_strategy=\"epoch\",          # Save checkpoints at the end of each epoch\n","        load_best_model_at_end=True,\n","        push_to_hub=True,\n","        save_total_limit=2              # Keep only the 2 most recent checkpoints\n","    )\n","\n","    # Define the Trainer\n","    trainer = Trainer(\n","        model=bi_encoder_model,             # Custom BiEncoder model\n","        args=training_args,                 # Training arguments\n","        train_dataset=tokenized_train,      # Training dataset\n","        eval_dataset=tokenized_val,         # Validation dataset\n","        data_collator=collator,             # Custom collator for handling bi-encoder inputs\n","        compute_metrics=compute_metrics     # Function to compute metrics\n","    )\n","\n","    # Train the model\n","    trainer.train()\n","\n","    # Evaluate on the test set\n","    trainer.evaluate(tokenized_test)\n","\n","    # Save the model to Hugging Face Hub\n","    trainer.save_model(f\"./output/empathy-biencoder-{loss_fn}_Ds2\")\n","    trainer.push_to_hub(f\"minoosh/empathy-biencoder-{loss_fn}_Ds2\")\n","\n","    # Finish wandb run\n","    wandb.finish()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T19:02:13.865053Z","iopub.status.busy":"2024-10-25T19:02:13.864550Z","iopub.status.idle":"2024-10-25T19:18:03.388080Z","shell.execute_reply":"2024-10-25T19:18:03.387221Z","shell.execute_reply.started":"2024-10-25T19:02:13.865003Z"},"trusted":true},"outputs":[{"data":{"text/html":["Finishing last run (ID:vn71fviz) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.016 MB of 0.016 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">rosy-plant-28</strong> at: <a href='https://wandb.ai/minoosh/bert-biencoder-empathy/runs/vn71fviz' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy/runs/vn71fviz</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-biencoder-empathy' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241025_190201-vn71fviz/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:vn71fviz). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241025_190213-qiy5ycy6</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/minoosh/bert-biencoder-empathy/runs/qiy5ycy6' target=\"_blank\">bert-biencoder-empathy-mae_Ds2</a></strong> to <a href='https://wandb.ai/minoosh/bert-biencoder-empathy' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/minoosh/bert-biencoder-empathy' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/minoosh/bert-biencoder-empathy/runs/qiy5ycy6' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy/runs/qiy5ycy6</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='390' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [390/390 15:14, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Mse</th>\n","      <th>Mae</th>\n","      <th>Pearson Corr</th>\n","      <th>Spearman Corr</th>\n","      <th>Cosine Sim</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.153100</td>\n","      <td>0.159352</td>\n","      <td>0.041124</td>\n","      <td>0.159252</td>\n","      <td>0.352507</td>\n","      <td>0.360193</td>\n","      <td>0.840801</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.127200</td>\n","      <td>0.152880</td>\n","      <td>0.036222</td>\n","      <td>0.152746</td>\n","      <td>0.516035</td>\n","      <td>0.516792</td>\n","      <td>0.868463</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.101500</td>\n","      <td>0.139206</td>\n","      <td>0.029945</td>\n","      <td>0.139116</td>\n","      <td>0.558192</td>\n","      <td>0.562953</td>\n","      <td>0.874459</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.098300</td>\n","      <td>0.148448</td>\n","      <td>0.034032</td>\n","      <td>0.148342</td>\n","      <td>0.564564</td>\n","      <td>0.567231</td>\n","      <td>0.878567</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.086500</td>\n","      <td>0.147851</td>\n","      <td>0.033814</td>\n","      <td>0.147728</td>\n","      <td>0.564612</td>\n","      <td>0.569424</td>\n","      <td>0.877721</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10/10 00:06]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["No files have been modified since last commit. Skipping to prevent empty commit.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.038 MB of 0.038 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/cosine_sim</td><td>▁▆▇██▇</td></tr><tr><td>eval/loss</td><td>█▆▃▅▅▁</td></tr><tr><td>eval/mae</td><td>█▆▃▅▅▁</td></tr><tr><td>eval/mse</td><td>█▅▁▄▃▁</td></tr><tr><td>eval/pearson_corr</td><td>▁▆████</td></tr><tr><td>eval/runtime</td><td>▁▂▂▂█▅</td></tr><tr><td>eval/samples_per_second</td><td>█▇▇▇▁▄</td></tr><tr><td>eval/spearman_corr</td><td>▁▆████</td></tr><tr><td>eval/steps_per_second</td><td>█▇▇▇▁▄</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▄▂▂▂▂▂▂▁▂▁▁▁▂▂▂▁▁▁▁▁▁▂▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁█</td></tr><tr><td>train/learning_rate</td><td>▂▂▃▄▅▅▆▇▇███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▅▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/cosine_sim</td><td>0.87191</td></tr><tr><td>eval/loss</td><td>0.13309</td></tr><tr><td>eval/mae</td><td>0.13309</td></tr><tr><td>eval/mse</td><td>0.02984</td></tr><tr><td>eval/pearson_corr</td><td>0.56024</td></tr><tr><td>eval/runtime</td><td>7.4083</td></tr><tr><td>eval/samples_per_second</td><td>41.575</td></tr><tr><td>eval/spearman_corr</td><td>0.56971</td></tr><tr><td>eval/steps_per_second</td><td>1.35</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>390</td></tr><tr><td>train/grad_norm</td><td>5.71564</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>0.0865</td></tr><tr><td>train_loss</td><td>0.1332</td></tr><tr><td>train_runtime</td><td>918.6471</td></tr><tr><td>train_samples_per_second</td><td>13.427</td></tr><tr><td>train_steps_per_second</td><td>0.425</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">bert-biencoder-empathy-mae_Ds2</strong> at: <a href='https://wandb.ai/minoosh/bert-biencoder-empathy/runs/qiy5ycy6' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy/runs/qiy5ycy6</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-biencoder-empathy' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241025_190213-qiy5ycy6/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Train bi-encoder with different loss functions\n","loss_functions = [\"mse\", \"mae\", \"contrastive\", \"cosine_embedding\"]\n","loss_fn = loss_functions[1]\n","wandb.init(project=\"bert-biencoder-empathy\", name=f\"bert-biencoder-empathy-{loss_fn}_Ds2\", config={\"epochs\": 5, \"batch_size\": 16, \"learning_rate\": 2e-5})\n","train_biencoder(loss_fn)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T18:24:01.420710Z","iopub.status.busy":"2024-10-25T18:24:01.419547Z","iopub.status.idle":"2024-10-25T18:40:11.926871Z","shell.execute_reply":"2024-10-25T18:40:11.926003Z","shell.execute_reply.started":"2024-10-25T18:24:01.420639Z"},"id":"C3DZ1S2ayTNd","trusted":true},"outputs":[{"data":{"text/html":["Finishing last run (ID:ot2n6erd) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">bert-biencoder-empathy-contrastive_Ds2</strong> at: <a href='https://wandb.ai/minoosh/bert-biencoder-empathy/runs/ot2n6erd' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy/runs/ot2n6erd</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-biencoder-empathy' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241025_182354-ot2n6erd/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:ot2n6erd). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241025_182401-axry8kbc</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/minoosh/bert-biencoder-empathy/runs/axry8kbc' target=\"_blank\">bert-biencoder-empathy-contrastive_Ds2</a></strong> to <a href='https://wandb.ai/minoosh/bert-biencoder-empathy' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/minoosh/bert-biencoder-empathy' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/minoosh/bert-biencoder-empathy/runs/axry8kbc' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy/runs/axry8kbc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='390' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [390/390 15:38, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Mse</th>\n","      <th>Mae</th>\n","      <th>Pearson Corr</th>\n","      <th>Spearman Corr</th>\n","      <th>Cosine Sim</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.054000</td>\n","      <td>0.062897</td>\n","      <td>0.042491</td>\n","      <td>0.168469</td>\n","      <td>0.233082</td>\n","      <td>0.253217</td>\n","      <td>0.769336</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.050400</td>\n","      <td>0.055750</td>\n","      <td>0.036857</td>\n","      <td>0.157270</td>\n","      <td>0.360932</td>\n","      <td>0.355529</td>\n","      <td>0.816929</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.048300</td>\n","      <td>0.055407</td>\n","      <td>0.035690</td>\n","      <td>0.155001</td>\n","      <td>0.413554</td>\n","      <td>0.404821</td>\n","      <td>0.824564</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.045200</td>\n","      <td>0.054082</td>\n","      <td>0.035762</td>\n","      <td>0.155291</td>\n","      <td>0.430628</td>\n","      <td>0.423020</td>\n","      <td>0.829136</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.044800</td>\n","      <td>0.053582</td>\n","      <td>0.036198</td>\n","      <td>0.156072</td>\n","      <td>0.433215</td>\n","      <td>0.428420</td>\n","      <td>0.828967</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10/10 00:07]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["No files have been modified since last commit. Skipping to prevent empty commit.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.038 MB of 0.038 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/cosine_sim</td><td>▁▆▇▇▇█</td></tr><tr><td>eval/loss</td><td>█▃▃▂▂▁</td></tr><tr><td>eval/mae</td><td>█▄▄▄▄▁</td></tr><tr><td>eval/mse</td><td>█▃▂▂▃▁</td></tr><tr><td>eval/pearson_corr</td><td>▁▅▇███</td></tr><tr><td>eval/runtime</td><td>▃▃▂▂▁█</td></tr><tr><td>eval/samples_per_second</td><td>▆▇▇▇█▁</td></tr><tr><td>eval/spearman_corr</td><td>▁▄▆▇▇█</td></tr><tr><td>eval/steps_per_second</td><td>▆▆▇▇█▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>█▄▃▃▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>train/learning_rate</td><td>▂▂▃▄▅▅▆▇▇███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/cosine_sim</td><td>0.83856</td></tr><tr><td>eval/loss</td><td>0.05214</td></tr><tr><td>eval/mae</td><td>0.14612</td></tr><tr><td>eval/mse</td><td>0.03394</td></tr><tr><td>eval/pearson_corr</td><td>0.44453</td></tr><tr><td>eval/runtime</td><td>7.8293</td></tr><tr><td>eval/samples_per_second</td><td>39.34</td></tr><tr><td>eval/spearman_corr</td><td>0.46289</td></tr><tr><td>eval/steps_per_second</td><td>1.277</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>390</td></tr><tr><td>train/grad_norm</td><td>0.69192</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>0.0448</td></tr><tr><td>train_loss</td><td>0.06924</td></tr><tr><td>train_runtime</td><td>941.971</td></tr><tr><td>train_samples_per_second</td><td>13.095</td></tr><tr><td>train_steps_per_second</td><td>0.414</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">bert-biencoder-empathy-contrastive_Ds2</strong> at: <a href='https://wandb.ai/minoosh/bert-biencoder-empathy/runs/axry8kbc' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy/runs/axry8kbc</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-biencoder-empathy' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241025_182401-axry8kbc/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Train bi-encoder with different loss functions\n","loss_functions = [\"mse\", \"mae\", \"contrastive\", \"cosine_embedding\"]\n","loss_fn = loss_functions[2]\n","wandb.init(project=\"bert-biencoder-empathy\", name=f\"bert-biencoder-empathy-{loss_fn}_Ds2\", config={\"epochs\": 5, \"batch_size\": 16, \"learning_rate\": 2e-5})\n","train_biencoder(loss_fn)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T18:42:12.802527Z","iopub.status.busy":"2024-10-25T18:42:12.801673Z","iopub.status.idle":"2024-10-25T18:57:52.905020Z","shell.execute_reply":"2024-10-25T18:57:52.904109Z","shell.execute_reply.started":"2024-10-25T18:42:12.802470Z"},"id":"xKA4Fuk7yVr3","trusted":true},"outputs":[{"data":{"text/html":["Finishing last run (ID:4d6e5oof) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.016 MB of 0.016 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">fragrant-glitter-26</strong> at: <a href='https://wandb.ai/minoosh/bert-biencoder-empathy/runs/4d6e5oof' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy/runs/4d6e5oof</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-biencoder-empathy' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241025_184156-4d6e5oof/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:4d6e5oof). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241025_184212-ja3dyeh0</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/minoosh/bert-biencoder-empathy/runs/ja3dyeh0' target=\"_blank\">bert-biencoder-empathy-cosine_embedding_Ds2</a></strong> to <a href='https://wandb.ai/minoosh/bert-biencoder-empathy' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/minoosh/bert-biencoder-empathy' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/minoosh/bert-biencoder-empathy/runs/ja3dyeh0' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy/runs/ja3dyeh0</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='390' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [390/390 15:03, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Mse</th>\n","      <th>Mae</th>\n","      <th>Pearson Corr</th>\n","      <th>Spearman Corr</th>\n","      <th>Cosine Sim</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.100500</td>\n","      <td>0.110309</td>\n","      <td>0.126254</td>\n","      <td>0.295663</td>\n","      <td>0.093024</td>\n","      <td>0.065044</td>\n","      <td>0.109258</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.085200</td>\n","      <td>0.084715</td>\n","      <td>0.134844</td>\n","      <td>0.315290</td>\n","      <td>0.080329</td>\n","      <td>0.092797</td>\n","      <td>-0.075253</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.060300</td>\n","      <td>0.072980</td>\n","      <td>0.143082</td>\n","      <td>0.328031</td>\n","      <td>0.122360</td>\n","      <td>0.102984</td>\n","      <td>-0.172735</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.065500</td>\n","      <td>0.072590</td>\n","      <td>0.132073</td>\n","      <td>0.316032</td>\n","      <td>0.183973</td>\n","      <td>0.182827</td>\n","      <td>-0.091000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.085300</td>\n","      <td>0.071080</td>\n","      <td>0.138098</td>\n","      <td>0.324282</td>\n","      <td>0.184668</td>\n","      <td>0.179811</td>\n","      <td>-0.138900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/3833924472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/3833924472.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10/10 00:06]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["No files have been modified since last commit. Skipping to prevent empty commit.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.038 MB of 0.038 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/cosine_sim</td><td>█▅▃▄▄▁</td></tr><tr><td>eval/loss</td><td>█▃▁▁▁▁</td></tr><tr><td>eval/mae</td><td>▁▅▇▅▇█</td></tr><tr><td>eval/mse</td><td>▁▄▇▃▅█</td></tr><tr><td>eval/pearson_corr</td><td>▂▁▄██▄</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█████▁</td></tr><tr><td>eval/spearman_corr</td><td>▁▃▃██▆</td></tr><tr><td>eval/steps_per_second</td><td>█████▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>▇▅▅▅▅▄▄▅▃▃▂▃▃▃▃▃▂▂▃▂▂▂▂▃▂▁▁▂▂▁▁▁▁▂▁▂▁▂█</td></tr><tr><td>train/learning_rate</td><td>▂▂▃▄▅▅▆▇▇███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▆▄▃▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/cosine_sim</td><td>-0.29085</td></tr><tr><td>eval/loss</td><td>0.07384</td></tr><tr><td>eval/mae</td><td>0.33128</td></tr><tr><td>eval/mse</td><td>0.14586</td></tr><tr><td>eval/pearson_corr</td><td>0.12918</td></tr><tr><td>eval/runtime</td><td>7.7258</td></tr><tr><td>eval/samples_per_second</td><td>39.866</td></tr><tr><td>eval/spearman_corr</td><td>0.15728</td></tr><tr><td>eval/steps_per_second</td><td>1.294</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>390</td></tr><tr><td>train/grad_norm</td><td>3.66335</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>0.0853</td></tr><tr><td>train_loss</td><td>0.12333</td></tr><tr><td>train_runtime</td><td>907.0694</td></tr><tr><td>train_samples_per_second</td><td>13.599</td></tr><tr><td>train_steps_per_second</td><td>0.43</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">bert-biencoder-empathy-cosine_embedding_Ds2</strong> at: <a href='https://wandb.ai/minoosh/bert-biencoder-empathy/runs/ja3dyeh0' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy/runs/ja3dyeh0</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-biencoder-empathy' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-empathy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241025_184212-ja3dyeh0/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Train bi-encoder with different loss functions\n","loss_functions = [\"mse\", \"mae\", \"contrastive\", \"cosine_embedding\"]\n","loss_fn = loss_functions[3]\n","wandb.init(project=\"bert-biencoder-empathy\", name=f\"bert-biencoder-empathy-{loss_fn}_Ds2\", config={\"epochs\": 5, \"batch_size\": 16, \"learning_rate\": 2e-5})\n","train_biencoder(loss_fn)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
