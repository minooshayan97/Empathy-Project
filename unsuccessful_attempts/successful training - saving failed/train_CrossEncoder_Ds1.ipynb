{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gc9HYIktx-Xf"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8rGHu1Ax_o9",
        "outputId": "f1eb139b-c085-45dc-bec8-5416934a7bb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login --token hf_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "K9OHEK-Axx5z",
        "outputId": "5d5e3f87-2b60-4eee-cfa9-55fcef83c5b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminooshayan97\u001b[0m (\u001b[33mminoosh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241030_025609-h9ervi4n</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/minoosh/bert-crossencoder-empathy/runs/h9ervi4n' target=\"_blank\">tricky-coffin-15</a></strong> to <a href='https://wandb.ai/minoosh/bert-crossencoder-empathy' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/minoosh/bert-crossencoder-empathy' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-empathy</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/minoosh/bert-crossencoder-empathy/runs/h9ervi4n' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-empathy/runs/h9ervi4n</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, TrainingArguments, Trainer\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "import wandb\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(\n",
        "    project=\"bert-crossencoder-regression\"\n",
        ")\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"minoosh/Annotated_story_pairs2\")\n",
        "\n",
        "# Initialize the tokenizer and model for cross-encoder setup\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Preprocess data for the cross-encoder model by concatenating text1 and text2 with [SEP]\n",
        "def preprocess_function(examples):\n",
        "    # Concatenate both texts with a [SEP] token in between\n",
        "    encodings = tokenizer(examples['text1'], examples['text2'], truncation=True, padding=True, max_length=512)\n",
        "    encodings['labels'] = examples['label']\n",
        "    return encodings\n",
        "\n",
        "# Apply tokenization\n",
        "tokenized_train = dataset['train'].map(preprocess_function, batched=True)\n",
        "tokenized_test = dataset['test'].map(preprocess_function, batched=True)\n",
        "tokenized_val = dataset['validation'].map(preprocess_function, batched=True)\n",
        "\n",
        "# Set format for PyTorch\n",
        "tokenized_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "tokenized_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "tokenized_val.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "\n",
        "# Define compute_metrics function for regression evaluation\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = predictions.squeeze()\n",
        "    labels = labels.squeeze()\n",
        "\n",
        "    mse = mean_squared_error(labels, predictions)\n",
        "    mae = mean_absolute_error(labels, predictions)\n",
        "    pearson_corr, _ = pearsonr(predictions, labels)\n",
        "    spearman_corr, _ = spearmanr(predictions, labels)\n",
        "    cosine_sim = torch.nn.functional.cosine_similarity(torch.tensor(predictions), torch.tensor(labels), dim=0).mean().item()\n",
        "\n",
        "    return {\n",
        "        \"mse\": mse,\n",
        "        \"mae\": mae,\n",
        "        \"pearson_corr\": pearson_corr,\n",
        "        \"spearman_corr\": spearman_corr,\n",
        "        \"cosine_sim\": cosine_sim  # Optional metric for similarity tasks\n",
        "    }\n",
        "\n",
        "# Custom Cross-Encoder model class with config\n",
        "class CrossEncoderModel(torch.nn.Module):\n",
        "    def __init__(self, model_name, loss_fn=\"mse\"):\n",
        "        super(CrossEncoderModel, self).__init__()\n",
        "        # Load model config\n",
        "        self.config = AutoConfig.from_pretrained(model_name, num_labels=1)  # Specify 1 output for regression\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, config=self.config)\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits.squeeze()  # Output logits for regression\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if self.loss_fn == \"mse\":\n",
        "                loss_fct = torch.nn.MSELoss()\n",
        "            elif self.loss_fn == \"mae\":\n",
        "                loss_fct = torch.nn.L1Loss()\n",
        "            elif self.loss_fn == \"cosine_embedding\":\n",
        "                loss_fct = torch.nn.CosineEmbeddingLoss()\n",
        "                labels_cosine = 2 * (labels > 0.5).float() - 1  # Convert to binary for cosine embedding loss\n",
        "                return loss_fct(logits, labels_cosine)\n",
        "            elif self.loss_fn == \"contrastive\":\n",
        "                loss_fct = self.contrastive_loss\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown loss function: {self.loss_fn}\")\n",
        "\n",
        "            if self.loss_fn == \"cosine_embedding\":\n",
        "                loss = loss_fct(logits, labels_cosine)\n",
        "            else:\n",
        "                loss = loss_fct(logits, labels)\n",
        "\n",
        "        return {\"loss\": loss, \"logits\": logits}\n",
        "\n",
        "    def contrastive_loss(self, logits, labels, margin=0.5):\n",
        "        positive_pairs = labels * torch.pow(1 - logits, 2)  # For similar pairs (y=1)\n",
        "        negative_pairs = (1 - labels) * torch.pow(torch.clamp(margin - logits, min=0.0), 2)  # For dissimilar pairs (y=0)\n",
        "        return torch.mean(positive_pairs + negative_pairs)\n",
        "\n",
        "# Function to initialize and train the cross-encoder model\n",
        "def train_crossencoder(loss_fn):\n",
        "    # Initialize the cross-encoder model with the specified loss function\n",
        "    model = CrossEncoderModel(model_name=model_name, loss_fn=loss_fn)\n",
        "\n",
        "    # Set up TrainingArguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./output/bert-reg-crossencoder-{loss_fn}\",\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=10,\n",
        "        per_device_train_batch_size=wandb.config['batch_size'],\n",
        "        per_device_eval_batch_size=wandb.config['batch_size'],\n",
        "        num_train_epochs=wandb.config['epochs'],\n",
        "        warmup_steps=100,\n",
        "        learning_rate=wandb.config['learning_rate'],\n",
        "        weight_decay=0.01,\n",
        "        report_to=\"wandb\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        push_to_hub=True,\n",
        "        save_total_limit=2\n",
        "    )\n",
        "\n",
        "    # Initialize Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train,\n",
        "        eval_dataset=tokenized_val,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    #trainer.evaluate(tokenized_test)\n",
        "\n",
        "    trainer.model = trainer.model.model\n",
        "\n",
        "    # Save and push the model to the Hugging Face Hub\n",
        "    trainer.save_model(f\"./output/bert-reg-crossencoder-{loss_fn}\")\n",
        "    trainer.push_to_hub(f\"minoosh/bert-reg-crossencoder-{loss_fn}\")\n",
        "\n",
        "    # End the wandb run\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f0269de8be944caba5d9ecb23cbd7277",
            "e3910d7785f34d149acff5c5688e13ef",
            "188d6624e3254f2abfcbe205428a8295",
            "7755d45089884b9ca3d97e93c2d64fb0",
            "5791737dff41454bad28f640716548a9",
            "a4cc687bfef844538098603267e48b5f",
            "940df78c1cc64d33ba14d1d5532fc2dc",
            "a1ac1fb842d043e996321100841a3732",
            "89b0ca65c97e492a9e3fbdc67917f911",
            "dd55d688a6c742dbaa9abac9d4746f33",
            "02a6c4e97cc5411c8b80d2bb8b785173"
          ]
        },
        "id": "Ug6246fIx0zD",
        "outputId": "8a5034f5-3ac6-497d-86ce-cf8181896c02"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:v3ko9pmi) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dreadful-specter-9</strong> at: <a href='https://wandb.ai/minoosh/bert-crossencoder-empathy/runs/v3ko9pmi' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-empathy/runs/v3ko9pmi</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-crossencoder-empathy' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-empathy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241030_021613-v3ko9pmi/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:v3ko9pmi). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241030_021619-skz9cxi3</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/minoosh/bert-crossencoder-empathy/runs/skz9cxi3' target=\"_blank\">bert-crossencoder-empathy-mse</a></strong> to <a href='https://wandb.ai/minoosh/bert-crossencoder-empathy' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/minoosh/bert-crossencoder-empathy' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-empathy</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/minoosh/bert-crossencoder-empathy/runs/skz9cxi3' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-empathy/runs/skz9cxi3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0269de8be944caba5d9ecb23cbd7277",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='287' max='287' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [287/287 10:19, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Mse</th>\n",
              "      <th>Mae</th>\n",
              "      <th>Pearson Corr</th>\n",
              "      <th>Spearman Corr</th>\n",
              "      <th>Cosine Sim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.124000</td>\n",
              "      <td>0.091279</td>\n",
              "      <td>0.091279</td>\n",
              "      <td>0.253694</td>\n",
              "      <td>0.146698</td>\n",
              "      <td>0.133682</td>\n",
              "      <td>0.904111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.098500</td>\n",
              "      <td>0.075166</td>\n",
              "      <td>0.075166</td>\n",
              "      <td>0.224198</td>\n",
              "      <td>0.101012</td>\n",
              "      <td>0.072596</td>\n",
              "      <td>0.901816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.107100</td>\n",
              "      <td>0.071218</td>\n",
              "      <td>0.071218</td>\n",
              "      <td>0.215689</td>\n",
              "      <td>0.228309</td>\n",
              "      <td>0.205325</td>\n",
              "      <td>0.907049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.078500</td>\n",
              "      <td>0.114128</td>\n",
              "      <td>0.114128</td>\n",
              "      <td>0.263189</td>\n",
              "      <td>0.161349</td>\n",
              "      <td>0.126939</td>\n",
              "      <td>0.895736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.077300</td>\n",
              "      <td>0.088915</td>\n",
              "      <td>0.088915</td>\n",
              "      <td>0.240450</td>\n",
              "      <td>0.140914</td>\n",
              "      <td>0.125374</td>\n",
              "      <td>0.880655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.066400</td>\n",
              "      <td>0.091903</td>\n",
              "      <td>0.091903</td>\n",
              "      <td>0.237298</td>\n",
              "      <td>0.228223</td>\n",
              "      <td>0.142802</td>\n",
              "      <td>0.898100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.052300</td>\n",
              "      <td>0.106984</td>\n",
              "      <td>0.106984</td>\n",
              "      <td>0.259456</td>\n",
              "      <td>0.182481</td>\n",
              "      <td>0.131917</td>\n",
              "      <td>0.889660</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/cosine_sim</td><td>▇▇█▅▁▆▃▄</td></tr><tr><td>eval/loss</td><td>▄▂▁█▄▄▇▄</td></tr><tr><td>eval/mae</td><td>▇▂▁█▅▄▇▇</td></tr><tr><td>eval/mse</td><td>▄▂▁█▄▄▇▄</td></tr><tr><td>eval/pearson_corr</td><td>▃▁▆▃▃▆▄█</td></tr><tr><td>eval/runtime</td><td>▁▅▇█▇▆▅▄</td></tr><tr><td>eval/samples_per_second</td><td>█▃▂▁▂▃▄▄</td></tr><tr><td>eval/spearman_corr</td><td>▄▁▇▃▃▄▄█</td></tr><tr><td>eval/steps_per_second</td><td>█▆▅▅▅▆▆▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/grad_norm</td><td>█▅▃▃▁▁▂▂▂▁▂▂▂▁▂▂▂▁▂▂▁▂▁▁▂▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁▂▃▄▄▅▆▇▇██▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▆▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/cosine_sim</td><td>0.8917</td></tr><tr><td>eval/loss</td><td>0.09104</td></tr><tr><td>eval/mae</td><td>0.25734</td></tr><tr><td>eval/mse</td><td>0.09104</td></tr><tr><td>eval/pearson_corr</td><td>0.28519</td></tr><tr><td>eval/runtime</td><td>2.3252</td></tr><tr><td>eval/samples_per_second</td><td>34.406</td></tr><tr><td>eval/spearman_corr</td><td>0.22604</td></tr><tr><td>eval/steps_per_second</td><td>2.15</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>7</td></tr><tr><td>train/global_step</td><td>287</td></tr><tr><td>train/grad_norm</td><td>2.22175</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0523</td></tr><tr><td>train_loss</td><td>0.13758</td></tr><tr><td>train_runtime</td><td>622.5849</td></tr><tr><td>train_samples_per_second</td><td>7.23</td></tr><tr><td>train_steps_per_second</td><td>0.461</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">bert-crossencoder-empathy-mse</strong> at: <a href='https://wandb.ai/minoosh/bert-crossencoder-empathy/runs/skz9cxi3' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-empathy/runs/skz9cxi3</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-crossencoder-empathy' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-empathy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241030_021619-skz9cxi3/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Specify list of loss functions to try\n",
        "loss_functions = [\"mse\", \"mae\", \"contrastive\", \"cosine_embedding\"]\n",
        "\n",
        "loss_fn = loss_functions[0]\n",
        "wandb.init(project=\"bert-crossencoder-regression\", name=f\"bert-crossencoder-{loss_fn}\", config={\"epochs\": 7, \"batch_size\": 16, \"learning_rate\": 2e-5})\n",
        "train_crossencoder(loss_fn)\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.0 (tags/v3.13.0:60403a5, Oct  7 2024, 09:38:07) [MSC v.1941 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "103de50b6741efac643968c186d1b1abfce3e31cc37d5e54d8bda505b68efb83"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02a6c4e97cc5411c8b80d2bb8b785173": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "188d6624e3254f2abfcbe205428a8295": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1ac1fb842d043e996321100841a3732",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89b0ca65c97e492a9e3fbdc67917f911",
            "value": 440449768
          }
        },
        "5791737dff41454bad28f640716548a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7755d45089884b9ca3d97e93c2d64fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd55d688a6c742dbaa9abac9d4746f33",
            "placeholder": "​",
            "style": "IPY_MODEL_02a6c4e97cc5411c8b80d2bb8b785173",
            "value": " 440M/440M [00:02&lt;00:00, 243MB/s]"
          }
        },
        "89b0ca65c97e492a9e3fbdc67917f911": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "940df78c1cc64d33ba14d1d5532fc2dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1ac1fb842d043e996321100841a3732": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4cc687bfef844538098603267e48b5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd55d688a6c742dbaa9abac9d4746f33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3910d7785f34d149acff5c5688e13ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4cc687bfef844538098603267e48b5f",
            "placeholder": "​",
            "style": "IPY_MODEL_940df78c1cc64d33ba14d1d5532fc2dc",
            "value": "model.safetensors: 100%"
          }
        },
        "f0269de8be944caba5d9ecb23cbd7277": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3910d7785f34d149acff5c5688e13ef",
              "IPY_MODEL_188d6624e3254f2abfcbe205428a8295",
              "IPY_MODEL_7755d45089884b9ca3d97e93c2d64fb0"
            ],
            "layout": "IPY_MODEL_5791737dff41454bad28f640716548a9"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
