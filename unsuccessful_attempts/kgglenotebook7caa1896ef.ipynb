{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-11-05T01:13:14.237748Z","iopub.status.busy":"2024-11-05T01:13:14.237125Z","iopub.status.idle":"2024-11-05T01:13:27.316225Z","shell.execute_reply":"2024-11-05T01:13:27.314986Z","shell.execute_reply.started":"2024-11-05T01:13:14.237703Z"},"trusted":true},"outputs":[],"source":["!pip install -q transformers datasets wandb"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T01:13:27.318991Z","iopub.status.busy":"2024-11-05T01:13:27.318607Z","iopub.status.idle":"2024-11-05T01:13:28.950974Z","shell.execute_reply":"2024-11-05T01:13:28.949880Z","shell.execute_reply.started":"2024-11-05T01:13:27.318947Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: fineGrained).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["!huggingface-cli login --token "]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T01:14:06.026450Z","iopub.status.busy":"2024-11-05T01:14:06.026036Z","iopub.status.idle":"2024-11-05T01:14:46.562186Z","shell.execute_reply":"2024-11-05T01:14:46.561319Z","shell.execute_reply.started":"2024-11-05T01:14:06.026409Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0bceeba818284df0b1d5f2994a683aec","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113025866666248, max=1.0…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241105_011435-tmsco4k2</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/minoosh/bert-biencoder-classification/runs/tmsco4k2' target=\"_blank\">dry-dust-36</a></strong> to <a href='https://wandb.ai/minoosh/bert-biencoder-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/minoosh/bert-biencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/minoosh/bert-biencoder-classification/runs/tmsco4k2' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification/runs/tmsco4k2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"02dc657bbad443d892df5367aef3ba5a","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/588 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0539dc517f964dbd8ec1047731b91f7a","version_major":2,"version_minor":0},"text/plain":["train-00000-of-00001.parquet:   0%|          | 0.00/660k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bde76325ce234809b49642eac3e009c7","version_major":2,"version_minor":0},"text/plain":["test-00000-of-00001.parquet:   0%|          | 0.00/100k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3c3db63c220a485d83e33cf5753dc150","version_major":2,"version_minor":0},"text/plain":["validation-00000-of-00001.parquet:   0%|          | 0.00/88.5k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49303e3360214fa0a216a116ecfc2074","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/2467 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c195d36f133e4768bb9d5c8b0b1ff06e","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/308 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e4c6c207851a4c6c8e02ae8421744ef2","version_major":2,"version_minor":0},"text/plain":["Generating validation split:   0%|          | 0/309 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"29061a2a6a58435996bf9c89ae880beb","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6e4da19b48184bb6a981e48aa866954a","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e8b3f04dde0412686ab9c1ef3a6911c","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9c34224c6bd491d802e477b6e6d0afd","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25beedec827d40d4a8c8866190a3e5e1","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b91342aada114d2081862602939242e9","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2467 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"debf136b1fc143c9801b90a83d01cbe5","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/308 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"beb17411615d4d1f95a009f36a99a6a8","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/309 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import torch\n","from datasets import load_dataset\n","from transformers import AutoModel, AutoTokenizer, TrainingArguments, Trainer\n","from transformers import BertConfig, BertModel\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","import wandb\n","import numpy as np\n","\n","# Initialize wandb\n","wandb.init(\n","    project=\"bert-biencoder-classification\"\n",")\n","\n","# Load dataset\n","dataset = load_dataset(\"minoosh/EPITOME_pairs\")\n","\n","# Initialize bi-encoder model (e.g., BERT as a sentence encoder)\n","model_name = \"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","base_model = AutoModel.from_pretrained(model_name)\n","\n","# Tokenize both text1 and text2 independently\n","def preprocess_function(examples):\n","    text1_encodings = tokenizer(examples['text1'], truncation=True, padding=True, max_length=512)\n","    text2_encodings = tokenizer(examples['text2'], truncation=True, padding=True, max_length=512)\n","    return {\n","        'input_ids_text1': text1_encodings['input_ids'],\n","        'attention_mask_text1': text1_encodings['attention_mask'],\n","        'input_ids_text2': text2_encodings['input_ids'],\n","        'attention_mask_text2': text2_encodings['attention_mask'],\n","        'labels': examples['label']\n","    }\n","\n","# Apply tokenization\n","tokenized_train = dataset['train'].map(preprocess_function, batched=True)\n","tokenized_test = dataset['test'].map(preprocess_function, batched=True)\n","tokenized_val = dataset['validation'].map(preprocess_function, batched=True)\n","\n","# Remove unnecessary columns and set format for PyTorch\n","columns_to_keep = ['input_ids_text1', 'attention_mask_text1', 'input_ids_text2', 'attention_mask_text2', 'labels']\n","tokenized_train.set_format(type='torch', columns=columns_to_keep)\n","tokenized_test.set_format(type='torch', columns=columns_to_keep)\n","tokenized_val.set_format(type='torch', columns=columns_to_keep)\n","\n","# Define a custom collator to handle text1 and text2 encoding\n","class BiEncoderCollator:\n","    def __call__(self, features):\n","        batch = {\n","            'input_ids_text1': torch.nn.utils.rnn.pad_sequence(\n","                [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","            'attention_mask_text1': torch.nn.utils.rnn.pad_sequence(\n","                [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","            'input_ids_text2': torch.nn.utils.rnn.pad_sequence(\n","                [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","            'attention_mask_text2': torch.nn.utils.rnn.pad_sequence(\n","                [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","            'labels': torch.tensor([f['labels'] for f in features], dtype=torch.long)  # Change to long for classification\n","        }\n","        return batch\n","\n","collator = BiEncoderCollator()\n","\n","# Define the compute_metrics function for classification with precision and recall\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    preds = np.argmax(predictions, axis=1)\n","    accuracy = accuracy_score(labels, preds)\n","    f1 = f1_score(labels, preds, average=\"weighted\")\n","    precision = precision_score(labels, preds, average=\"weighted\")\n","    recall = recall_score(labels, preds, average=\"weighted\")\n","    return {\n","        \"accuracy\": accuracy,\n","        \"f1\": f1,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","    }\n","\n","# Define a custom BiEncoder model with options for different loss functions\n","class BiEncoderModel(torch.nn.Module):\n","    def __init__(self, base_model, config=None, num_classes=4, loss_fn=\"cross_entropy\"):\n","        super(BiEncoderModel, self).__init__()\n","        self.base_model = base_model\n","        self.config = config  # Add this line to set the config attribute\n","        self.classifier = torch.nn.Linear(base_model.config.hidden_size * 2, num_classes)  # Updated for 4 classes\n","        self.loss_fn = loss_fn\n","\n","    def forward(self, input_ids_text1, attention_mask_text1, input_ids_text2, attention_mask_text2, labels=None):\n","        # Encode text1 and text2 separately\n","        outputs_text1 = self.base_model(input_ids_text1, attention_mask=attention_mask_text1)\n","        outputs_text2 = self.base_model(input_ids_text2, attention_mask=attention_mask_text2)\n","\n","        # Extract [CLS] token embeddings (first token)\n","        cls_embedding_text1 = outputs_text1.last_hidden_state[:, 0, :]\n","        cls_embedding_text2 = outputs_text2.last_hidden_state[:, 0, :]\n","\n","        # Concatenate embeddings and apply classifier\n","        concatenated_embeddings = torch.cat([cls_embedding_text1, cls_embedding_text2], dim=1)\n","        logits = self.classifier(concatenated_embeddings)\n","\n","        loss = None\n","        if labels is not None:\n","            if self.loss_fn == \"cross_entropy\":\n","                loss_fct = torch.nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n","                loss = loss_fct(logits, labels)\n","            elif self.loss_fn == \"focal_loss\":\n","                # Focal loss implementation\n","                alpha = 0.25\n","                gamma = 2.0\n","                ce_loss = torch.nn.CrossEntropyLoss(reduction=\"none\")(logits, labels)\n","                pt = torch.exp(-ce_loss)  # Probability of the true class\n","                loss = (alpha * (1 - pt) ** gamma * ce_loss).mean()\n","            elif self.loss_fn == \"kl_divergence\":\n","                # KL Divergence for soft-label classification\n","                kl_div = torch.nn.KLDivLoss(reduction=\"batchmean\")\n","                soft_labels = torch.nn.functional.one_hot(labels, num_classes=self.classifier.out_features).float()\n","                log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n","                loss = kl_div(log_probs, soft_labels)\n","            else:\n","                raise ValueError(f\"Unsupported loss function: {self.loss_fn}\")\n","\n","        return {\"loss\": loss, \"logits\": logits}\n","\n","# Initialize the Bi-Encoder model with specified loss function\n","def train_biencoder(loss_fn=\"cross_entropy\"):\n","    # Load pre-trained BERT configuration and model\n","    config = BertConfig.from_pretrained(model_name)\n","    bert_model = BertModel.from_pretrained(model_name)\n","\n","    # Initialize your custom BiEncoderModel with the BERT model, config, and loss function\n","    bi_encoder_model = BiEncoderModel(base_model=bert_model, config=config, loss_fn=loss_fn)\n","\n","    # Define TrainingArguments\n","    training_args = TrainingArguments(\n","        output_dir=f\"./output/bert-clf-biencoder-{loss_fn}\",\n","        evaluation_strategy=\"epoch\",    # Evaluate at the end of each epoch\n","        logging_dir='./logs',           # Directory for logs\n","        logging_steps=10,               # Log every 10 steps\n","        per_device_train_batch_size=wandb.config['batch_size'],\n","        per_device_eval_batch_size=wandb.config['batch_size'],\n","        num_train_epochs=wandb.config['epochs'],\n","        warmup_steps=100,\n","        learning_rate=wandb.config['learning_rate'],\n","        weight_decay=0.01,\n","        report_to=\"wandb\",\n","        save_strategy=\"epoch\",          # Save checkpoints at the end of each epoch\n","        load_best_model_at_end=True,\n","        push_to_hub=True,\n","        save_total_limit=2              # Keep only the 2 most recent checkpoints\n","    )\n","\n","    # Define the Trainer\n","    trainer = Trainer(\n","        model=bi_encoder_model,             # Custom BiEncoder model\n","        args=training_args,                 # Training arguments\n","        train_dataset=tokenized_train,      # Training dataset\n","        eval_dataset=tokenized_val,         # Validation dataset\n","        data_collator=collator,             # Custom collator for handling bi-encoder inputs\n","        compute_metrics=compute_metrics     # Function to compute metrics\n","    )\n","\n","    # Train the model\n","    trainer.train()\n","\n","    # Evaluate the model on the test set\n","    #trainer.evaluate(tokenized_test)\n","\n","    #trainer.model = trainer.model.base_model\n","\n","    # Save and push the model to the Hugging Face Hub\n","    trainer.save_model(f\"./output/bert-clf-biencoder-{loss_fn}\")\n","    trainer.push_to_hub(f\"minoosh/bert-clf-biencoder-{loss_fn}\")\n","\n","    # Finish wandb run\n","    wandb.finish()\n","\n","    return trainer"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T01:14:46.606628Z","iopub.status.busy":"2024-11-05T01:14:46.606200Z","iopub.status.idle":"2024-11-05T01:36:27.451488Z","shell.execute_reply":"2024-11-05T01:36:27.450745Z","shell.execute_reply.started":"2024-11-05T01:14:46.606580Z"},"trusted":true},"outputs":[{"data":{"text/html":["Finishing last run (ID:tmsco4k2) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eab0644ca624431a97ae6c46c5951f8a","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.016 MB of 0.016 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">dry-dust-36</strong> at: <a href='https://wandb.ai/minoosh/bert-biencoder-classification/runs/tmsco4k2' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification/runs/tmsco4k2</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-biencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241105_011435-tmsco4k2/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:tmsco4k2). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241105_011446-9qr31xxe</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/minoosh/bert-biencoder-classification/runs/9qr31xxe' target=\"_blank\">bert-biencoder-classification-cross_entropy</a></strong> to <a href='https://wandb.ai/minoosh/bert-biencoder-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/minoosh/bert-biencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/minoosh/bert-biencoder-classification/runs/9qr31xxe' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification/runs/9qr31xxe</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","/tmp/ipykernel_30/2421804472.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='546' max='546' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [546/546 21:18, Epoch 7/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.183900</td>\n","      <td>1.077525</td>\n","      <td>0.579288</td>\n","      <td>0.553207</td>\n","      <td>0.604092</td>\n","      <td>0.579288</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.836100</td>\n","      <td>0.855902</td>\n","      <td>0.660194</td>\n","      <td>0.652314</td>\n","      <td>0.670091</td>\n","      <td>0.660194</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.651600</td>\n","      <td>0.857550</td>\n","      <td>0.644013</td>\n","      <td>0.648457</td>\n","      <td>0.658787</td>\n","      <td>0.644013</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.524300</td>\n","      <td>0.906198</td>\n","      <td>0.640777</td>\n","      <td>0.640736</td>\n","      <td>0.650274</td>\n","      <td>0.640777</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.344600</td>\n","      <td>0.939663</td>\n","      <td>0.647249</td>\n","      <td>0.645739</td>\n","      <td>0.652287</td>\n","      <td>0.647249</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.280800</td>\n","      <td>0.974774</td>\n","      <td>0.634304</td>\n","      <td>0.634407</td>\n","      <td>0.635573</td>\n","      <td>0.634304</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.198200</td>\n","      <td>1.014879</td>\n","      <td>0.631068</td>\n","      <td>0.631045</td>\n","      <td>0.634338</td>\n","      <td>0.631068</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_30/2421804472.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/2421804472.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/2421804472.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/2421804472.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/2421804472.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/2421804472.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/tmp/ipykernel_30/2421804472.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","No files have been modified since last commit. Skipping to prevent empty commit.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ffc0756648444f5a86da1c1e066703a4","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.040 MB of 0.040 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁█▇▆▇▆▅</td></tr><tr><td>eval/f1</td><td>▁██▇█▇▆</td></tr><tr><td>eval/loss</td><td>█▁▁▃▄▅▆</td></tr><tr><td>eval/precision</td><td>▁█▇▆▆▄▄</td></tr><tr><td>eval/recall</td><td>▁█▇▆▇▆▅</td></tr><tr><td>eval/runtime</td><td>▅▄▄▁█▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▄▅▄▇▁██</td></tr><tr><td>eval/steps_per_second</td><td>▄▅▅█▁██</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇██</td></tr><tr><td>train/grad_norm</td><td>▂▅▁▃▂▂▂▄▂▃▃▃▂▂▄▆▅▅▃▃▂▂▄▃▄▃▄▆▃█▂▃▂▃▅▄▄▁▂▃</td></tr><tr><td>train/learning_rate</td><td>▂▂▄▅▆▇████▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁</td></tr><tr><td>train/loss</td><td>██▇▇▇▆▆▅▆▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.63107</td></tr><tr><td>eval/f1</td><td>0.63105</td></tr><tr><td>eval/loss</td><td>1.01488</td></tr><tr><td>eval/precision</td><td>0.63434</td></tr><tr><td>eval/recall</td><td>0.63107</td></tr><tr><td>eval/runtime</td><td>7.2224</td></tr><tr><td>eval/samples_per_second</td><td>42.784</td></tr><tr><td>eval/steps_per_second</td><td>1.385</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>7</td></tr><tr><td>train/global_step</td><td>546</td></tr><tr><td>train/grad_norm</td><td>5.88884</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.1982</td></tr><tr><td>train_loss</td><td>0.6359</td></tr><tr><td>train_runtime</td><td>1282.0481</td></tr><tr><td>train_samples_per_second</td><td>13.47</td></tr><tr><td>train_steps_per_second</td><td>0.426</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">bert-biencoder-classification-cross_entropy</strong> at: <a href='https://wandb.ai/minoosh/bert-biencoder-classification/runs/9qr31xxe' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification/runs/9qr31xxe</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-biencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-biencoder-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20241105_011446-9qr31xxe/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Start training with classification setup and selected loss function\n","loss_fns = [\"cross_entropy\", \"focal_loss\", \"kl_divergence\"]\n","loss_fn = loss_fns[0]\n","wandb.init(project=\"bert-biencoder-classification\", name=f\"bert-biencoder-classification-{loss_fn}\", config={\"epochs\": 7, \"batch_size\": 16, \"learning_rate\": 2e-5})\n","tr = train_biencoder(loss_fn)"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T01:55:18.389238Z","iopub.status.busy":"2024-11-05T01:55:18.388870Z","iopub.status.idle":"2024-11-05T01:55:33.294184Z","shell.execute_reply":"2024-11-05T01:55:33.293191Z","shell.execute_reply.started":"2024-11-05T01:55:18.389204Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07cd8f216cb341e48bd717496731b9da","version_major":2,"version_minor":0},"text/plain":["Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7fa92cda8ca64a63985016c177c18b24","version_major":2,"version_minor":0},"text/plain":["training_args.bin:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca2bdba7a2064916a31561b9fde06cd1","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/minoosh/bert-clf-biencoder-cross_entropy/commit/ecebb764b69e70fa600211415fe638f27734ebb9', commit_message='End of training', commit_description='', oid='ecebb764b69e70fa600211415fe638f27734ebb9', pr_url=None, repo_url=RepoUrl('https://huggingface.co/minoosh/bert-clf-biencoder-cross_entropy', endpoint='https://huggingface.co', repo_type='model', repo_id='minoosh/bert-clf-biencoder-cross_entropy'), pr_revision=None, pr_num=None)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["tr.push_to_hub()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T01:41:21.162759Z","iopub.status.busy":"2024-11-05T01:41:21.161805Z","iopub.status.idle":"2024-11-05T01:41:21.169226Z","shell.execute_reply":"2024-11-05T01:41:21.168118Z","shell.execute_reply.started":"2024-11-05T01:41:21.162716Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<transformers.trainer.Trainer at 0x7ad084279d50>"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["tr"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T01:41:58.041403Z","iopub.status.busy":"2024-11-05T01:41:58.040802Z","iopub.status.idle":"2024-11-05T01:41:59.782937Z","shell.execute_reply":"2024-11-05T01:41:59.782021Z","shell.execute_reply.started":"2024-11-05T01:41:58.041346Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminooshayan97\u001b[0m (\u001b[33mminoosh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241105_014158-sqz4bibf</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/minoosh/uncategorized/runs/sqz4bibf' target=\"_blank\">flowing-hill-7</a></strong> to <a href='https://wandb.ai/minoosh/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/minoosh/uncategorized' target=\"_blank\">https://wandb.ai/minoosh/uncategorized</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/minoosh/uncategorized/runs/sqz4bibf' target=\"_blank\">https://wandb.ai/minoosh/uncategorized/runs/sqz4bibf</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/minoosh/uncategorized/runs/sqz4bibf?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7ad1d54d5150>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T01:41:59.825633Z","iopub.status.busy":"2024-11-05T01:41:59.825292Z","iopub.status.idle":"2024-11-05T01:42:06.498938Z","shell.execute_reply":"2024-11-05T01:42:06.498085Z","shell.execute_reply.started":"2024-11-05T01:41:59.825598Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_30/2421804472.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]}],"source":["# Tokenize the test set\n","tokenized_test = dataset['test'].map(preprocess_function, batched=True)\n","\n","# Set the format for the test dataset for PyTorch\n","tokenized_test.set_format(type='torch', columns=columns_to_keep)\n","\n","# Predict on the test set after training\n","def predict_test_set(trainer, test_dataset):\n","    # Get predictions\n","    predictions = trainer.predict(test_dataset)\n","    pred_logits = predictions.predictions\n","    pred_labels = np.argmax(pred_logits, axis=1)  # Get the predicted class labels\n","    return pred_labels, predictions.label_ids  # Return predicted and actual labels\n","\n","# Example usage after training\n","#trainer = train_biencoder(loss_fn=\"cross_entropy\")  # Train the model first\n","pred_labels, true_labels = predict_test_set(tr, tokenized_test)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T01:42:06.500899Z","iopub.status.busy":"2024-11-05T01:42:06.500557Z","iopub.status.idle":"2024-11-05T01:42:06.527698Z","shell.execute_reply":"2024-11-05T01:42:06.526899Z","shell.execute_reply.started":"2024-11-05T01:42:06.500862Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Set Evaluation:\n","Accuracy: 0.6461038961038961\n","F1 Score: 0.6421041927303539\n","Precision: 0.6614733854189244\n","Recall: 0.6461038961038961\n"]}],"source":["# Optionally, calculate metrics on test set predictions\n","accuracy = accuracy_score(true_labels, pred_labels)\n","f1 = f1_score(true_labels, pred_labels, average=\"weighted\")\n","precision = precision_score(true_labels, pred_labels, average=\"weighted\")\n","recall = recall_score(true_labels, pred_labels, average=\"weighted\")\n","\n","# Print metrics\n","print(\"Test Set Evaluation:\")\n","print(f\"Accuracy: {accuracy}\")\n","print(f\"F1 Score: {f1}\")\n","print(f\"Precision: {precision}\")\n","print(f\"Recall: {recall}\")\n","\n","# Optionally save the predictions in a CSV file\n","import pandas as pd\n","df_predictions = pd.DataFrame({\"True Labels\": true_labels, \"Predicted Labels\": pred_labels})\n","df_predictions.to_csv(\"test_predictions.csv\", index=False)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T01:52:31.163242Z","iopub.status.busy":"2024-11-05T01:52:31.162215Z","iopub.status.idle":"2024-11-05T01:52:37.683362Z","shell.execute_reply":"2024-11-05T01:52:37.682554Z","shell.execute_reply.started":"2024-11-05T01:52:31.163202Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_30/2421804472.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["pred_labels, true_labels = predict_test_set(tr, tokenized_val)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T01:52:37.685132Z","iopub.status.busy":"2024-11-05T01:52:37.684813Z","iopub.status.idle":"2024-11-05T01:52:37.703683Z","shell.execute_reply":"2024-11-05T01:52:37.702789Z","shell.execute_reply.started":"2024-11-05T01:52:37.685098Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Set Evaluation:\n","Accuracy: 0.6601941747572816\n","F1 Score: 0.6523140839405329\n","Precision: 0.6700914000695115\n","Recall: 0.6601941747572816\n"]}],"source":["# Optionally, calculate metrics on test set predictions\n","accuracy = accuracy_score(true_labels, pred_labels)\n","f1 = f1_score(true_labels, pred_labels, average=\"weighted\")\n","precision = precision_score(true_labels, pred_labels, average=\"weighted\")\n","recall = recall_score(true_labels, pred_labels, average=\"weighted\")\n","\n","# Print metrics\n","print(\"Test Set Evaluation:\")\n","print(f\"Accuracy: {accuracy}\")\n","print(f\"F1 Score: {f1}\")\n","print(f\"Precision: {precision}\")\n","print(f\"Recall: {recall}\")\n","\n","# Optionally save the predictions in a CSV file\n","import pandas as pd\n","df_predictions = pd.DataFrame({\"True Labels\": true_labels, \"Predicted Labels\": pred_labels})\n","df_predictions.to_csv(\"test_predictions.csv\", index=False)"]},{"cell_type":"code","execution_count":114,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T02:33:47.411692Z","iopub.status.busy":"2024-11-05T02:33:47.411299Z","iopub.status.idle":"2024-11-05T02:33:47.469168Z","shell.execute_reply":"2024-11-05T02:33:47.468043Z","shell.execute_reply.started":"2024-11-05T02:33:47.411650Z"},"trusted":true},"outputs":[{"ename":"AttributeError","evalue":"'BiEncoderModel' object has no attribute 'save_pretrained'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[114], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMOOO5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1729\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1728\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1729\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'BiEncoderModel' object has no attribute 'save_pretrained'"]}],"source":["tr.model.save_pretrained(\"MOOO5\")"]},{"cell_type":"code","execution_count":157,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T02:52:44.086443Z","iopub.status.busy":"2024-11-05T02:52:44.085557Z","iopub.status.idle":"2024-11-05T02:52:44.092625Z","shell.execute_reply":"2024-11-05T02:52:44.091665Z","shell.execute_reply.started":"2024-11-05T02:52:44.086388Z"},"trusted":true},"outputs":[],"source":["bi_encoder_model = BiEncoderModel(base_model=tr.model.base_model, config=config)"]},{"cell_type":"code","execution_count":176,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T03:13:02.016079Z","iopub.status.busy":"2024-11-05T03:13:02.015675Z","iopub.status.idle":"2024-11-05T03:13:02.142868Z","shell.execute_reply":"2024-11-05T03:13:02.141909Z","shell.execute_reply.started":"2024-11-05T03:13:02.016038Z"},"trusted":true},"outputs":[],"source":["import torch\n","from transformers import AutoConfig, AutoModel, AutoTokenizer, Trainer\n"," \n","model_name = \"/kaggle/working/This\"\n","\n","# Load the tokenizer and model from Hugging Face\n","#tokenizer = AutoTokenizer.from_pretrained(model_name)\n","tokenizer = tokenizer\n","config = AutoConfig.from_pretrained(model_name)\n","model = AutoModel.from_pretrained(model_name)\n","\n","bi_encoder_model = BiEncoderModel(base_model=model, config=config)\n","\n","trainer = Trainer(\n","        model=loaded_model,\n","        data_collator=collator,# Custom collator for handling bi-encoder inputs\n","    )"]},{"cell_type":"code","execution_count":180,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T03:17:55.805659Z","iopub.status.busy":"2024-11-05T03:17:55.804965Z","iopub.status.idle":"2024-11-05T03:18:02.843075Z","shell.execute_reply":"2024-11-05T03:18:02.842191Z","shell.execute_reply.started":"2024-11-05T03:17:55.805616Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_30/2421804472.py:50: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n","/tmp/ipykernel_30/2421804472.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["import numpy as np\n","\n","def predict_test_set(trainer, test_dataset):\n","    # Get predictions\n","    predictions = trainer.predict(test_dataset)\n","    pred_logits = predictions.predictions\n","    pred_labels = np.argmax(pred_logits, axis=1)  # Get the predicted class labels\n","    return pred_labels, predictions.label_ids  # Return predicted and actual labels\n","\n","# Example usage after training\n","#trainer = train_biencoder(loss_fn=\"cross_entropy\")  # Train the model first\n","pred_labels, true_labels = predict_test_set(loaded_trainer, tokenized_test)"]},{"cell_type":"code","execution_count":182,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T03:18:05.961593Z","iopub.status.busy":"2024-11-05T03:18:05.961217Z","iopub.status.idle":"2024-11-05T03:18:05.977705Z","shell.execute_reply":"2024-11-05T03:18:05.976644Z","shell.execute_reply.started":"2024-11-05T03:18:05.961560Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Set Evaluation:\n","Accuracy: 0.6461038961038961\n","F1 Score: 0.6421041927303539\n","Precision: 0.6614733854189244\n","Recall: 0.6461038961038961\n"]}],"source":["# Optionally, calculate metrics on test set predictions\n","accuracy = accuracy_score(true_labels, pred_labels)\n","f1 = f1_score(true_labels, pred_labels, average=\"weighted\")\n","precision = precision_score(true_labels, pred_labels, average=\"weighted\")\n","recall = recall_score(true_labels, pred_labels, average=\"weighted\")\n","\n","# Print metrics\n","print(\"Test Set Evaluation:\")\n","print(f\"Accuracy: {accuracy}\")\n","print(f\"F1 Score: {f1}\")\n","print(f\"Precision: {precision}\")\n","print(f\"Recall: {recall}\")"]},{"cell_type":"code","execution_count":99,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T02:26:55.539222Z","iopub.status.busy":"2024-11-05T02:26:55.538210Z","iopub.status.idle":"2024-11-05T02:26:55.548864Z","shell.execute_reply":"2024-11-05T02:26:55.547949Z","shell.execute_reply.started":"2024-11-05T02:26:55.539166Z"},"trusted":true},"outputs":[{"data":{"text/plain":["BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertModel\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.45.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}"]},"execution_count":99,"metadata":{},"output_type":"execute_result"}],"source":["trainer.model.config"]},{"cell_type":"code","execution_count":139,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T02:48:14.772265Z","iopub.status.busy":"2024-11-05T02:48:14.771372Z","iopub.status.idle":"2024-11-05T02:48:14.777220Z","shell.execute_reply":"2024-11-05T02:48:14.776414Z","shell.execute_reply.started":"2024-11-05T02:48:14.772225Z"},"trusted":true},"outputs":[],"source":["trainer = tr"]},{"cell_type":"code","execution_count":162,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T02:54:07.502376Z","iopub.status.busy":"2024-11-05T02:54:07.501898Z","iopub.status.idle":"2024-11-05T02:54:07.510629Z","shell.execute_reply":"2024-11-05T02:54:07.509673Z","shell.execute_reply.started":"2024-11-05T02:54:07.502329Z"},"trusted":true},"outputs":[{"data":{"text/plain":["True"]},"execution_count":162,"metadata":{},"output_type":"execute_result"}],"source":["trainer.model == tr.model.base_model "]},{"cell_type":"code","execution_count":163,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T02:54:17.256734Z","iopub.status.busy":"2024-11-05T02:54:17.256335Z","iopub.status.idle":"2024-11-05T02:54:17.264403Z","shell.execute_reply":"2024-11-05T02:54:17.263497Z","shell.execute_reply.started":"2024-11-05T02:54:17.256701Z"},"trusted":true},"outputs":[{"data":{"text/plain":["True"]},"execution_count":163,"metadata":{},"output_type":"execute_result"}],"source":["trainer.model == trainer.model.base_model"]},{"cell_type":"code","execution_count":164,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T02:55:00.312057Z","iopub.status.busy":"2024-11-05T02:55:00.311188Z","iopub.status.idle":"2024-11-05T02:55:00.846679Z","shell.execute_reply":"2024-11-05T02:55:00.845659Z","shell.execute_reply.started":"2024-11-05T02:55:00.312015Z"},"trusted":true},"outputs":[],"source":["trainer.save_model(\"This\")"]},{"cell_type":"code","execution_count":168,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T02:56:13.428549Z","iopub.status.busy":"2024-11-05T02:56:13.428040Z","iopub.status.idle":"2024-11-05T02:56:27.908577Z","shell.execute_reply":"2024-11-05T02:56:27.907491Z","shell.execute_reply.started":"2024-11-05T02:56:13.428507Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"129b4988b77040c7bb18edc409ffbbb4","version_major":2,"version_minor":0},"text/plain":["Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50c628bab8c1438bb45e604671d62ebb","version_major":2,"version_minor":0},"text/plain":["training_args.bin:   0%|          | 0.00/5.24k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ea5a777e7b6548a1b95d4c0456476fdc","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/minoosh/tmp_trainer/commit/cb6b7fcdff83a6ebdd75661ae69040779d88cc12', commit_message='End of training', commit_description='', oid='cb6b7fcdff83a6ebdd75661ae69040779d88cc12', pr_url=None, repo_url=RepoUrl('https://huggingface.co/minoosh/tmp_trainer', endpoint='https://huggingface.co', repo_type='model', repo_id='minoosh/tmp_trainer'), pr_revision=None, pr_num=None)"]},"execution_count":168,"metadata":{},"output_type":"execute_result"}],"source":["trainer.push_to_hub()"]},{"cell_type":"code","execution_count":175,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T03:12:12.301702Z","iopub.status.busy":"2024-11-05T03:12:12.301242Z","iopub.status.idle":"2024-11-05T03:12:15.082251Z","shell.execute_reply":"2024-11-05T03:12:15.081297Z","shell.execute_reply.started":"2024-11-05T03:12:12.301664Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model saved successfully to test_claude_save\n","Loading base model...\n","Creating BiEncoder model...\n","Loading model state...\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_30/3437885287.py:49: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(state_dict_path)\n"]},{"name":"stdout","output_type":"stream","text":["Loading tokenizer...\n","Creating trainer...\n","Model loaded successfully!\n"]}],"source":["import os\n","import torch\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, Trainer\n","\n","def save_biencoder_model(trainer, save_path):\n","    \"\"\"\n","    Save both the base model and the complete BiEncoder model structure\n","    \"\"\"\n","    # Create directory if it doesn't exist\n","    os.makedirs(save_path, exist_ok=True)\n","    \n","    # 1. Save the complete model state dict\n","    torch.save(trainer.model.state_dict(), os.path.join(save_path, \"pytorch_model.bin\"))\n","    \n","    # 2. Save the base model separately\n","    trainer.model.base_model.save_pretrained(os.path.join(save_path, \"base_model\"))\n","    \n","    # 3. Save the model config\n","    trainer.model.config.save_pretrained(save_path)\n","    \n","    # 4. Save the tokenizer if it exists\n","    if hasattr(trainer, 'tokenizer'):\n","        trainer.tokenizer.save_pretrained(save_path)\n","    \n","    print(f\"Model saved successfully to {save_path}\")\n","\n","def load_biencoder_model(load_path, num_classes=4):\n","    \"\"\"\n","    Load the complete BiEncoder model structure\n","    \"\"\"\n","    try:\n","        # 1. Load the base model and config\n","        print(\"Loading base model...\")\n","        base_model = AutoModel.from_pretrained(os.path.join(load_path, \"base_model\"))\n","        config = AutoConfig.from_pretrained(os.path.join(load_path, \"base_model\"))\n","        \n","        # 2. Recreate the BiEncoder model\n","        print(\"Creating BiEncoder model...\")\n","        model = BiEncoderModel(\n","            base_model=base_model,\n","            config=config,\n","            num_classes=num_classes\n","        )\n","        \n","        # 3. Load the complete state dict\n","        print(\"Loading model state...\")\n","        state_dict_path = os.path.join(load_path, \"pytorch_model.bin\")\n","        if os.path.exists(state_dict_path):\n","            state_dict = torch.load(state_dict_path)\n","            model.load_state_dict(state_dict)\n","        else:\n","            raise FileNotFoundError(f\"Model state dict not found at {state_dict_path}\")\n","        \n","        # 4. Load the tokenizer\n","        print(\"Loading tokenizer...\")\n","        try:\n","            tokenizer = AutoTokenizer.from_pretrained(load_path)\n","        except:\n","            print(\"Warning: Tokenizer not found in save path\")\n","            tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","        \n","        # 5. Create a new trainer instance\n","        print(\"Creating trainer...\")\n","        trainer = Trainer(\n","            model=model,\n","            data_collator=BiEncoderCollator(),\n","            compute_metrics=compute_metrics\n","        )\n","        \n","        print(\"Model loaded successfully!\")\n","        return trainer, model, tokenizer\n","    \n","    except Exception as e:\n","        print(f\"Error loading model: {str(e)}\")\n","        raise\n","        \n","save_path = \"test_claude_save\"\n","save_biencoder_model(tr, save_path)\n","\n","# Load the model\n","loaded_trainer, loaded_model, loaded_tokenizer = load_biencoder_model(save_path)"]},{"cell_type":"code","execution_count":183,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T03:19:22.280044Z","iopub.status.busy":"2024-11-05T03:19:22.279632Z","iopub.status.idle":"2024-11-05T03:19:24.709127Z","shell.execute_reply":"2024-11-05T03:19:24.708260Z","shell.execute_reply.started":"2024-11-05T03:19:22.280006Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["No files have been modified since last commit. Skipping to prevent empty commit.\n"]},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/minoosh/tmp_trainer/commit/b22bf8476fc56f9acca6e58304666b5a2b63b7c0', commit_message='End of training', commit_description='', oid='b22bf8476fc56f9acca6e58304666b5a2b63b7c0', pr_url=None, repo_url=RepoUrl('https://huggingface.co/minoosh/tmp_trainer', endpoint='https://huggingface.co', repo_type='model', repo_id='minoosh/tmp_trainer'), pr_revision=None, pr_num=None)"]},"execution_count":183,"metadata":{},"output_type":"execute_result"}],"source":["loaded_trainer.push_to_hub()"]},{"cell_type":"code","execution_count":194,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T03:41:00.322411Z","iopub.status.busy":"2024-11-05T03:41:00.321923Z","iopub.status.idle":"2024-11-05T03:41:00.343930Z","shell.execute_reply":"2024-11-05T03:41:00.342705Z","shell.execute_reply.started":"2024-11-05T03:41:00.322370Z"},"trusted":true},"outputs":[],"source":["import os\n","import json\n","from huggingface_hub import HfApi\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, BertConfig\n","\n","def save_and_push_to_hub(trainer, repo_id, token=None):\n","    \"\"\"\n","    Save and push BiEncoder model to Hugging Face Hub\n","    \"\"\"\n","    api = HfApi()\n","    \n","    try:\n","        temp_save_path = f\"temp_save_{repo_id.split('/')[-1]}\"\n","        os.makedirs(temp_save_path, exist_ok=True)\n","        \n","        print(f\"Saving model to {temp_save_path}...\")\n","        \n","        # 1. Save the base model configuration\n","        base_config = trainer.model.base_model.config.to_dict()\n","        base_config[\"model_type\"] = \"bert\"  # Ensure we're using BERT as base\n","        base_config[\"architectures\"] = [\"BertModel\"]\n","        \n","        with open(os.path.join(temp_save_path, \"config.json\"), 'w') as f:\n","            json.dump(base_config, f)\n","            \n","        # 2. Save model weights\n","        torch.save(trainer.model.state_dict(), os.path.join(temp_save_path, \"pytorch_model.bin\"))\n","        \n","        # 3. Save tokenizer\n","        print(\"Saving tokenizer...\")\n","        if hasattr(trainer, 'tokenizer'):\n","            trainer.tokenizer.save_pretrained(temp_save_path)\n","        \n","        # 4. Create model card\n","        model_card = f\"\"\"---\n","language: en\n","tags:\n","- bert\n","- classification\n","- pytorch\n","pipeline_tag: text-classification\n","---\n","\n","# BiEncoder Classification Model\n","\n","This model is a BiEncoder architecture based on BERT for text pair classification.\n","\n","## Model Details\n","- Base Model: bert-base-uncased\n","- Architecture: BiEncoder with BERT base\n","- Number of classes: {trainer.model.classifier.out_features}\n","\n","## Usage\n","\n","```python\n","from transformers import AutoTokenizer\n","import torch\n","\n","# Load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"{repo_id}\")\n","\n","# Load model weights\n","state_dict = torch.load(\"pytorch_model.bin\")\n","\n","# Initialize model (you'll need the BiEncoderModel class)\n","model = BiEncoderModel(\n","    base_model=AutoModel.from_pretrained(\"bert-base-uncased\"),\n","    num_classes={trainer.model.classifier.out_features}\n",")\n","model.load_state_dict(state_dict)\n","```\n","\"\"\"\n","        with open(os.path.join(temp_save_path, \"README.md\"), 'w') as f:\n","            f.write(model_card)\n","        \n","        # 5. Push to hub\n","        print(f\"Pushing to hub at {repo_id}...\")\n","        api.upload_folder(\n","            folder_path=temp_save_path,\n","            repo_id=repo_id,\n","            token=token\n","        )\n","        \n","        print(f\"Successfully pushed model to {repo_id}\")\n","        \n","    except Exception as e:\n","        print(f\"Error during push to hub: {str(e)}\")\n","        raise\n","    finally:\n","        if os.path.exists(temp_save_path):\n","            import shutil\n","            shutil.rmtree(temp_save_path)\n","\n","def load_from_hub(repo_id, num_classes=4):\n","    \"\"\"\n","    Load BiEncoder model from Hugging Face Hub\n","    \"\"\"\n","    try:\n","        print(f\"Loading model from {repo_id}...\")\n","        \n","        # 1. Initialize base model with BERT\n","        base_model = AutoModel.from_pretrained(\"bert-base-uncased\")\n","        \n","        # 2. Create BiEncoder model\n","        model = BiEncoderModel(\n","            base_model=base_model,\n","            num_classes=num_classes\n","        )\n","        \n","        # 3. Load state dict\n","        state_dict = torch.hub.load_state_dict_from_url(\n","            f\"https://huggingface.co/{repo_id}/resolve/main/pytorch_model.bin\",\n","            map_location=\"cpu\"\n","        )\n","        model.load_state_dict(state_dict)\n","        \n","        # 4. Load tokenizer\n","        tokenizer = AutoTokenizer.from_pretrained(repo_id)\n","        \n","        # 5. Create trainer\n","        trainer = Trainer(\n","            model=model,\n","            data_collator=BiEncoderCollator(),\n","            compute_metrics=compute_metrics\n","        )\n","        \n","        print(\"Model loaded successfully!\")\n","        return trainer, model, tokenizer\n","        \n","    except Exception as e:\n","        print(f\"Error loading model from hub: {str(e)}\")\n","        raise"]},{"cell_type":"code","execution_count":195,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T03:41:03.730169Z","iopub.status.busy":"2024-11-05T03:41:03.729246Z","iopub.status.idle":"2024-11-05T03:41:21.507790Z","shell.execute_reply":"2024-11-05T03:41:21.506694Z","shell.execute_reply.started":"2024-11-05T03:41:03.730125Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Saving model to temp_save_repo...\n","Saving tokenizer...\n","Pushing to hub at minoosh/repo...\n","Successfully pushed model to minoosh/repo\n","Loading model from minoosh/repo...\n"]},{"name":"stderr","output_type":"stream","text":["Downloading: \"https://huggingface.co/minoosh/repo/resolve/main/pytorch_model.bin\" to /root/.cache/torch/hub/checkpoints/pytorch_model.bin\n","100%|██████████| 418M/418M [00:10<00:00, 42.3MB/s] \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf7d3b51cd094b5ab40d7c8e3278fbf4","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"65e2a5e8085b4c338e35b871a78d1bea","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"470ff380df4d471496515968226324cd","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b432fae36e374f398d00ad2c8c499787","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Model loaded successfully!\n"]}],"source":["# To save and push to hub:\n","repo_id = \"minoosh/repo\"  # e.g., \"minoosh/bert-biencoder-classification\"\n","save_and_push_to_hub(tr, repo_id)\n","\n","# To load from hub later:\n","loaded_trainer, loaded_model, loaded_tokenizer = load_from_hub(repo_id)"]},{"cell_type":"code","execution_count":193,"metadata":{"execution":{"iopub.execute_input":"2024-11-05T03:39:43.363374Z","iopub.status.busy":"2024-11-05T03:39:43.362368Z","iopub.status.idle":"2024-11-05T03:39:44.490772Z","shell.execute_reply":"2024-11-05T03:39:44.489765Z","shell.execute_reply.started":"2024-11-05T03:39:43.363316Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["\n","zip error: Nothing to do! (test_claude_save.zip)\n"]}],"source":["!zip test_claude_save  "]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
