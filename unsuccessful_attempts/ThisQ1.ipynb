{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2024-10-30T22:08:55.309771Z",
          "iopub.status.busy": "2024-10-30T22:08:55.309489Z",
          "iopub.status.idle": "2024-10-30T22:09:07.951366Z",
          "shell.execute_reply": "2024-10-30T22:09:07.949914Z",
          "shell.execute_reply.started": "2024-10-30T22:08:55.309740Z"
        },
        "id": "TY_JJkPo58St",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-10-30T22:09:07.953669Z",
          "iopub.status.busy": "2024-10-30T22:09:07.953321Z",
          "iopub.status.idle": "2024-10-30T22:09:09.542210Z",
          "shell.execute_reply": "2024-10-30T22:09:09.541355Z",
          "shell.execute_reply.started": "2024-10-30T22:09:07.953629Z"
        },
        "id": "Um2NZlL_58Su",
        "outputId": "b1856c19-93fd-4bb2-d42b-81fa5df9af2e",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login --token "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "execution": {
          "iopub.execute_input": "2024-10-30T22:09:09.544029Z",
          "iopub.status.busy": "2024-10-30T22:09:09.543707Z",
          "iopub.status.idle": "2024-10-30T22:10:37.499057Z",
          "shell.execute_reply": "2024-10-30T22:10:37.498201Z",
          "shell.execute_reply.started": "2024-10-30T22:09:09.543993Z"
        },
        "id": "XTnEOW4N58Sv",
        "outputId": "b8306239-f2ac-4096-e4be-0e322208d567",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:svnj8stb) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">glittering-parachute-84</strong> at: <a href='https://wandb.ai/minoosh/bert-crossencoder-classification/runs/svnj8stb' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-classification/runs/svnj8stb</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-crossencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241101_233022-svnj8stb/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:svnj8stb). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241101_233032-jmvpbqgo</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/minoosh/bert-crossencoder-classification/runs/jmvpbqgo' target=\"_blank\">scintillating-blossom-85</a></strong> to <a href='https://wandb.ai/minoosh/bert-crossencoder-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/minoosh/bert-crossencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-classification</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/minoosh/bert-crossencoder-classification/runs/jmvpbqgo' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-classification/runs/jmvpbqgo</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig, TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import wandb\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(\n",
        "    project=\"bert-crossencoder-classification\"\n",
        ")\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"minoosh/EPITOME_pairs\")\n",
        "\n",
        "# Initialize the tokenizer and model for cross-encoder setup\n",
        "model_name = \"google-bert/bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Preprocess data for the cross-encoder model by concatenating text1 and text2 with [SEP]\n",
        "def preprocess_function(examples):\n",
        "    # Concatenate both texts with a [SEP] token in between\n",
        "    encodings = tokenizer(examples['text1'], examples['text2'], truncation=True, padding=True, max_length=512)\n",
        "    encodings['labels'] = examples['label']  # Add labels\n",
        "    return encodings\n",
        "\n",
        "# Apply tokenization\n",
        "tokenized_train = dataset['train'].map(preprocess_function, batched=True)\n",
        "tokenized_test = dataset['test'].map(preprocess_function, batched=True)\n",
        "tokenized_val = dataset['validation'].map(preprocess_function, batched=True)\n",
        "\n",
        "# Set format for PyTorch\n",
        "tokenized_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "tokenized_test.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "tokenized_val.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
        "\n",
        "# Define compute_metrics function for classification evaluation\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    preds = predictions.argmax(axis=1)\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    precision = precision_score(labels, preds, average=\"weighted\")\n",
        "    recall = recall_score(labels, preds, average=\"weighted\")\n",
        "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1\n",
        "    }\n",
        "\n",
        "# Custom Cross-Encoder model class for classification\n",
        "class CrossEncoderModel(torch.nn.Module):\n",
        "    def __init__(self, model_name, num_classes=4, loss_fn=\"cross_entropy\"):\n",
        "        super(CrossEncoderModel, self).__init__()\n",
        "        # Load model config\n",
        "        self.config = AutoConfig.from_pretrained(model_name, num_labels=num_classes)\n",
        "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, config=self.config)\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits  # Output logits for classification\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if self.loss_fn == \"cross_entropy\":\n",
        "                loss_fct = torch.nn.CrossEntropyLoss()  # Use CrossEntropyLoss for classification\n",
        "                loss = loss_fct(logits, labels)\n",
        "            elif self.loss_fn == \"focal_loss\":\n",
        "                # Focal loss implementation for handling class imbalance\n",
        "                alpha = 0.25\n",
        "                gamma = 2.0\n",
        "                ce_loss = torch.nn.CrossEntropyLoss(reduction=\"none\")(logits, labels)\n",
        "                pt = torch.exp(-ce_loss)  # Probability of the true class\n",
        "                loss = (alpha * (1 - pt) ** gamma * ce_loss).mean()\n",
        "            elif self.loss_fn == \"kl_divergence\":\n",
        "                # KL Divergence for soft-label classification\n",
        "                kl_div = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
        "                soft_labels = torch.nn.functional.one_hot(labels, num_classes=self.config.num_labels).float()\n",
        "                log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
        "                loss = kl_div(log_probs, soft_labels)\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported loss function: {self.loss_fn}\")\n",
        "\n",
        "        return {\"loss\": loss, \"logits\": logits}\n",
        "\n",
        "\n",
        "    def save_pretrained(self, save_directory):\n",
        "        # Save model weights\n",
        "        #self.model.save_pretrained(save_directory)\n",
        "        # Save tokenizer if applicable\n",
        "        #tokenizer.save_pretrained(save_directory)\n",
        "        # Save config\n",
        "        self.config.save_pretrained(save_directory)\n",
        "\n",
        "\n",
        "\n",
        "# Function to initialize and train the cross-encoder model\n",
        "def train_crossencoder(loss_fn):\n",
        "    model = CrossEncoderModel(model_name=model_name, loss_fn=loss_fn)\n",
        "\n",
        "    # Set up TrainingArguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./output/TTTTempathy-crossencoder-{loss_fn}\",\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=10,\n",
        "        per_device_train_batch_size=wandb.config['batch_size'],\n",
        "        per_device_eval_batch_size=wandb.config['batch_size'],\n",
        "        num_train_epochs=wandb.config['epochs'],\n",
        "        warmup_steps=100,\n",
        "        learning_rate=wandb.config['learning_rate'],\n",
        "        weight_decay=0.01,\n",
        "        report_to=\"wandb\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        push_to_hub=True,\n",
        "        save_total_limit=2\n",
        "    )\n",
        "\n",
        "    # Initialize Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train,\n",
        "        eval_dataset=tokenized_val,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    trainer.evaluate(tokenized_test)\n",
        "\n",
        "    trainer.model.save_pretrained(f\"./output/TTTTempathy-crossencoder-{loss_fn}\")\n",
        "\n",
        "    # Save and push the model to the Hugging Face Hub\n",
        "    trainer.save_model(f\"./output/TTTTempathy-crossencoder-{loss_fn}\")\n",
        "    trainer.push_to_hub(f\"minoosh/TTTTempathy-crossencoder-{loss_fn}\")\n",
        "\n",
        "    # End the wandb run\n",
        "    wandb.finish()\n",
        "    return trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "execution": {
          "iopub.execute_input": "2024-10-30T21:30:52.671355Z",
          "iopub.status.busy": "2024-10-30T21:30:52.671063Z",
          "iopub.status.idle": "2024-10-30T21:46:02.501200Z",
          "shell.execute_reply": "2024-10-30T21:46:02.500470Z",
          "shell.execute_reply.started": "2024-10-30T21:30:52.671323Z"
        },
        "id": "DATap4of58Sw",
        "outputId": "0f50d7ce-234a-48ec-95cb-c5f0f4d90f7a",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:jmvpbqgo) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">scintillating-blossom-85</strong> at: <a href='https://wandb.ai/minoosh/bert-crossencoder-classification/runs/jmvpbqgo' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-classification/runs/jmvpbqgo</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-crossencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241101_233032-jmvpbqgo/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:jmvpbqgo). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241101_233040-plhtys4r</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/minoosh/bert-crossencoder-classification/runs/plhtys4r' target=\"_blank\">bert-crossencoder-classification-cross_entropy</a></strong> to <a href='https://wandb.ai/minoosh/bert-crossencoder-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/minoosh/bert-crossencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-classification</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/minoosh/bert-crossencoder-classification/runs/plhtys4r' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-classification/runs/plhtys4r</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='465' max='465' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [465/465 12:57, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.193100</td>\n",
              "      <td>1.067032</td>\n",
              "      <td>0.601942</td>\n",
              "      <td>0.612247</td>\n",
              "      <td>0.601942</td>\n",
              "      <td>0.581434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.907300</td>\n",
              "      <td>0.962425</td>\n",
              "      <td>0.611650</td>\n",
              "      <td>0.623103</td>\n",
              "      <td>0.611650</td>\n",
              "      <td>0.606202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.790000</td>\n",
              "      <td>0.941332</td>\n",
              "      <td>0.611650</td>\n",
              "      <td>0.613697</td>\n",
              "      <td>0.611650</td>\n",
              "      <td>0.608384</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [20/20 00:09]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>‚ñÅ‚ñà‚ñà‚ñá</td></tr><tr><td>eval/f1</td><td>‚ñÅ‚ñá‚ñà‚ñá</td></tr><tr><td>eval/loss</td><td>‚ñà‚ñÇ‚ñÅ‚ñÖ</td></tr><tr><td>eval/precision</td><td>‚ñÇ‚ñà‚ñÉ‚ñÅ</td></tr><tr><td>eval/recall</td><td>‚ñÅ‚ñà‚ñà‚ñá</td></tr><tr><td>eval/runtime</td><td>‚ñÖ‚ñÖ‚ñÅ‚ñà</td></tr><tr><td>eval/samples_per_second</td><td>‚ñÖ‚ñÑ‚ñà‚ñÅ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñÑ‚ñÑ‚ñà‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñÇ</td></tr><tr><td>train/learning_rate</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.61039</td></tr><tr><td>eval/f1</td><td>0.6036</td></tr><tr><td>eval/loss</td><td>1.01857</td></tr><tr><td>eval/precision</td><td>0.61049</td></tr><tr><td>eval/recall</td><td>0.61039</td></tr><tr><td>eval/runtime</td><td>9.8313</td></tr><tr><td>eval/samples_per_second</td><td>31.328</td></tr><tr><td>eval/steps_per_second</td><td>2.034</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>465</td></tr><tr><td>train/grad_norm</td><td>8.65658</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.79</td></tr><tr><td>train_loss</td><td>1.03358</td></tr><tr><td>train_runtime</td><td>778.6172</td></tr><tr><td>train_samples_per_second</td><td>9.505</td></tr><tr><td>train_steps_per_second</td><td>0.597</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">bert-crossencoder-classification-cross_entropy</strong> at: <a href='https://wandb.ai/minoosh/bert-crossencoder-classification/runs/plhtys4r' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-classification/runs/plhtys4r</a><br/> View project at: <a href='https://wandb.ai/minoosh/bert-crossencoder-classification' target=\"_blank\">https://wandb.ai/minoosh/bert-crossencoder-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241101_233040-plhtys4r/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Specify list of loss functions to try\n",
        "loss_functions = [\"cross_entropy\", \"focal_loss\", \"kl_divergence\"]\n",
        "\n",
        "loss_fn = loss_functions[0]  # Change to desired loss function\n",
        "wandb.init(project=\"bert-crossencoder-classification\", name=f\"bert-crossencoder-classification-{loss_fn}\", config={\"epochs\": 3, \"batch_size\": 16, \"learning_rate\": 2e-5})\n",
        "tr = train_crossencoder(loss_fn)\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yie3val5E86J",
        "outputId": "17283bbd-19bd-4628-e478-c982b1486290"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertTokenizerFast(name_or_path='google-bert/bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = tr.tokenizer\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIXBvF2EK-0i",
        "outputId": "3ce97a8b-05d3-4375-88fb-09b6e1833d0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text1', 'text2', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "    num_rows: 309\n",
              "})"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "pbyFXAtrESHQ",
        "outputId": "5e9d0914-b544-4033-97b7-c01f1e0856d8"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Unsupported types (<class 'NoneType'>) passed to `_pad_across_processes`. Only nested list/tuple/dicts of objects that are valid for `is_torch_tensor` should be passed.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-0283fedf83fa>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Make predictions on the test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Get the predicted class indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3743\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3744\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   3745\u001b[0m             \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3746\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3875\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3876\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3877\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_logits_for_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3879\u001b[0m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_logits_for_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mpad_across_processes\u001b[0;34m(self, tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m   2548\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2549\u001b[0m         \"\"\"\n\u001b[0;32m-> 2550\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2552\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munwrap_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_fp32_wrapper\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDistributedOperationException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0moperation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{function.__module__}.{function.__name__}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mpad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m     return recursively_apply(\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0m_pad_across_processes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_on_other_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \"\"\"\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         return honor_type(\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mhonor_type\u001b[0;34m(obj, generator)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             (\n\u001b[0;32m--> 111\u001b[0;31m                 recursively_apply(\n\u001b[0m\u001b[1;32m    112\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_on_other_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_on_other_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0merror_on_other_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0;34mf\"Unsupported types ({type(data)}) passed to `{func.__name__}`. Only nested list/tuple/dicts of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;34mf\"objects that are valid for `{test_type.__name__}` should be passed.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Unsupported types (<class 'NoneType'>) passed to `_pad_across_processes`. Only nested list/tuple/dicts of objects that are valid for `is_torch_tensor` should be passed."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer\n",
        "from datasets import load_dataset\n",
        "\n",
        "'''# Load the model and tokenizer\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"/content/output/TTTTempathy-crossencoder-cross_entropy\")\n",
        "'''\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"minoosh/EPITOME_pairs\")\n",
        "\n",
        "# Tokenize the test split\n",
        "def preprocess_test_function(examples):\n",
        "    encodings = tokenizer(examples['text1'], examples['text2'], truncation=True, padding=True, max_length=512)\n",
        "    return encodings\n",
        "\n",
        "# Apply tokenization to the test dataset\n",
        "tokenized_test = dataset['validation'].map(preprocess_test_function, batched=True)\n",
        "tokenized_test.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = tr\n",
        "\n",
        "# Make predictions on the test dataset\n",
        "predictions = trainer.predict(tokenized_test)\n",
        "\n",
        "# Get the predicted class indices\n",
        "predicted_classes = predictions.predictions.argmax(axis=1)\n",
        "\n",
        "# If you want to compare with actual labels\n",
        "actual_labels = tokenized_test['label']\n",
        "\n",
        "# Print out predictions and actual labels for verification\n",
        "for i in range(len(predicted_classes)):\n",
        "    print(f\"Predicted: {predicted_classes[i]}, Actual: {actual_labels[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DxapER-EcpE"
      },
      "outputs": [],
      "source": [
        "res = compute_metrics2(actual_labels, predicted_classes)\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6gFGCh1Ecs8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_Yc7GSnEcvI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUhtlbqOEczG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8V9XmXy6oS3h",
        "outputId": "72f7bb5a-ba6f-45fb-9b1d-bcb8a277e74e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/output/TTTTempathy-crossencoder-cross_entropy and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241102_000048-o6edigfu</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/minoosh/huggingface/runs/o6edigfu' target=\"_blank\">tmp_trainer</a></strong> to <a href='https://wandb.ai/minoosh/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/minoosh/huggingface' target=\"_blank\">https://wandb.ai/minoosh/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/minoosh/huggingface/runs/o6edigfu' target=\"_blank\">https://wandb.ai/minoosh/huggingface/runs/o6edigfu</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 3\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 0\n",
            "Predicted: 0, Actual: 2\n",
            "Predicted: 0, Actual: 1\n",
            "Predicted: 0, Actual: 3\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"/content/output/TTTTempathy-crossencoder-cross_entropy\")\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"minoosh/EPITOME_pairs\")\n",
        "\n",
        "# Tokenize the test split\n",
        "def preprocess_test_function(examples):\n",
        "    encodings = tokenizer(examples['text1'], examples['text2'], truncation=True, padding=True, max_length=512)\n",
        "    return encodings\n",
        "\n",
        "# Apply tokenization to the test dataset\n",
        "tokenized_test = dataset['validation'].map(preprocess_test_function, batched=True)\n",
        "tokenized_test.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(model=model)\n",
        "\n",
        "# Make predictions on the test dataset\n",
        "predictions = trainer.predict(tokenized_test)\n",
        "\n",
        "# Get the predicted class indices\n",
        "predicted_classes = predictions.predictions.argmax(axis=1)\n",
        "\n",
        "# If you want to compare with actual labels\n",
        "actual_labels = tokenized_test['label']\n",
        "\n",
        "# Print out predictions and actual labels for verification\n",
        "for i in range(len(predicted_classes)):\n",
        "    print(f\"Predicted: {predicted_classes[i]}, Actual: {actual_labels[i]}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5bJE7y_4-47",
        "outputId": "6e5fb99f-6ae0-48fb-c8f9-7c19880fc2fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      1.00      0.37        69\n",
            "           1       0.00      0.00      0.00        56\n",
            "           2       0.00      0.00      0.00       130\n",
            "           3       0.00      0.00      0.00        54\n",
            "\n",
            "    accuracy                           0.22       309\n",
            "   macro avg       0.06      0.25      0.09       309\n",
            "weighted avg       0.05      0.22      0.08       309\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "a = classification_report(actual_labels, predicted_classes)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK0MTjGF5i2S",
        "outputId": "3af710f0-5241-4287-cc4c-3370b5941303"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.22330097087378642"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "recall_score(actual_labels, predicted_classes, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "krmrWPNnDOrY"
      },
      "outputs": [],
      "source": [
        "def compute_metrics2(preds, labels):\n",
        "    #predictions, labels = eval_pred\n",
        "    #preds = predictions.argmax(axis=1)\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    precision = precision_score(labels, preds, average=\"weighted\")\n",
        "    recall = recall_score(labels, preds, average=\"weighted\")\n",
        "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ5KVM9p5k9l",
        "outputId": "5065d9ed-64df-4ed6-fe37-0a06ddc13c5d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "res = compute_metrics2(actual_labels, predicted_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRTJrz98Dbis",
        "outputId": "075b07cc-7443-44d1-f17c-3f5d03c68cd6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.22330097087378642,\n",
              " 'precision': 1.0,\n",
              " 'recall': 0.22330097087378642,\n",
              " 'f1': 0.36507936507936506}"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30787,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
