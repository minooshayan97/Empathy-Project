{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tgj3xkNh7RF",
        "outputId": "9281f929-4223-4ffe-bfd6-c76a8bc92cd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/480.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpS1JGLpiiAE",
        "outputId": "7d6ae6f6-56d3-4756-f74a-74fd0574f44f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login --token "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "_0ko5hr-koyu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# Define a custom BiEncoder model with options for different loss functions\n",
        "class BiEncoderModel(torch.nn.Module):\n",
        "    def __init__(self, base_model, config=None, num_classes=4, loss_fn=\"cross_entropy\"):\n",
        "        super(BiEncoderModel, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.config = config  # Add this line to set the config attribute\n",
        "        self.classifier = torch.nn.Linear(base_model.config.hidden_size * 2, num_classes)  # Updated for 4 classes\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def forward(self, input_ids_text1, attention_mask_text1, input_ids_text2, attention_mask_text2, labels=None):\n",
        "        # Encode text1 and text2 separately\n",
        "        outputs_text1 = self.base_model(input_ids_text1, attention_mask=attention_mask_text1)\n",
        "        outputs_text2 = self.base_model(input_ids_text2, attention_mask=attention_mask_text2)\n",
        "        # Extract [CLS] token embeddings (first token)\n",
        "        cls_embedding_text1 = outputs_text1.last_hidden_state[:, 0, :]\n",
        "        cls_embedding_text2 = outputs_text2.last_hidden_state[:, 0, :]\n",
        "\n",
        "        # Concatenate embeddings and apply classifier\n",
        "        concatenated_embeddings = torch.cat([cls_embedding_text1, cls_embedding_text2], dim=1)\n",
        "        logits = self.classifier(concatenated_embeddings)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if self.loss_fn == \"cross_entropy\":\n",
        "                loss_fct = torch.nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
        "                loss = loss_fct(logits, labels)\n",
        "            elif self.loss_fn == \"focal_loss\":\n",
        "                # Focal loss implementation\n",
        "                alpha = 0.25\n",
        "                gamma = 2.0\n",
        "                ce_loss = torch.nn.CrossEntropyLoss(reduction=\"none\")(logits, labels)\n",
        "                pt = torch.exp(-ce_loss)  # Probability of the true class\n",
        "                loss = (alpha * (1 - pt) ** gamma * ce_loss).mean()\n",
        "            elif self.loss_fn == \"kl_divergence\":\n",
        "                # KL Divergence for soft-label classification\n",
        "                kl_div = torch.nn.KLDivLoss(reduction=\"batchmean\")\n",
        "                soft_labels = torch.nn.functional.one_hot(labels, num_classes=self.classifier.out_features).float()\n",
        "                log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
        "                loss = kl_div(log_probs, soft_labels)\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported loss function: {self.loss_fn}\")\n",
        "\n",
        "        return {\"loss\": loss, \"logits\": logits}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "hi6tBgKRwNvm"
      },
      "outputs": [],
      "source": [
        "class BiEncoderCollator:\n",
        "    def __call__(self, features):\n",
        "        batch = {\n",
        "            'input_ids_text1': torch.nn.utils.rnn.pad_sequence(\n",
        "                [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n",
        "            'attention_mask_text1': torch.nn.utils.rnn.pad_sequence(\n",
        "                [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n",
        "            'input_ids_text2': torch.nn.utils.rnn.pad_sequence(\n",
        "                [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n",
        "            'attention_mask_text2': torch.nn.utils.rnn.pad_sequence(\n",
        "                [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n",
        "            'labels': torch.tensor([f['labels'] for f in features], dtype=torch.long)  # Change to long for classification\n",
        "        }\n",
        "        return batch\n",
        "\n",
        "collator = BiEncoderCollator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "rJ6YZkd2hm0a"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "def compute_metrics2(labels, preds):\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "    precision = precision_score(labels, preds, average=\"weighted\")\n",
        "    recall = recall_score(labels, preds, average=\"weighted\")\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "gcVW7tzkw4O2"
      },
      "outputs": [],
      "source": [
        "columns_to_keep = ['input_ids_text1', 'attention_mask_text1', 'input_ids_text2', 'attention_mask_text2', 'labels']\n",
        "\n",
        "# Tokenize both text1 and text2 independently\n",
        "def preprocess_function(examples):\n",
        "    text1_encodings = tokenizer(examples['text1'], truncation=True, padding=True, max_length=512)\n",
        "    text2_encodings = tokenizer(examples['text2'], truncation=True, padding=True, max_length=512)\n",
        "    return {\n",
        "        'input_ids_text1': text1_encodings['input_ids'],\n",
        "        'attention_mask_text1': text1_encodings['attention_mask'],\n",
        "        'input_ids_text2': text2_encodings['input_ids'],\n",
        "        'attention_mask_text2': text2_encodings['attention_mask'],\n",
        "        'labels': examples['label']\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5O-4xc-qwbV"
      },
      "source": [
        "# \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "vBnxNGJFlr1I"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load test dataset\n",
        "dataset = load_dataset(\"minoosh/EPITOME_pairs\")\n",
        "\n",
        "# Tokenize the test set\n",
        "tokenized_test = dataset['test'].map(preprocess_function, batched=True)\n",
        "\n",
        "# Set the format for the test dataset for PyTorch\n",
        "tokenized_test.set_format(type='torch', columns=columns_to_keep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDifpi0ZlJ1_",
        "outputId": "0e23fdc9-8c02-4a84-da63-67dc511193c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at minoosh/tmp_trainer were not used when initializing BertModel: ['base_model.embeddings.LayerNorm.bias', 'base_model.embeddings.LayerNorm.weight', 'base_model.embeddings.position_embeddings.weight', 'base_model.embeddings.token_type_embeddings.weight', 'base_model.embeddings.word_embeddings.weight', 'base_model.encoder.layer.0.attention.output.LayerNorm.bias', 'base_model.encoder.layer.0.attention.output.LayerNorm.weight', 'base_model.encoder.layer.0.attention.output.dense.bias', 'base_model.encoder.layer.0.attention.output.dense.weight', 'base_model.encoder.layer.0.attention.self.key.bias', 'base_model.encoder.layer.0.attention.self.key.weight', 'base_model.encoder.layer.0.attention.self.query.bias', 'base_model.encoder.layer.0.attention.self.query.weight', 'base_model.encoder.layer.0.attention.self.value.bias', 'base_model.encoder.layer.0.attention.self.value.weight', 'base_model.encoder.layer.0.intermediate.dense.bias', 'base_model.encoder.layer.0.intermediate.dense.weight', 'base_model.encoder.layer.0.output.LayerNorm.bias', 'base_model.encoder.layer.0.output.LayerNorm.weight', 'base_model.encoder.layer.0.output.dense.bias', 'base_model.encoder.layer.0.output.dense.weight', 'base_model.encoder.layer.1.attention.output.LayerNorm.bias', 'base_model.encoder.layer.1.attention.output.LayerNorm.weight', 'base_model.encoder.layer.1.attention.output.dense.bias', 'base_model.encoder.layer.1.attention.output.dense.weight', 'base_model.encoder.layer.1.attention.self.key.bias', 'base_model.encoder.layer.1.attention.self.key.weight', 'base_model.encoder.layer.1.attention.self.query.bias', 'base_model.encoder.layer.1.attention.self.query.weight', 'base_model.encoder.layer.1.attention.self.value.bias', 'base_model.encoder.layer.1.attention.self.value.weight', 'base_model.encoder.layer.1.intermediate.dense.bias', 'base_model.encoder.layer.1.intermediate.dense.weight', 'base_model.encoder.layer.1.output.LayerNorm.bias', 'base_model.encoder.layer.1.output.LayerNorm.weight', 'base_model.encoder.layer.1.output.dense.bias', 'base_model.encoder.layer.1.output.dense.weight', 'base_model.encoder.layer.10.attention.output.LayerNorm.bias', 'base_model.encoder.layer.10.attention.output.LayerNorm.weight', 'base_model.encoder.layer.10.attention.output.dense.bias', 'base_model.encoder.layer.10.attention.output.dense.weight', 'base_model.encoder.layer.10.attention.self.key.bias', 'base_model.encoder.layer.10.attention.self.key.weight', 'base_model.encoder.layer.10.attention.self.query.bias', 'base_model.encoder.layer.10.attention.self.query.weight', 'base_model.encoder.layer.10.attention.self.value.bias', 'base_model.encoder.layer.10.attention.self.value.weight', 'base_model.encoder.layer.10.intermediate.dense.bias', 'base_model.encoder.layer.10.intermediate.dense.weight', 'base_model.encoder.layer.10.output.LayerNorm.bias', 'base_model.encoder.layer.10.output.LayerNorm.weight', 'base_model.encoder.layer.10.output.dense.bias', 'base_model.encoder.layer.10.output.dense.weight', 'base_model.encoder.layer.11.attention.output.LayerNorm.bias', 'base_model.encoder.layer.11.attention.output.LayerNorm.weight', 'base_model.encoder.layer.11.attention.output.dense.bias', 'base_model.encoder.layer.11.attention.output.dense.weight', 'base_model.encoder.layer.11.attention.self.key.bias', 'base_model.encoder.layer.11.attention.self.key.weight', 'base_model.encoder.layer.11.attention.self.query.bias', 'base_model.encoder.layer.11.attention.self.query.weight', 'base_model.encoder.layer.11.attention.self.value.bias', 'base_model.encoder.layer.11.attention.self.value.weight', 'base_model.encoder.layer.11.intermediate.dense.bias', 'base_model.encoder.layer.11.intermediate.dense.weight', 'base_model.encoder.layer.11.output.LayerNorm.bias', 'base_model.encoder.layer.11.output.LayerNorm.weight', 'base_model.encoder.layer.11.output.dense.bias', 'base_model.encoder.layer.11.output.dense.weight', 'base_model.encoder.layer.2.attention.output.LayerNorm.bias', 'base_model.encoder.layer.2.attention.output.LayerNorm.weight', 'base_model.encoder.layer.2.attention.output.dense.bias', 'base_model.encoder.layer.2.attention.output.dense.weight', 'base_model.encoder.layer.2.attention.self.key.bias', 'base_model.encoder.layer.2.attention.self.key.weight', 'base_model.encoder.layer.2.attention.self.query.bias', 'base_model.encoder.layer.2.attention.self.query.weight', 'base_model.encoder.layer.2.attention.self.value.bias', 'base_model.encoder.layer.2.attention.self.value.weight', 'base_model.encoder.layer.2.intermediate.dense.bias', 'base_model.encoder.layer.2.intermediate.dense.weight', 'base_model.encoder.layer.2.output.LayerNorm.bias', 'base_model.encoder.layer.2.output.LayerNorm.weight', 'base_model.encoder.layer.2.output.dense.bias', 'base_model.encoder.layer.2.output.dense.weight', 'base_model.encoder.layer.3.attention.output.LayerNorm.bias', 'base_model.encoder.layer.3.attention.output.LayerNorm.weight', 'base_model.encoder.layer.3.attention.output.dense.bias', 'base_model.encoder.layer.3.attention.output.dense.weight', 'base_model.encoder.layer.3.attention.self.key.bias', 'base_model.encoder.layer.3.attention.self.key.weight', 'base_model.encoder.layer.3.attention.self.query.bias', 'base_model.encoder.layer.3.attention.self.query.weight', 'base_model.encoder.layer.3.attention.self.value.bias', 'base_model.encoder.layer.3.attention.self.value.weight', 'base_model.encoder.layer.3.intermediate.dense.bias', 'base_model.encoder.layer.3.intermediate.dense.weight', 'base_model.encoder.layer.3.output.LayerNorm.bias', 'base_model.encoder.layer.3.output.LayerNorm.weight', 'base_model.encoder.layer.3.output.dense.bias', 'base_model.encoder.layer.3.output.dense.weight', 'base_model.encoder.layer.4.attention.output.LayerNorm.bias', 'base_model.encoder.layer.4.attention.output.LayerNorm.weight', 'base_model.encoder.layer.4.attention.output.dense.bias', 'base_model.encoder.layer.4.attention.output.dense.weight', 'base_model.encoder.layer.4.attention.self.key.bias', 'base_model.encoder.layer.4.attention.self.key.weight', 'base_model.encoder.layer.4.attention.self.query.bias', 'base_model.encoder.layer.4.attention.self.query.weight', 'base_model.encoder.layer.4.attention.self.value.bias', 'base_model.encoder.layer.4.attention.self.value.weight', 'base_model.encoder.layer.4.intermediate.dense.bias', 'base_model.encoder.layer.4.intermediate.dense.weight', 'base_model.encoder.layer.4.output.LayerNorm.bias', 'base_model.encoder.layer.4.output.LayerNorm.weight', 'base_model.encoder.layer.4.output.dense.bias', 'base_model.encoder.layer.4.output.dense.weight', 'base_model.encoder.layer.5.attention.output.LayerNorm.bias', 'base_model.encoder.layer.5.attention.output.LayerNorm.weight', 'base_model.encoder.layer.5.attention.output.dense.bias', 'base_model.encoder.layer.5.attention.output.dense.weight', 'base_model.encoder.layer.5.attention.self.key.bias', 'base_model.encoder.layer.5.attention.self.key.weight', 'base_model.encoder.layer.5.attention.self.query.bias', 'base_model.encoder.layer.5.attention.self.query.weight', 'base_model.encoder.layer.5.attention.self.value.bias', 'base_model.encoder.layer.5.attention.self.value.weight', 'base_model.encoder.layer.5.intermediate.dense.bias', 'base_model.encoder.layer.5.intermediate.dense.weight', 'base_model.encoder.layer.5.output.LayerNorm.bias', 'base_model.encoder.layer.5.output.LayerNorm.weight', 'base_model.encoder.layer.5.output.dense.bias', 'base_model.encoder.layer.5.output.dense.weight', 'base_model.encoder.layer.6.attention.output.LayerNorm.bias', 'base_model.encoder.layer.6.attention.output.LayerNorm.weight', 'base_model.encoder.layer.6.attention.output.dense.bias', 'base_model.encoder.layer.6.attention.output.dense.weight', 'base_model.encoder.layer.6.attention.self.key.bias', 'base_model.encoder.layer.6.attention.self.key.weight', 'base_model.encoder.layer.6.attention.self.query.bias', 'base_model.encoder.layer.6.attention.self.query.weight', 'base_model.encoder.layer.6.attention.self.value.bias', 'base_model.encoder.layer.6.attention.self.value.weight', 'base_model.encoder.layer.6.intermediate.dense.bias', 'base_model.encoder.layer.6.intermediate.dense.weight', 'base_model.encoder.layer.6.output.LayerNorm.bias', 'base_model.encoder.layer.6.output.LayerNorm.weight', 'base_model.encoder.layer.6.output.dense.bias', 'base_model.encoder.layer.6.output.dense.weight', 'base_model.encoder.layer.7.attention.output.LayerNorm.bias', 'base_model.encoder.layer.7.attention.output.LayerNorm.weight', 'base_model.encoder.layer.7.attention.output.dense.bias', 'base_model.encoder.layer.7.attention.output.dense.weight', 'base_model.encoder.layer.7.attention.self.key.bias', 'base_model.encoder.layer.7.attention.self.key.weight', 'base_model.encoder.layer.7.attention.self.query.bias', 'base_model.encoder.layer.7.attention.self.query.weight', 'base_model.encoder.layer.7.attention.self.value.bias', 'base_model.encoder.layer.7.attention.self.value.weight', 'base_model.encoder.layer.7.intermediate.dense.bias', 'base_model.encoder.layer.7.intermediate.dense.weight', 'base_model.encoder.layer.7.output.LayerNorm.bias', 'base_model.encoder.layer.7.output.LayerNorm.weight', 'base_model.encoder.layer.7.output.dense.bias', 'base_model.encoder.layer.7.output.dense.weight', 'base_model.encoder.layer.8.attention.output.LayerNorm.bias', 'base_model.encoder.layer.8.attention.output.LayerNorm.weight', 'base_model.encoder.layer.8.attention.output.dense.bias', 'base_model.encoder.layer.8.attention.output.dense.weight', 'base_model.encoder.layer.8.attention.self.key.bias', 'base_model.encoder.layer.8.attention.self.key.weight', 'base_model.encoder.layer.8.attention.self.query.bias', 'base_model.encoder.layer.8.attention.self.query.weight', 'base_model.encoder.layer.8.attention.self.value.bias', 'base_model.encoder.layer.8.attention.self.value.weight', 'base_model.encoder.layer.8.intermediate.dense.bias', 'base_model.encoder.layer.8.intermediate.dense.weight', 'base_model.encoder.layer.8.output.LayerNorm.bias', 'base_model.encoder.layer.8.output.LayerNorm.weight', 'base_model.encoder.layer.8.output.dense.bias', 'base_model.encoder.layer.8.output.dense.weight', 'base_model.encoder.layer.9.attention.output.LayerNorm.bias', 'base_model.encoder.layer.9.attention.output.LayerNorm.weight', 'base_model.encoder.layer.9.attention.output.dense.bias', 'base_model.encoder.layer.9.attention.output.dense.weight', 'base_model.encoder.layer.9.attention.self.key.bias', 'base_model.encoder.layer.9.attention.self.key.weight', 'base_model.encoder.layer.9.attention.self.query.bias', 'base_model.encoder.layer.9.attention.self.query.weight', 'base_model.encoder.layer.9.attention.self.value.bias', 'base_model.encoder.layer.9.attention.self.value.weight', 'base_model.encoder.layer.9.intermediate.dense.bias', 'base_model.encoder.layer.9.intermediate.dense.weight', 'base_model.encoder.layer.9.output.LayerNorm.bias', 'base_model.encoder.layer.9.output.LayerNorm.weight', 'base_model.encoder.layer.9.output.dense.bias', 'base_model.encoder.layer.9.output.dense.weight', 'base_model.pooler.dense.bias', 'base_model.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at minoosh/tmp_trainer and are newly initialized: ['embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoConfig, AutoModel, AutoTokenizer, Trainer\n",
        "\n",
        "model_name = \"minoosh/tmp_trainer\"\n",
        "\n",
        "# Load the tokenizer and model from Hugging Face\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "bi_encoder_model = BiEncoderModel(base_model=model, config=config)\n",
        "\n",
        "trainer = Trainer(\n",
        "        model=loaded_model,\n",
        "        data_collator=collator,# Custom collator for handling bi-encoder inputs\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "fTj8Eo3alJ7A",
        "outputId": "65d6f29f-b14d-46ef-cf4d-208e7842ed57"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-50-d2bb23ff5eb9>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['input_ids_text1']) for f in features], batch_first=True),\n",
            "<ipython-input-50-d2bb23ff5eb9>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['attention_mask_text1']) for f in features], batch_first=True),\n",
            "<ipython-input-50-d2bb23ff5eb9>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['input_ids_text2']) for f in features], batch_first=True),\n",
            "<ipython-input-50-d2bb23ff5eb9>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  [torch.tensor(f['attention_mask_text2']) for f in features], batch_first=True),\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict_test_set(trainer, test_dataset):\n",
        "    # Get predictions\n",
        "    predictions = trainer.predict(test_dataset)\n",
        "    pred_logits = predictions.predictions\n",
        "    pred_labels = np.argmax(pred_logits, axis=1)  # Get the predicted class labels\n",
        "    return pred_labels, predictions.label_ids  # Return predicted and actual labels\n",
        "\n",
        "# Example usage after training\n",
        "#trainer = train_biencoder(loss_fn=\"cross_entropy\")  # Train the model first\n",
        "pred_labels, true_labels = predict_test_set(trainer, tokenized_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJeMCssxlKAP",
        "outputId": "cac9a0c5-bed4-470d-c0af-e242c7c09480"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.6461038961038961,\n",
              " 'f1': 0.6501035994774385,\n",
              " 'precision': 0.6706513643205454,\n",
              " 'recall': 0.6461038961038961}"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_metrics2(pred_labels, true_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZGv0Dp_rGdc"
      },
      "source": [
        "# \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yIRB1O2lDev"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y00XdaLAKGKd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LTtccnyKGQu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeDWeF4hlDio"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V00xn-scCbN"
      },
      "source": [
        "# \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OP9xDwVXlFEP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0aXAgrGlFJH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sadfT-sElHHn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-HhPGtLlFOP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "mYbcr6K8agjj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from huggingface_hub import HfApi\n",
        "from transformers import AutoModel, AutoConfig, AutoTokenizer, BertConfig\n",
        "\n",
        "def save_and_push_to_hub(trainer, repo_id, token=None):\n",
        "    \"\"\"\n",
        "    Save and push BiEncoder model to Hugging Face Hub\n",
        "    \"\"\"\n",
        "    api = HfApi()\n",
        "\n",
        "    try:\n",
        "        temp_save_path = f\"temp_save_{repo_id.split('/')[-1]}\"\n",
        "        os.makedirs(temp_save_path, exist_ok=True)\n",
        "\n",
        "        print(f\"Saving model to {temp_save_path}...\")\n",
        "\n",
        "        # 1. Save the base model configuration\n",
        "        base_config = trainer.model.base_model.config.to_dict()\n",
        "        base_config[\"model_type\"] = \"bert\"  # Ensure we're using BERT as base\n",
        "        base_config[\"architectures\"] = [\"BertModel\"]\n",
        "\n",
        "        with open(os.path.join(temp_save_path, \"config.json\"), 'w') as f:\n",
        "            json.dump(base_config, f)\n",
        "\n",
        "        # 2. Save model weights\n",
        "        torch.save(trainer.model.state_dict(), os.path.join(temp_save_path, \"pytorch_model.bin\"))\n",
        "\n",
        "        # 3. Save tokenizer\n",
        "        print(\"Saving tokenizer...\")\n",
        "        if hasattr(trainer, 'tokenizer'):\n",
        "            trainer.tokenizer.save_pretrained(temp_save_path)\n",
        "\n",
        "        # 4. Create model card\n",
        "        model_card = f\"\"\"---\n",
        "language: en\n",
        "tags:\n",
        "- bert\n",
        "- classification\n",
        "- pytorch\n",
        "pipeline_tag: text-classification\n",
        "---\n",
        "\n",
        "# BiEncoder Classification Model\n",
        "\n",
        "This model is a BiEncoder architecture based on BERT for text pair classification.\n",
        "\n",
        "## Model Details\n",
        "- Base Model: bert-base-uncased\n",
        "- Architecture: BiEncoder with BERT base\n",
        "- Number of classes: {trainer.model.classifier.out_features}\n",
        "\n",
        "## Usage\n",
        "\n",
        "```python\n",
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"{repo_id}\")\n",
        "\n",
        "# Load model weights\n",
        "state_dict = torch.load(\"pytorch_model.bin\")\n",
        "\n",
        "# Initialize model (you'll need the BiEncoderModel class)\n",
        "model = BiEncoderModel(\n",
        "    base_model=AutoModel.from_pretrained(\"bert-base-uncased\"),\n",
        "    num_classes={trainer.model.classifier.out_features}\n",
        ")\n",
        "model.load_state_dict(state_dict)\n",
        "```\n",
        "\"\"\"\n",
        "        with open(os.path.join(temp_save_path, \"README.md\"), 'w') as f:\n",
        "            f.write(model_card)\n",
        "\n",
        "        # 5. Push to hub\n",
        "        print(f\"Pushing to hub at {repo_id}...\")\n",
        "        api.upload_folder(\n",
        "            folder_path=temp_save_path,\n",
        "            repo_id=repo_id,\n",
        "            token=token\n",
        "        )\n",
        "\n",
        "        print(f\"Successfully pushed model to {repo_id}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during push to hub: {str(e)}\")\n",
        "        raise\n",
        "    finally:\n",
        "        if os.path.exists(temp_save_path):\n",
        "            import shutil\n",
        "            shutil.rmtree(temp_save_path)\n",
        "\n",
        "def load_from_hub(repo_id, num_classes=4):\n",
        "    \"\"\"\n",
        "    Load BiEncoder model from Hugging Face Hub\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"Loading model from {repo_id}...\")\n",
        "\n",
        "        # 1. Initialize base model with BERT\n",
        "        base_model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "        # 2. Create BiEncoder model\n",
        "        model = BiEncoderModel(\n",
        "            base_model=base_model,\n",
        "            num_classes=num_classes\n",
        "        )\n",
        "\n",
        "        # 3. Load state dict\n",
        "        state_dict = torch.hub.load_state_dict_from_url(\n",
        "            f\"https://huggingface.co/{repo_id}/resolve/main/pytorch_model.bin\",\n",
        "            map_location=\"cpu\"\n",
        "        )\n",
        "        model.load_state_dict(state_dict)\n",
        "\n",
        "        # 4. Load tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(repo_id)\n",
        "\n",
        "        # 5. Create trainer\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            data_collator=BiEncoderCollator(),\n",
        "            # compute_metrics=compute_metrics\n",
        "        )\n",
        "\n",
        "        print(\"Model loaded successfully!\")\n",
        "        return trainer, model, tokenizer\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model from hub: {str(e)}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51mI7TZualGi",
        "outputId": "7f917cd2-3b0c-4eef-dc15-2fb70676a464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from minoosh/repo...\n",
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "repo_id = \"minoosh/repo\"  # e.g., \"minoosh/bert-biencoder-classification\"\n",
        "\n",
        "# To load from hub later:\n",
        "loaded_trainer, loaded_model, loaded_tokenizer = load_from_hub(repo_id)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
